\documentclass{mtmtcl}

\newcommand{\cs}[1]{\texttt{\PrintChar{92}#1}}
% \newcommand{\tsplode}{\texttt{%
%   \PrintChar{123}\kern-0.1em*\kern-0.1em\PrintChar{125}%
% }}

\theoremstyle{plain}
\newtheorem{policy}{Policy}

\theoremstyle{remark}
\newtheorem*{example}{Example}

% 
% \usepackage{amsmath,amsfonts,amssymb}
% \usepackage{amsthm}
% 
% \usepackage{longtable}
% 
% \theoremstyle{definition}
% \newtheorem*{definition}{Definition}
% \theoremstyle{remark}
% \newtheorem*{remark}{Remark}
% 
% 
% \makeatletter
% \NewDescribeCommand{\defining}{%
%    \XD@grab@oarg\XD@grab@sarg{*}\XD@grab@oarg\XD@grab@marg
% }{4}{%
%    \IndexEntry{%
%       \ifx \NoValue#1%
%          \LevelSame{\ifx\NoValue#3#4\else#3\fi}%
%       \else
%          \LevelSorted{#1}{\ifx\NoValue#3#4\else#3\fi}%
%       \fi
%    }{main}{\thepage}%
%    \textbf{#4}%
%    \@gobble % Eats \ignorespaces
% }
% \makeatother
% 
% \PageIndex
% \CodelineNumbered
% \setcounter{IndexColumns}{2}
% 
% \newenvironment{procmethod}{%
%    \tclsubcommand{method}{submethod}%
% }{\endtclsubcommand}
% 
% 
% % \newcommand{\Z}{\ensuremath{\mathbb{Z}}}
% \newcommand{\Z}{\texttt{Z}}
% 
% \newcommand*{\mw}[1]{\word{$#1$}}
% 
% \newcommand{\mtl}{\texttt{mathematcl}}
% \newcommand{\Tcl}{\Tcllogo}
% \newcommand{\TclObj}{\Tcllogo\_Obj}
% \newcommand{\TclObjs}{\TclObj s}
% 
% \providecommand{\Ldash}{---}
% \providecommand{\Rdash}{---}
% \providecommand{\Dash}{---}

\begin{document}

\title{\mtl~interfaces}
\author{Lars Hellstr\"om}
\date{2006-06-21--}
\maketitle


\begin{abstract}
  A key part in the \mtl\ system is the use of \emph{interfaces} 
  for structures as a way of making them work together. This 
  document is the primary collection of specifications of these 
  interfaces.
\end{abstract}

\tableofcontents


\section{Introduction}

The \mtl\ system for algebraic computations is designed to meet the 
following goals:
\begin{itemize}
  \item
    It should be reasonably easy to program. 
    \iffalse
    and in particular not 
    constantly burden the mathematician's mind with issues of how 
    data is being stored.
    \fi
  \item
    It should be open to new concepts and new implementations\Dash 
    built-in operations should not recieve preferential treatment or 
    display behaviour that is otherwise unattainable.
  \item
    It should be able to manage the many levels of abstraction that 
    occur in algebraic constructions.
  \item
    The system should be portable.
%   \item
%     \dots
\end{itemize}
To meet these goals, the following design decisions have been made:

\begin{policy} \label{Pol:Strukturer}
  Focus is on mathematical \emph{structures} and the \emph{interfaces} 
  these support. Generic algorithms should be expressed not in terms 
  of concrete implementations, but in terms of abstract structures 
  provided as parameters. Structures expose their capabilities and 
  useful properties by declaring support for particular interfaces.
\end{policy}

Basic examples of interfaces are `ring', `group', `lattice', and so 
on. Examples of structures are $\mathbb{Z}$~(ring, additive group, 
lattice under $\max$ and $\min$), $\mathbb{C}$~(field, ring, additive 
group), $\mathbb{N}$~(semiring, additive monoid, multiplicative 
monoid, divisor lattice, max/min lattice), $\mathbb{Z}[x]$~(ring etc.), 
$\mathbb{Z}[x]\big/ \langle x^2 - 2\rangle$~(ditto), $\mathbb{Z} + 
i\mathbb{Z}$~(Gaussian integers: Euclidean domain, ring etc.), 
$\mathrm{M}_n(\mathbb{R})$~(real $n \times n$ matrices: ring etc.), 
$\mathrm{GL}_n(\mathbb{R})$~(invertible real $n \times n$ matrices: a 
group), and so on. What should be apparent from these examples is 
that many structures naturally support more than one interface; it is 
seldom useful to ask for a name describing all that a structure is, 
but generally quite sufficient to pick an interface and ask whether 
the structure supports it. The case of the natural numbers should 
also make it clear that there are sometimes more than one way in which 
a set can often be turned into a structure supporting a particular 
interface; the ways in which one can reinterpret the basic 
mathematical structures are surprisingly many.

What this means in practice is that in order to multiply two 
elements $a$ and $b$ of some algebra $\mathcal{A}$ one does not 
write `$a$ times $b$', but rather `$\mathcal{A}$-multiply $a$ and 
$b$'; cf.~the notation \(a \cdot_{\mathcal{A}} b\) that is 
sometimes used when one needs to clarify that this is the 
multiplication operation of~$\mathcal{A}$. Provided that (references 
to) structures such as this `$\mathcal{A}$' can be passed around as 
easily as elements of structures\Ldash which is essentially the 
`provided as parameters' in the policy statment, and explained in 
more detail below\Rdash this is a cheap and effective way of 
explaining to the computer what operation is desired. Equally 
important is the fact that it scales well: that it can handle 
hundreds of structures as easily as one. Both are necessary to meet 
the goal of handling multiple levels of abstraction, since a level 
$n$ structure is usually constructed from one or several level $n-1$ 
structures, which in turn are constructed from level $n-2$ 
structures, and so on; the implementation of a basic operation in 
a high level structure can easily exercise dozens of operations in 
lower level structures.

\begin{example}
  The field of rational numbers $\mathbb{Q}$ is typically implemented 
  as the field of fractions of the ring of integers $\mathbb{Z}$. 
  This means every rational number is a pair of integers. Even for 
  such an ``easy'' operation as addition in $\mathbb{Q}$, it is 
  necessary to compute a common multiple of the denominators of the 
  terms and extend all the fractions accordingly, which requires at 
  least multiplication in $\mathbb{Z}$. One furthermore typically 
  wants to use as small numbers as possible in these calculations, 
  and then it is also necessary to compute quotients and GCDs in 
  $\mathbb{Z}$.
  
  Consider next the ring of $n \times n$ matrices over $\mathbb{Q}$. 
  One addition in this ring is $n^2$ separate additions in $\mathbb{Q}$. 
  Multiplication in the matrix ring requires both the multiplication 
  and addition operations in $\mathbb{Q}$. Going further, one can 
  consider the subgroup $\mathrm{SL}_n(\mathbb{Q})$, and even the 
  corresponding group algebra $\mathbb{Q}\bigl[ 
  \mathrm{SL}_n(\mathbb{Q}) \bigr]$. There are now four different 
  multiplication operations involved in this definition, so the 
  computer would have a lot to choose from if we didn't tell it which 
  one of these we mean in each case.
\end{example}

In ordinary mathematical writing the structure name 
is usually omitted\Ldash e.g.~when each particular argument only 
involves one multiplication operation anyway\Rdash but in higher 
algebra the normal state of affairs is rather than there are 
several multiplication operations that have to be distinguished. 
A system for algebraic computation must deal with e.g.~the fact 
that the multiplication in a semigroup algebra is defined in 
terms of the multiplications of the underlying semigroup and 
coefficient ring.

\begin{policy}
  There are no ``blessed'' structures, only standard implementations 
  provided for convenience, and anyone is free to provide 
  alternatives. Constructions should not rely on details of a 
  structure that are not publicly declared through an interface.
\end{policy}

This is part of the \emph{openness} goal. Policy~\ref{Pol:Strukturer} 
relates more to the goal of managing many levels of abstraction, 
since the very act of relying on declared interfaces implies that 
all lower levels are ignored. Portability and ease of programming is 
the subject of the next policy.


\begin{policy} \label{Policy:Tcl}
  The main computing environment shall be a \Tcl~(Tool Command 
  Language) interpreter.
\end{policy}

Formally, the \emph{main computing environment} is merely that in 
which independent pieces of code is combined. It \emph{may} be 
thought of strictly as a generic dispatch mechanism (that just happens 
to contain a complete programming language too) for interfacing with 
other people's code (possibly written in some quite different language 
than what you're using), but you may also find that it serves your 
actual computing needs quite well.

\Tcl\ is both syntactically and semantically an extremely simple 
language\Ldash yet expressive and highly flexible\Rdash which makes 
it easy to learn. Unlike the majority of contemporary programming 
languages, the syntax of \Tcl\ is not descendant from that of 
traditional mathematical formulae (hence it will probably seem 
unfamiliar the first time it is encountered), but when it comes to 
programming this is mostly an improvement; the syntax of mathematical 
formulae is actually very complicated and it is often a matter of 
convention rather than grammar how a nontrivial formula like $\sin 
2x$ or $\sin 2\ln x$ should be understood. In addition to this 
simplicity, the \Tcl\ syntax also provides an elegant solution to 
the problem of distinguishing between several similarly-named 
operations that can be a major headache when describing complex 
algebraic constructions.


%     
% \begin{itemize}
%     
%   \item
%     
%     
%     
%     
%     ---
%     
%     
%     
%   \item
%     The system should \emph{not} employ a type system to interpret 
%     operations. Instead, it is required that every operation is fully 
%     identified independently of the data it is to operate on.
%     
%     The main use for type systems in computer languages has been to 
%     reserve memory for data storage, but modern high level languages 
%     generally allocate memory dynamically when needed, freeing the 
%     programmer from having to manage allocation explicitly. 
%     A secondary use for a type system that has grown more common in 
%     the last decades is to resolve overloaded (polymorphic) 
%     operations, where the same symbol is used for several operations 
%     and the language environment picks one whose type-labelling 
%     matches that of the operands. It is primarily the latter practice 
%     that this decision rejects.
%     
%     The runtime rationale for this decision is that type-controlled 
%     polymorphism inserts an impractical detour into the very heart of 
%     the computing environment. The programmer implementing an 
%     algorithm always knows \emph{exactly} (up to parameters defining 
%     the context for the computation) which operation is intended at 
%     every point in the program, and this is also what the computer 
%     needs to know to execute the program. 
%     Relying upon type-controlled polymorphism when instructing the 
%     computer will however mean that a lot of this information is 
%     omitted or provided only indirectly, which requires constant 
%     detours into type-matching to resolve the ambiguity created by 
%     the overloading.
%     
%     The coding time rationale is that the system becomes much simpler 
%     if the administrative overhead of assigning formalised types to 
%     everything can be dropped. There is however also a coding time 
%     cost in that polymorphism is often exploited to produce more 
%     compact source code; the explicit identification of operations 
%     must not become tedious.
% \end{itemize}


\section{Interpreting interface specifications}

This section explains how to interpret the various specifications of 
interfaces that make up a significant part of the \mtl\ 
infrastructure.
Here is an example of an interface specification (recall that a 
\emph{magma} is an algebraic structure with a binary multiplication 
operation, which is not required to be associative or anything like 
that):
\begin{quote}
  \small\leavevmode
  \begin{APIspec}{division}{1.0}
    The |division| interface specifies the existence of a binary 
    division operation |/| that is an inverse of |*|. The quotient 
    need not be defined for all pairs of elements. It probably makes 
    more sense if |*| is at least associative, but is perfectly 
    possible to define even in other situations.
    \begin{APIdescription}{magma}
      \begin{APImethod}{=}
        \word{element} \word{element}
      \end{APImethod}
        The |=| method must satisfy \APIref+{equality}{1.0}.
      \begin{APImethod}{*}
        \word{element} \word{element}
      \end{APImethod}
        The |*| method returns an element.
      \begin{APImethod}{/}
        \word{element} \word{element}
      \end{APImethod}
        This method may throw an error, but if
        \begin{displaysyntax}
          [$M$ / $a$ $b$]
        \end{displaysyntax}
        for elements $a$ and $b$ of a \meta{magma} $M$ returns $x$ 
        then that $x$ must be an element such that the two expressions
        \begin{displaysyntax}
          [$M$ * $b$ $x$]\par
          $a$
        \end{displaysyntax}
        are |=|-equal.
        
        \begin{remark}
          In terms of a multiplicative inverse, this defines $a/b$ 
          to be $b^{-1}a$, i.e., it is a \emph{left} division. This 
          may seem unintuitive, but it makes it possible to have 
          \(a/(bc) = (a/b)/c\). Right division would have \(a/(bc) = 
          (a/c)/b\).
        \end{remark}
        
        If this method throws an error, then it should set the 
        |-errorcode| to one of the following lists:
        \begin{displaysyntax}
          API division nosolution\par
          API division unimplemented
        \end{displaysyntax}
        Use of the |nosolution| form signals that there really isn't 
        any solution $x$ to \(bx=a\). Use of the |unimplemented| form 
        merely means that division has not been implemented for these 
        arguments (e.g.~a ring of polynomials might have division 
        implemented only for monomial denominators), in which case 
        the error does not imply nonexistence of a solution.
    \end{APIdescription}
    
    Note that |/| is not required to be congruent. This is 
    because the \texttt{division} interface does not require the 
    equation \(bx=a\) to have a unique solution, and 
    ensuring that the choice of solution is independent of 
    argument representation could well be unreasonably expensive. 
  \end{APIspec}
\end{quote}
The name and version number in the left margin marks where the formal 
specification begins. The triangle marks where it ends (compare 
\qedsymbol\ in proofs).


\subsection{Pseudocode formulae}

For many mathematical structures, it is appropriate for 
specifications to spell out the axioms that the primitive concepts of 
such structures must obey. However, since the main computing environment 
by Policy~\ref{Policy:Tcl} is a \Tcl\ interpreter, it follows that the 
only syntax for these concepts that is guaranteed to be formally defined 
is that which is exposed in this environment; more traditional 
mathematical syntaxes usually exist, but it is hard for a 
specification to rely on them. 
Therefore the axioms will generally have to be expressed using 
\emph{pseudocode formulae}, which mix traditional mathematical 
notation with some basics of \Tcl\ syntax.

The pseudocode formula syntax is essentially given by the following 
rules:
\begin{displaysyntax}
  \(\meta{formula} \longrightarrow \meta{mathematical formula} \mid 
  {}\)[\meta{sentence}]\par
  \(\meta{sentence} \longrightarrow \meta{word} \mid
  \meta{sentence}\meta{whitespace}\meta{word}\)\par
  \(\meta{word} \longrightarrow \meta{literal} \mid \meta{formula}\)
\end{displaysyntax}
Here, a \meta{sentence} is the syntactical unit corresponding to a 
\Tcl\ command call, and the brackets signal that we want to make use 
of the value returned by that call. A typical example of how such a 
\meta{formula} might look is
\begin{displaysyntax}
  [$G$ * [$G$ * $a$ $b$] $c$]
\end{displaysyntax}
where `$G$', `$a$', `$b$', and `$c$' are \meta{mathematical formula}s 
while `\texttt{*}' is a \meta{literal}; literals will be written in 
\texttt{typewriter} font.

A `\texttt{[}\meta{sentence}\texttt{]}' formula is evaluated as 
follows. First the individual \meta{word}s are evaluated, and a list 
of their values is constructed. Second, the value of the first word 
is interpreted as a \emph{command name}, and the corresponding 
command implementation is looked up. Third, the list of values is 
passed on to that command, to be interpreted in whatever way it sees 
fit, and the return value of that call is taken as the value of the 
formula as a whole. In other words, sentence formulae will formally 
be in \emph{prefix notation}; the value of a formula `\texttt{[f $x$ 
[g $y$] $z$]}' is $f(x,g(y),z)$ if $f$ and $g$ are the implementations 
of the commands named `\texttt{f}' and `\texttt{g}' respectively. 
The very simple syntax does however leave plenty of room in practice 
for deviations from this prefix notation, where the programmer deems 
that they are appropriate.

The trick is that every command is free to interpret its arguments in 
whatever way it wants; in particular it may expect one or several 
arguments to be \meta{literal}s that control what will be done to 
remaining arguments. The most important use of this 
possibility is the \emph{object command pattern},\footnote{
  So called because it is in \Tcl\ the traditional form of method 
  calls in object-oriented (OO) programming systems: each object is 
  a separate command that has the methods as subcommands. Different 
  methods of a single object may have wildly different syntaxes, but 
  methods of the same name for different objects of the same class 
  will normally have exactly the same syntax.
} where the actual 
command name is not explicit in the code (it is rather kept in a 
variable or function parameter) but the \emph{second} word is a 
literal name of a \emph{subcommand}; it is known that the primary 
command will perform a new round of dispatch based on its subcommand 
argument. Thus, in the example above, `$G$' is to be thought of as 
such an ``object command'' for a mathematical structure, while 
`\texttt{*}' is a subcommand name. Indeed, if $G$ is a group and 
\texttt{*} the group operation then the example above is the left 
hand side of the associativity axiom \((ab)c = a(bc)\), or \((a 
*_G\nobreak b) *_G c = a *_G (b *_G\nobreak c)\) if the operation 
symbol and dependence on the structure cannot be elided. In 
comparison to the latter, the pseudocode formula counterpart
\begin{displaysyntax}
  [$G$ * [$G$ * $a$ $b$] $c$] ${}={}$ [$G$ * $a$ [$G$ * $b$ $c$]]
\end{displaysyntax}
isn't too onerous---especially for formulae involving things that are 
not merely the associate binary operations for which traditional 
mathematical notation has been optimised.

One reservation one can have regarding the formula above is however 
that the equality relation `$=$' itself is one of the things that 
depend on the structure\Ldash indeed, a perfectly sensible 
implementation of many quotient structures is to have everything the 
same as in the numerator structure, except that the equality relation 
considers more things to be equal\Rdash and therefore the claim 
should rather be that
\begin{displaysyntax}
  [$G$ = [$G$ * [$G$ * $a$ $b$] $c$] [$G$ * $a$ [$G$ * $b$ $c$]]]
\end{displaysyntax}
has the value true for all $G$-elements $a$, $b$, and $c$. This is 
also what needs to be done when specifying more unusual structures, 
but for ordinary structures with equality the following intermediate 
formulation (of \(aa^{-1} = a^{-1}a = 1\)) is convenient:
\begin{quote}
  For all \(a \in G\), the three expressions
  \begin{displaysyntax}
    [$G$ * $a$ [$G$ inv $a$]]\par
    [$G$ * [$G$ inv $a$] $a$]\par
    [$G$ 1]
  \end{displaysyntax}
  are |=|-equal.
\end{quote}
The formal interpretation of this would be: \texttt{[$G$ = $x$ $y$]} 
must return true when given as $x$ and $y$ any two of those three 
expressions.


\subsection{Command syntax specifications}

Besides the axioms characterising a mathematical structure, it is 
also necessary for an interface specification to detail the syntax 
of each subcommand. In principle this can of course be done using BNF 
rules for \meta{syntax elements} as above, but two extensions of this 
formalism turn out to be very useful, to the point that almost all 
syntaxes one needs to specify can be handled without any 
$\longrightarrow$ rules at all.

The first extension stems from the fact that all a \Tcl\ command gets 
to see is a list of words (or rather the values these words evaluate 
to)\Dash hence it is preferable to point out when an element makes up 
exactly one word. This is done by changing the angle brackets around 
an \meta{element} to braces, like so: \word{element}. This makes it 
totally clear that the |foo| command with syntax
\begin{displaysyntax}
  foo \word{bar} \word{baz}
\end{displaysyntax}
has exactly two arguments.
Because of this, the basic \meta{foo} kind of syntax element is most 
commonly used when the element is a list of items that are going to 
be inserted into the sentence as one word per item. It is however 
also used for used for syntax elements that may only constitute part 
of a word, such as the \meta{unsigned integer}s of 
Subsection~\ref{Ssec:InterfaceVersion} below.

The second extension is that made in EBNF~\cite{EBNF-RFC}, namely 
that one may use the repetition and grouping constructions of 
regular expressions within a syntax description. Hence
\begin{longtable}{l@{ means }p{0.6\linewidth}}
  \word{term}\regstar& zero or more \word{term}s,\\
  \word{term}\regplus& one or more \word{term}s,\\
  \word{term}\regopt& zero or one \word{term},\\
  \word{foo} \begin{regblock} \word{bar}\regalt \word{baz} 
    \end{regblock}& 
    a \word{foo} followed by a \word{bar} or a \word{baz},\\
  \begin{regblock}[\regstar] \word{key} \word{value} \end{regblock}&
    an even number (which may be zero) of elements, which 
    alternatingly are \word{key}s and \word{value}s, beginning with a 
    \word{key},
\end{longtable}\noindent
and so on. The \regstar, \regplus, and \regopt\ in particular often 
come in handy to clarify whether an operation is binary, unary, or 
variadic.


\subsection{Lists in pseudocode formulae}

The 


% $^{\splode} L + {}^{\splode}\!L + {\splode} + \hbox{|{*}|} L$
% 
% $^{\circledast} L + {}^{\circledast}\!L + 
% {}^{\circledast}\!\!L + {\circledast} L$

% \begin{displaysyntax}
%   [$M$ + [$M$ + \splode$L_1$] [$M$ + \splode$L_2$]]\par
%   [$M$ + \splode$L_1$ \splode$L_2$]
% \end{displaysyntax}
% \begin{displaysyntax}
%   [$M$ + [$M$ + \tsplode$L_1$] [$M$ + \tsplode$L_2$]]\par
%   [$M$ + \tsplode$L_1$ \tsplode$L_2$]
% \end{displaysyntax}

---


\subsection{Interface names and versions}
\label{Ssec:InterfaceVersion}

An important aspect of the \mtl\ system is that the information of 
which interfaces are supported by a structure should be available at 
runtime, for other structures to query and act upon. This is done 
using the \emph{API convention}, according to which every structure 
should have a method |API| with the following three forms:
\begin{displaysyntax}
  \meta{structure} API \word{interface} \word{version}\par
  \meta{structure} API \word{interface}\par
  \meta{structure} API
\end{displaysyntax}
In these calls, the \word{interface} is the name of the interface and 
the \word{version} is a version number such as \texttt{1.0} or 
\texttt{2.3.1}. Formally, the \word{interface} can be an arbitrary 
string and the \word{version} is defined by the rules
\begin{displaysyntax}
  \meta{version} $\longrightarrow$ \meta{unsigned integer}\relax
    \begin{regblock}[\regstar] .\meta{unsigned integer} \end{regblock}
    \par
  \meta{unsigned integer} $\longrightarrow$ 0 $\bigm\vert$ 
    \meta{digit 1--9}\meta{digit}\regstar\par
  \meta{digit} $\longrightarrow$ 0 $\vert$ 1 $\vert$ 2 $\vert$ 3 
    $\vert$ 4 $\vert$ 5 $\vert$ 6 $\vert$ 7 $\vert$ 8 $\vert$ 9\par
  \meta{digit 1--9} $\longrightarrow$ 1 $\vert$ 2 $\vert$ 3 
    $\vert$ 4 $\vert$ 5 $\vert$ 6 $\vert$ 7 $\vert$ 8 $\vert$ 9
\end{displaysyntax}
The most important form of the |API| method is the first, since it 
constitutes the query ``does \meta{structure} support version 
\meta{version} of \word{interface}''; the return value is a boolean. 
When the result is true, the user knows that this structure lives up 
to what is specified in that version of the interface.

The idea of the version numbers is that interface specifications, like 
standards in general, may evolve over time and that later versions 
are better (for example from a usability perspective) than earlier 
versions; hence it is desirable to support as high a version number 
as possible. On the other hand, it is usually easier to implement 
lower versions of an interface since these make fewer claims that the 
implementation needs to satisfy. That \mtl\ interfaces are more or less 
\emph{theories} in the sense of mathematical logic implies that they 
evolve in a slightly different manner than for example software 
packages do.

The first \meta{unsigned integer} of a \word{version} is called the 
\emph{major version number}, whereas the remaining are collectively 
known as \emph{minor version numbers}. Within a series of versions 
with the same major version number, later versions are 
specialisations of earlier versions, meaning any axiom claimed by the 
earlier version must hold also in the later version. Versions with 
different major numbers are however formally as independent as 
interfaces with different names; a jump to a new major number signals 
a fresh start, sometimes because of taking a completely different 
view of the subject (e.g.~starting from a different set of primitive 
concepts), but other times because the previous specification turned 
out to have botched some technical detail and thereby became less 
useful than what was intended.

Taking the above specification of \texttt{division} as an example, 
one could (especially in view of the \emph{remark}) imagine that there 
had been some version~0.0 of this interface according to which |/| 
would instead do right division, but that this got deprecated because 
in a \texttt{group} $G$ it would unintuitively imply that 
\texttt{[$G$ / $a$ [$G$ * $b$ $c$]]} is equal to 
\texttt{[$G$ / [$G$ / $a$ $c$] $b$]}. (There wasn't such a version, 
but there could have been.) Bumping the major version number up to~1 
would then be the way to start anew. Structures where |*| is 
commutative could actually claim to support both versions, but 
noncommutative ones would have to choose on or the other.

For minor version numbers, one could imagine a \texttt{division}~1.1 
where the syntax of |/| was generalised to
\begin{displaysyntax}
  \meta{magma} / \word{numerator} \word{denominator}\regplus
\end{displaysyntax}
This should then be combined with an axiom that serves as a 
definition of this extended division operation. One possibility is to 
say that
\begin{displaysyntax}
  [$M$ / $a$ $b$ \splode$C$]\par
  [$M$ / [$M$ / $a$ $b$] \splode$C$]
\end{displaysyntax}
are |=|-equal for all \(a,b \in M\) and nonempty lists $C$ of 
elements of $M$, but this has the disadvantage to enforcing an 
algorithm for computing the multiple-argument form of |/|. A 
different approach is to say that if \(x \in M\) is the value of
\begin{displaysyntax}
  [$M$ / $a$ $b_1$ \dots $b_n$]
\end{displaysyntax}
then
\begin{displaysyntax}
  [$M$ * $b_1$ [$\dots$ [$M$ * $b_n$ $x$]$\dots$]]
\end{displaysyntax}
is |=|-equal to $a$.


% \subsection{A \Tcl\ primer}
% 
% Informally, a \Tcl\ program (or \emph{script}) is a sequence of 
% \emph{command sentences}\Ldash typically one per line, although there 
% is variance in both directions\Dash and a sentence consists of 
% \emph{words} which are separated by whitespace. The style of these 
% sentences can range from the cryptic:
% \begin{quote}
%   |while {$b} {set b [expr {$a % [set a $b]}]}|
% \end{quote}
% via shell-like:
% \begin{quote}
%   |fconfigure $socket -encoding utf-8 -eofchar "\x19"|
% \end{quote}
% to almost pseudocode:
% \begin{quote}
%   |pick z maximizing realpart from points|
% \end{quote}
% but as far as the language is concerned, all of these are merely 
% lists of words, the first of which is the name of a command. Beyond 
% that, it is up to that command to interpret and use the remaining 
% words as it sees fit. This allows e.g.~`|*|' to be both a binary 
% infix operation (times) in numeric expressions and a unary postfix 
% operation (zero or more) in regular expressions; neither is part of 
% the overall language syntax, so it is entirely up to the command 
% whether to make such an interpretation of the `|*|' character. 
% \Tcl\ was designed to \emph{not get in the way} of programmers 
% needing to express some domain-specific concept, and will happily 
% allow several ``little languages'' (of which numerical expressions 
% and regexps are two built-in examples) to coexist within a single 
% interpreter.
% 
% What the language syntax \emph{does} control is how a script is split 
% up into sentences, how these are split up into words, and what the 
% contents of these words will be. Within each sentence, there are 
% three interacting processes: grouping, substitution, and expansion.
% 
% \emph{Grouping} collects text into a word, even if it contains whitespace 
% characters which would otherwise act as word or sentence separators. 
% The characters which can trigger grouping are `|"|', `|{|', and 
% `|}|', and they appear as delimiters at the beginning and end of the 
% word, with the contents of the word consisting of all characters in 
% between. A word begun by a quote ends with the next quote (that has 
% not been escaped), whereas a word begun by a left brace ends at the 
% matching right brace; the contents of a brace-delimited word have to 
% be balanced with respect to (unescaped) left and right braces. In 
% practice, quotes are often used to delimit ``ordinary'' strings, 
% whereas braces are used to delimit blocks of code or data, but once a 
% word has been parsed, it will have no memory of whether it was 
% quote-, brace-, or just plain whitespace-delimited.
% 
% The difference between the two lies instead in their relation to 
% \emph{substitution}, which is inhibited in brace-delimited words but 
% carried out otherwise. The three types of substitution are:
% \begin{description}
%   \item[Variable substitution,]
%     which is triggered by the dollar sign `|$|'.
%     , which should be 
%     followed by the name of a variable. 
% \end{description}
% 
% ---
% 
% syntactically a sequence of 
% \emph{command sentences} and comments, separated by newlines. Each 
% sentence is a sequence of \emph{words}, separated by whitespace 
% (typically one or several spaces, but tabs are fine too). Words can 
% be arbitrary strings. Semantically, the first word of each sentence 
% is interpreted as the name of the command to execute, whereas the 
% other words are passed to that command as arguments to interpret 
% and process in whatever way it sees fit. Each command produces 
% a result, and the result of the last command it the result of the 
% script as a whole.
% 
% What makes this a Turing-complete programming language is that there 
% are commands for all the usual elementary operations\Dash in 
% particular there are commands for the basic control structures. 
% Unbounded repetition can for example be achieved through the |while| 
% command, which has the syntax
% \begin{displaysyntax}
%   while \word{expression} \word{script}
% \end{displaysyntax}
% When this command is executed\Ldash or \emph{evaluated}, as is the 
% official term in \Tcl\Rdash the \word{expression} and \word{script} 
% are alternatingly evaluated, with the command completing as soon as 
% the \word{expression} value is not boolean true. Other control 
% structures available as core commands include |if|~(if--then--else 
% choice), |for|~(loop with control variable), |foreach|~(loop over 
% list elements), |switch|~(multiway choice), |break|~(loop abortion), 
% and |proc|~(subroutine creation).
% For such \word{script} arguments to be interesting, it must however 
% be possible to embed newlines and spaces in it (since otherwise the 
% \word{script} above would only be a single sentence of one word). 
% To that end, there are three mechanisms which change the words of a 
% command sentence en route from script-string to sequence of words: 
% quoting, substitution, and expansion.
% 
% Quoting collects a piece of text into one word, overriding characters 
% which would otherwise force a word or sentence boundary. The most 
% important form of quoting is brace-quoting, which happens for words 
% where the first character is `|{|' (left brace), the last character 
% is `|}|', and the material between them is balanced with respect to 
% braces;\footnote{
%   Braces preceeded by a backslash don't count when balancing however, 
%   so you can get an unmatched brace if you need to. Even though the 
%   technical details are quite different, the net effect is 
%   very similar to that in \TeX\ where \cs{\{} and \cs{\}} don't 
%   count as braces that have to be balanced.
% } in this case the command argument becomes exactly the string 
% of characters between the outermost braces. This is the main 
% mechanism for nesting ``blocks'' of \Tcl\ code, since it inhibits 
% substitution in ``inner'' commands.
% 
% Substitution replaces a piece of text\Ldash often, but not always, an 
% entire word\Rdash by something else. There are three types of 
% substitution, which differ in where they get the replacement text 
% from and which character triggers them.
% \begin{description}
%   \item[Command substitution]
%     uses the return value of a script. It is triggered by a left 
%     bracket |[| and the script to evaluate is terminated by the 
%     matching right bracket |]|. This mechanism corresponds to 
%     function calls in most other languages, although the syntax is 
%     not the conventional
%     \begin{equation}
%       f(x_1,x_2,x_3,\dotsc,x_n)
%     \end{equation}
%     but rather
%     \begin{displaysyntax}
%       [f $x_1$ $x_2$ $x_3$ $\dots$ $x_n$]
%     \end{displaysyntax}
%     (Putting the ``function name'' inside the bracket with the 
%     arguments may seem odd, but we shall see that it is rather 
%     useful.) An extreme application of command substitution is the 
%     one-liner
%     \begin{quote}
%       |puts [join [lsort [split [read stdin] \n]] \n]|
%     \end{quote}
%     which works similarly to the Unix standard utility |sort|: |read|s 
%     standard in, |split|s it into a list of lines, sorts this list 
%     (|lsort|), |join|s the list back into a string, and out|puts| the 
%     result to standard out.
%     
%   \item[Backslash substitution]
%     is triggered by a backslash `|\|' and functions very much as in 
%     strings in the C~language: as a mechanism for escaping special 
%     interpretations of characters, and as a mechanism for expressing 
%     arbitrary characters using only those found in ``visible ASCII''. 
%     The |\n| above will thus be seen as a linefeed character by 
%     |join| and |split|, whereas any character with special syntactic 
%     meaning in \Tcl\ (backslash `|\|', dollar `|$|', braces `|{|' and 
%     `|}|', brackets `|[|' and `|]|', number sign `|#|', semicolon 
%     `|;|', and the various forms of whitespace\Dash \emph{that's the 
%     entire list!}) can be escaped into an ordinary character by 
%     prepending a backslash. The combination backslash--newline is a 
%     special case in that it counts as an unescaped space rather than 
%     as a newline character, but this makes it convenient to express 
%     sentences with too many words to fit on one line: 
%     
%     ---
%   
%   \item[Variable substitution]
%     uses the value of a variable. It is triggered by the |$| 
%     character, which is followed by the name of the variable to 
%     substitute.
%     
% \end{description}
% It should be observed that replacement text ``inserted'' by a 
% substitution will be passed on verbatim to the command; it will in 
% particular not be subjected to another round of substitution, even if 
% it contains backslashes, dollars, or brackets. Nor does whitespace in 
% substituted material count as word or sentence separators; if 
% something looks as one word before substitution, then it will 
% count as one word in the command sentence no matter what is 
% substituted.
% 
% 
% 
% 
% 
% ---


\section{Basic notions}

A structure is supposed to be more or less the kind of things that 
universal algebra are about, although the need to make it work in 
practice rather than just in theory means some classical tricks to 
simplify the theoretical framework cannot be used. As a particular 
example, modules are in universal algebra often regarded as an 
algebra with one unary operation for every element of the thing 
acting on the module, which leads to huge (often infinite) axiom 
systems but makes it possible to keep the theory single-sorted. A 
more pragmatic approach will have to face up with the fact that many 
algebraic structures have several sorts of elements.\footnote{\relax
  Even though it is sometimes possible to ``hide'' all but the main 
  set of elements in ``helper'' structures.
} Another example is that in theoretical constructions it is often 
sufficient to know equality (or congruence, depending on how one 
looks at it) as an implicit relation (give me two elements and I can 
tell you whether they are equal), but in practice it may be much 
more useful to provide a function that computes a canonical form 
for every element is given.


\subsection{Types and encodings}

\Tcl\ has the basic principle that any value is 
\emph{formally} a string of (Unicode) characters\Ldash which from a 
foundational mathematical point of view is very sound, as it admits 
direct translation to several fundamental models for computation\Dash 
although internally the usual assortment of implementation tricks 
(such as machine-native number representations where possible) are 
employed to speed up processing (and in some cases reduce memory use). 
A consequence of this principle is that \Tcl\ is mostly a typeless 
language (or if you prefer, language with exactly one type). This may 
seem strange if one is used to classical programming languages, but 
one should keep in mind that the main reason variables are typed in 
languages such as Fortran, Pascal, and C is that different types of 
data require different amounts of memory. More modern, higher level 
programming languages such as Tcl manage memory allocation implicitly 
and dynamically, so there is no need for the programmer to bother 
with the minutae of this.

Another, more conceptual application of types in many modern 
programming languages is for selecting definition of a polymorphic 
operation; practically the same token is used as name of several 
different operations, and the types (which in some cases are 
compile-time properties of variables and in other runtime properties 
of values) of the operation arguments are used to select an exact 
definition. This idea was probably taken from ordinary mathematical 
notation, where it is common that the intended interpretation of an 
operation symbol (or lack thereof, as in $xy$) depends on what the 
operands happen to denote; $G-u$ means one thing if $G$ and $u$ are 
numbers, another thing if they are vectors, and something very 
different if $G$ is a graph and $u$ is a vertex in $G$. While this 
is absolutely standard, one should nonetheless observe that it really 
is a shorthand notation; the standard formalisation of mathematics in 
mathematical logic requires that operation with different definitions 
are given distinct names. In particular the distinction between 
`element' and `set' used to justify shorthands such as $f(S)$ for 
$\left\{ f(x) \bigm\vert x \in S\right\}$ when $S$ is a set break 
down when it is taken into account that mathematics is constructed on 
top of set theory, since \emph{everything} is a set\footnote{Or in 
some axiomatisations: a class; the same argument applies for all 
kinds of collections.} in standard set theory. 

---


; the closest equivalent of `type' that one finds is 
`set of values (strings) which are valid in a particular circumstance 
(for example, constitute valid input to a particular command)', and 
as it happens that is very much the case also in mathematics.

Ultimately, what one deals with is always \emph{encodings} in computer 
memory of mathematical elements rather than the elements 
themselves. 


\begin{definition}
  A structure is said to be \defining{single-sorted} if it has one sort 
  of elements (all elements are syntactically equivalent) and 
  \defining{multiple-sorted} otherwise. A structure is 
  \defining{principal} if it is single-sorted or multiple-sorted but 
  comes with a distinguished sort of element (the \defining{principal} 
  sort). The \defining{principal set of elements} of a structure is 
  the set of elements of the principal sort.
\end{definition}


\subsection{Implementations and constructors}

There are typically (at least) two \Tcl\ commands associated with each 
structure. One provides the structure \emph{implementation}, in that 
it is the underlying command of the command prefix representing the 
structure. The other command constructs such command prefixes, and is 
therefore called a \emph{constructor}. It is sometimes possible for 
several constructors to make use of the same implementation, but 
perhaps more common that one constructor chooses one of several 
implementations\Dash usually the most specialised that will be 
applicable, since that would probably provide the most features and 
take advantage of the maximal number of optimisations.
Implementation commands need not be part of the documented interface 
of a package, since it is sufficient that some constructor ``knows'' 
its name, but it may at times be appropriate to support users calling 
the implementation command directly.

\begin{example}[Integers]
  The |mtmtcl::rings::integers::all| command is an implementation of 
  the ring of integers $\mathbb{Z}$, and it is documented that users 
  may call this command directly. A constructor companion 
  |mtmtcl::rings::integers::make| is provided, but the main 
  reason for using it would be that it returns the fully qualified 
  name of the implementation; there is no shame in inlining what is 
  returned instead of calling this.
\end{example}

\begin{example}[Integers modulo $n$]
  The |mtmtcl::rings::integers::modulo| command is an implementation 
  of the ring of integers-modulo-$n$ $\mathbb{Z}_n$. While it is 
  documented that this command has the call syntax
  \begin{displaysyntax}
    mtmtcl::rings::integers::modulo \word{n} \word{API} 
    \word{subcommand} \word{argument}\regstar
  \end{displaysyntax}
  (where the first three words make up the \meta{structure}), the 
  preferred usage is rather via the constructor command
  \begin{displaysyntax}
    |mtmtcl::rings::integers::make_modulo| \word{n}
  \end{displaysyntax}
  since computing the \word{API} parameter is rather technical. The 
  reason for still documenting the implementation command is that it 
  can be useful for other constructors. In particular, a constructor 
  for finite fields can use |modulo| directly for fields of prime 
  order, but must resort to something more complicated for other 
  finite fields.
\end{example}



---

It seems useful to make a distinction between \emph{adapters} (for 
run-time adaptation, sitting between the caller and the actual 
implementation) and \emph{adaptors} (for define-time adaptation, 
defining a new command which does not itself call the adaptor).


\subsection{Combining interfaces}

It often feels natural to say things like ``if this structure 
satisfies interface $Y$ in addition to interface $X$ then it must 
also be the case that \dots'' The problem with this is that it would 
then not be safe to declare that a structure satisfies interface $Y$ 
(for example as a consequence of an adaptation) unless one can vouch 
also for all possible combination implications of that interface 
with other interfaces on that structure, the set of which can grow 
after the adaptor gets implemented. The implication would thus be 
that an adaptor has to throw away all interfaces it doesn't know 
about, which would be somewhat counterproductive.

Therefore the rule is that properties of an interface may not be 
conditionalised on other interfaces; each interface makes its claims 
on its own. Interfaces may extend other interfaces, but then there is 
a direct implication. If the natural combination of two interfaces is 
slightly stronger than the logical conjunction of the two (e.g.~field 
and totally ordered set), then that should be handled by making the 
combination a third interface (e.g.~ordered field) which implies the 
first two.


---


\subsection{Concrete and abstract data}

The interfaces mostly deal with \emph{abstract} data, i.e., it does 
not specify how the data is to be encoded. This is generally because 
the interface may productively be applied to mathematical objects 
well beyond the interface author's imagination; when even the 
basic information that needs to be encoded is unknown, there 
obviously wouldn't be any point in trying to prescribe an encoding 
for it. There are however also data involved in the interfaces that 
are quite concretely known, and for that it seems appropriate to lay 
down standard encodings.

\paragraph{Booleans}
A boolean is true or false. In \Tcl\ the canonical representations 
for these are |1| and |0| respectively, but any nonzero integer is 
accepted as true, and several strings (|on|, |off|, |yes|, |no|, 
|true|, and |false|) are accepted as boolean values. In \mtl, 
anything \Cfunctionidentifier{Tcl\_GetBooleanFromObj} accepts as boolean 
is a valid boolean.

\paragraph{Integers}
Any string matching the regular expression \verb"0|-?[1-9][0-9]*" is 
a valid integer, and two such strings are equal as integers if and 
only if they are equal as strings. (Hence these are \emph{proper} 
integers, not machine-integers.) These are the canonical 
representations of integers. There are also some valid noncanonical 
representations, e.g.~hexadecimal notation as strings matching 
|-?0x[0-9A-Fa-f]+|, and octal notation.

\paragraph{Permutations}
A permutation $\sigma$ is typically regarded as a bijection from 
$\{0,1,\dotsc, n-\nobreak1\}$ to itself. It is encoded as a list of 
$n$ elements, where the element at index $i$ is the value of 
$\sigma(i)$.

\paragraph{Data-tree}
A \emph{data-tree} is effectively the type of data structure that 
XML encodes: a rooted tree where the nodes carry a type-tag and 
optionally attributes, the children of a node are ordered, and (as a 
special case) strings may appear as children of a node. The encoding 
of these follow the \textsf{tdom} ``list'' format for XML nodes, 
i.e., a data-tree is either (i)~a three element list
\begin{quote}
  \word{tag} \word{attributes} \word{children}
\end{quote}
where \word{tag} is a string (which must be a valid XML name), 
\word{attributes} is a dictionary (mapping attribute name to value), 
and \word{children} is a list of data-trees, or a data-tree is (ii)~a 
two element list
\begin{quote}
  |#text| \word{string}
\end{quote}
encoding the explicit string \word{string}.

Note that all \word{string}s and attribute values are \Tcl\ strings, 
not XML encodings of such strings. This means the amperand character 
is really `|&|', not `|&amp;|'. Also note that |#text| is not a valid 
\word{tag}, since `|#|' is not allowed in XML names. This implies 
that \textbf{data-trees can be processed directly using the 
data-is-code technique}.


\DocInclude{support}
\DocInclude{groups}
\DocInclude{rings}
\DocInclude{export}

\PrintIndex

\end{document}




\endinput

---


As a particular example, one may consider polynomials. The standard 
library naturally contains a construction of polynomials over 
(i.e., with coefficients from) an arbitrary ring $\mathcal{R}$; the 
result of that construction being the polynomial ring $\mathcal{R}[X]$. 
However, a semiring enthu


This makes 
\mtl\ different from many computer algebra systems, where the things 
built in tend to be special (e.g.~$2+2$ is always $4$, never $1$ as in 
$\mathbb{Z}_3$). Integers are certainly fun, but there is nothing 
about 


---


A construction of polynomials over something at least requires the 
underlying structure of scalars to be a ring,\footnote{Semiring 
enthusiasts may at this point object that a semiring, such as for 
example the natural numbers $\mathbb{N}$, is sufficient, and this is 
true. However it is not practically possible to always offer the most 
general construction of everything, so in reality there will likely be 
a standard ``polynomial over'' construction that starts with a ring 
$\mathcal{R}$ and produces some ring $\mathcal{R}[X]$. There is no 
restriction or disadvantage in this, as long as anyone can also 
implement and use an alternative semiring-aware construction of 
polynomials.}  and 

The only 
thing common to all structure objects is the way in which they can be 
queried which interfaces they support.


---

