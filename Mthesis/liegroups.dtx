% 
% \iffalse 
%<*driver>
\documentclass{mtmtcl}
\usepackage{amsmath,amssymb,amsfonts}
\begin{document}
\DocInput{liegroups.dtx}
\PrintIndex
\end{document}
%</driver>
% \fi
% 
% \tableofcontents
% 
% 
% \section{Interfaces}
% 
% A Lie group is a pretty complicated structure, on account of 
% (i)~being a group, (ii)~being a manifold, and (iii)~having a 
% corresponding Lie algebra. The following is an attempt to provide 
% a interfaces for all that.
% 
% \begin{APIspec}{manifold}{1.0}
%   A \emph{manifold}, as defined in differential geometry, is a 
%   topological space with locally valid coordinate systems; these 
%   coordinate systems are called \emph{charts}. The rules are 
%   basically that every point must be covered by at least one chart, 
%   and two charts which overlap must be compatible (even if they can 
%   view the common domain quite differently).
%   
%   As an API, a manifold operates with three types of object: 
%   \emph{points} (which are the elements of the manifold-as-set), 
%   \emph{coordinates} (which would typically be vectors of real or 
%   complex numbers, but it seems unnecessary to require that at this 
%   stage), and the \emph{charts} (which are abstract functions).
%   \begin{APIdescription}{manifold}
%     \begin{APImethod}{=}
%       \word{point} \word{point}
%     \end{APImethod}
%       The |=| method tests whether two points are equal. It 
%       satisfies version~1.0 of the \APIref{equality}{1.0} 
%       interface.
%       
%     \begin{APImethod}{charts}
%       \word{point}\regstar
%     \end{APImethod}
%       The |charts| method returns a list of charts which cover all 
%       of the given \word{point}s.  If exactly one \word{point} is 
%       given, then the result must be nonempty. Calling this method 
%       without any points should return the entire collection of 
%       charts if practical, and at least one chart on each component 
%       of the manifold. The result may depend on the order in which 
%       the \word{point}s are given.
%       
%       The reason for the weak wording in the specification of this 
%       method is that the problem of on-the-fly atlas construction 
%       is rather nontrivial. For a geometrically simple manifold 
%       such as the sphere, it is natural to have an implementation 
%       with an explicitly encoded discrete set of charts, but this 
%       is not at all easy for more complicated manifolds such as the 
%       standard matrix Lie groups. In those cases, it may instead be 
%       natural to have a separate chart for each point, which 
%       renders the atlas effectively infinite.
%       
%     \begin{APImethod}{p2c}
%       \word{chart} \word{point}
%     \end{APImethod}
%       The |p2c| method returns the \word{chart} coordinates for the 
%       \word{point}. If the \word{chart} does not cover this 
%       \word{point}, then an error is thrown.
%       
%     \begin{APImethod}{c2p}
%       \word{chart} \word{coordinate}
%     \end{APImethod}
%       The |c2p| method returns the point whose \word{chart} 
%       coordinates are \word{coordinate}. If \word{coordinate} is 
%       not the \word{chart} coordinate of any point, then an error 
%       is thrown.
%       
%     \begin{APImethod}{coord}
%       \word{method} \word{arg}\regstar
%     \end{APImethod}
%       The |coord| method is used to access the structure for 
%       coordinates. This would typically be a real or complex vector 
%       space.
%   \end{APIdescription}
%   
%   
% \end{APIspec}
% 
% 
% \begin{APIspec}{Lie algebra}{1.0}
%   A \emph{Lie algebra} can be viewed both as an abstract algebraic 
%   and as a differential geometric structure. The original geometric 
%   view is that the elements of a Lie algebra are ``infinitesimal 
%   transformations'', or in more modern terminology \emph{velocities} 
%   within a space of transformations; in particular rotation 
%   velocities naturally live in a Lie algebra, although it is in 
%   elementary contexts unusual to make explicit use of more than the 
%   vector space structure on the velocities. However, this formal 
%   specification rather takes the abstract algebraic view.
%   
%   \begin{APIdescription}{Lie-algebra}
%     \begin{APImethod}{=}
%       \word{element} \word{element}
%     \end{APImethod}
%     \begin{APImethod}{+}
%       \word{element} \word{element}
%     \end{APImethod}
%     \begin{APImethod}{0}
%     \end{APImethod}
%     \begin{APImethod}{neg}
%       \word{element}
%     \end{APImethod}
%     \begin{APImethod}{scalar}
%       \word{submethod} \word{argument}\regstar
%     \end{APImethod}
%     \begin{APImethod}{.}
%       \word{scalar} \word{element}
%     \end{APImethod}
%     \begin{APImethod}{*}
%       \word{element} \word{element}
%     \end{APImethod}
%       These methods satisfy the \APIref+{ring-algebra}{2.0} 
%       interface. Consequently various subsets of them also satisfy 
%       the \APIref+{equality}{1.0}, \APIref+{additive group}{2.0}, 
%       \APIref+{ring-module}{2.1}, and \APIref+{ring}{2.0} interfaces. 
%       
%       In addition, the three expressions
%       \begin{displaysyntax}
%         [$A$ 0]\par
%         [$A$ * $x$ $x$]\par
%         [$A$ + [$A$ * [$A$ * $x$ $y$] $z$] \linebreak[1][$A$ + 
%           [$A$ * [$A$ * $y$ $z$] $x$] [$A$ * [$A$ * $z$ $x$] $y$]]]
%       \end{displaysyntax}
%       are |=|-equal for all elements $x$, $y$, and $z$ of the 
%       \meta{Lie-algebra} $A$.
%   \end{APIdescription}
%   
%   That the first two of these three expressions are equal is the 
%   \emph{anticommutativity axiom} of a Lie algebra. In traditional 
%   notation, where the Lie product |*| of $x$ and $y$ is denoted 
%   $[x,y]$, it amounts to saying \([x,x]=0\) for all \(x \in A\). 
%   The more common form \([y,x] = -[x,y]\) of the anticommutativity 
%   identity follows from this, since by distributivity
%   \begin{multline*}
%     0 =
%     [x+y,x+y] =
%     [x,x] + [x,y] + [y,x] + [y,y] =
%     [x,y] + [y,x] \text{.}
%   \end{multline*}
%   The converse does not hold if $A$~\texttt{scalar} has 
%   characteristic two (i.e., if \texttt{[$A$ neg $z$]} is equal to 
%   $z$ for all \(z \in A\)), so the modern tradition is to use 
%   \([x,x]=0\) as the axiom.
%   
%   That the first and third of the three expressions are equal is 
%   known as the \emph{Jacobi identity}. It could, when 
%   anticommutativity is given, equivalently be replaced by the 
%   \emph{Leibniz identity}
%   \begin{equation*}
%     \bigl[ z, [x,y] \bigr] =
%     \bigl[ [z,x], y \bigr]  + \bigl[ x, [z,y] \bigr] 
%   \end{equation*}
% \end{APIspec}
% 
% 
% Before reading the specification below, one might wish to recall 
% that a \emph{one-parameter subgroup} of a Lie group $G$ is a smooth 
% curve \(\theta\colon \mathbb{R} \longrightarrow G\) satisfying
% \begin{equation*}
%   \theta(s+t) = \theta(s) \theta(t)
%   \qquad\text{for all \(s,t \in \mathbb{R}\).}
% \end{equation*}
% It follows from the above that $\theta(0)$ is the identity in $G$, 
% because taking \(s=t=0\) gives \(\theta(0) = \theta(0) \theta(0)\) 
% and hence if $e$ is the identity then \(e = \theta(0)^{-1} \theta(0) 
% = \theta(0)^{-1} \theta(0) \theta(0) = e \theta(0) = \theta(0)\). 
% It also follows that the image of $\theta$ is a commutative 
% subgroup of $G$.
% 
% A one-parameter subgroup $\theta$ is uniquely determined by its 
% values on any open neighbourhood 
% $\mathopen{]}-\varepsilon,\varepsilon\mathclose{[}$ of $0$, since 
% \(\theta(t) = \theta(t/n)^n\) for any integer \(n>0\) and thus also 
% some $n$ such that \(-\varepsilon < t/n < \varepsilon\). Conversely, 
% there is for every tangent vector $u$ at the identity $e$ a unique 
% one-parameter subgroup $\theta$ with \(\theta'(0) = u\), because that 
% subgroup is an integral curve of the left-invariant (and also the 
% right-invariant) vector field with value $u$ at the identity. 
% 
% 
% \begin{APIspec}{Lie group}{1.1}
%   Specifying what a Lie group is in the form of an abstract 
%   algebraic interface is not so easy, because the concept relies 
%   heavily on analysis. Technically it is just a group that is a 
%   manifold, but the importance of the concept has much to do with 
%   the corresponding Lie algebra that arises and the way this can be 
%   used to describe the group. Giving a finite specification of this 
%   connection seems very difficult. Hence the following does not 
%   attempt to be an axiomatised formal theory of Lie groups, but 
%   rather to specify a collection of methods that make something 
%   \emph{usable} as a Lie group.
%   
%   \begin{APIdescription}{Lie group}
%     \begin{APImethod}{=}
%       \word{element} \word{element}
%     \end{APImethod}
%     \begin{APImethod}{*}
%       \word{element} \word{element}
%     \end{APImethod}
%     \begin{APImethod}{1} \end{APImethod}
%     \begin{APImethod}{inverse}
%       \word{element}
%     \end{APImethod}
%       To begin with, these operations satisfy the 
%       \APIref+{group}{1.0} interface.
%       
%     \begin{APImethod}{charts}
%       \word{point}\regstar
%     \end{APImethod}
%     \begin{APImethod}{p2c}
%       \word{chart} \word{point}
%     \end{APImethod}
%     \begin{APImethod}{c2p}
%       \word{chart} \word{coordinate}
%     \end{APImethod}
%     \begin{APImethod}{coord}
%       \word{method} \word{arg}\regstar
%     \end{APImethod}
%       Next, these methods satisfy the \APIref+{manifold}{1.0} 
%       interface.
%       
%     \begin{APImethod}{tangent}
%       \word{method} \word{arg}\regstar
%     \end{APImethod}
%       For any Lie group $G$, `\texttt{$G$ tangent}' is the 
%       structure of the tangent space $\mathrm{T}_eG$ to $G$ at the 
%       identity \(e ={}\)\texttt{[$G$ 1]}.
%       
%       Every Lie group endows this tangent space with a Lie algebra 
%       structure, but even though it would be highly recommended 
%       that \texttt{[$G$ tangent API "Lie algebra" 1.0]} is true, it 
%       is not a formal requirement of the \APIref{Lie group}{1.1} 
%       interface.
%       
%     \begin{APImethod}{exp}
%       \word{tangent}
%     \end{APImethod}
%       This is the exponent map from tangent space to Lie group, i.e., 
%       if \(\theta\colon \mathbb{R} \longrightarrow G\) is the 
%       one-parameter subgroup of $G$ for which $\theta'(0)$ is the 
%       \word{tangent} then \texttt{[$G$ exp \word{tangent}]} is 
%       $\theta(1)$.
%   \end{APIdescription}
% \end{APIspec}
% 
% Now, is that all there is to it\Dash does the above express all the 
% relevant structure that a general Lie group has? Rather far from 
% it, but it does represent a useful subset (the exponent map 
% provides a way of turning velocities into actual movements) that can 
% be expressed in the terms available; doing more would also require 
% defining more.
% 
% What is the weakest link above is, perhaps unexpectedly, the 
% \APIref+{manifold}{1.0} structure. It is true that it 
% computationally codifies the mathematical definition of a manifold, 
% but it fails to cater for many things that any manifold as a 
% consequence of this definition will support. In particular, any 
% manifold $M$ has a tangent bundle $TM$ consisting of all its tangent 
% vectors, and $TM$ is a manifold too; a chart \(\phi\colon U 
% \longrightarrow V\), where \(U \subseteq M\) is open and $V$ is a 
% vector space, has a tangent bundle counterpart \(\Phi\colon TU 
% \longrightarrow TV \cong V \times V\) which puts coordinates on not 
% just points of $M$ but also on vectors of $M$. Having `vector on 
% manifold' as an explicit object, the Lie group structure would 
% bring maps that transport vectors from one point to another, or 
% equivalently to\slash from the \texttt{tangent} space and any point 
% on the manifold. 
% 
% \begin{APIspec}{Lie group}{1.0}
%   Indeed, it even makes sense to contrarily define a lower version 
%   of \APIref{Lie group}{1.1}, that drops even the requirements about 
%   a \APIref{manifold}{1.0} structure; implementing it can be a 
%   nontrivial task, and there are plenty of applications in which it 
%   wouldn't be used anyway. 
% \end{APIspec}
% 
% Another aspect of \texttt{tangent} vectors that the above 
% definition fails to touch upon is that they are derivations\Dash 
% naively derivations at the identity, but also algebraic derivations 
% on the whole of a suitable ring of functions via their 
% corresponding left- or right-invariant vector field. However, this 
% presupposes that one can implement a structure of such functions, 
% which is by no means obvious and definitely not easy.
% From an elementary perspective, it makes sense to stop at a set 
% of methods that directly involve the elements of the Lie group.
% 
% \bigskip
% 
% One way to continue now would be to define a generic `cartesian 
% product of Lie groups' structure, but most readers are probably 
% better served by a less abstract example.
% 
% 
% \section{Real arithmetic Lie groups}
% 
% \subsection{The abelian Lie group $\mathbb{R}^n$}
% 
% The simplest possible Lie group is obtained by dressing up the 
% plain old $n$-dimensional vector space $\mathbb{R}^n$ in Lie 
% garments. This involves having the same basic set appearing in three 
% different roles: as the group (with vector addition as group 
% operation), as the coordinate space (every point is the coordinates 
% for itself), and as the Lie algebra. The implementational 
% complexity is however somewhat lower, as many method 
% implementations can be reused for several of the structures that 
% are involved.
% 
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::Rn 1.0 Rn
%</docstrip.tcl::catalogue>
%<*Rn>
package require Tcl 8.6
package require API 1.0
package require mtmtcl::openmath 1.1
package require mtmtcl::sets::finite_ordinal 1.0
package require mtmtcl::rings::float 1.0
% \end{tcl}
% For practical reasons, the underlying ring of reals is taken to be 
% the |mtmtcl::rings::float| one, as explicit |expr|s are used in the 
% implementations of operations below. What is not so hardwired is 
% the dimension $n$ of the space, since that is often something which 
% is not known until after the program has started. Therefore all the 
% methods defined below have a parameter which determines $n$, and 
% which would typically be part of the command prefix of the Lie 
% group (or the like) structure and therefore not be visible in code 
% employing it abstractly.
% 
% \begin{tcl}
namespace eval ::mtmtcl::Lie::Rn {
% \end{tcl}
% \setnamespace{mtmtcl::Lie::Rn}
% 
% It would work to use the simple integer $n$ as the parameter, but 
% experience has shown that it is often more convenient to let the 
% parameter be the zero vector, as that is often closer to what has 
% to be computed.
% 
% \begin{proc}{0}
%   An extreme example of this is the |0| method whose job is to 
%   return that zero vector. This is however not the only case.
%   \begin{tcl}
   proc 0 {zero} {return $zero}
%   \end{tcl}
% \end{proc}
% 
% The value representation used for an element of $\mathbb{R}^n$ is a 
% list of $n$ |double|s.
% 
% \begin{proc}{neg}
%   Hence, the way to negate a vector $u$ is to construct the list of 
%   the negations of the elements of $u$.
%   \begin{tcl}
   proc neg {zero u} {
      set res {}
      foreach x $u {lappend res [expr {-$x}]}
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{+}
%   For addition, one performs a simultaneous loop over the elements 
%   of the two terms.
%   \begin{tcl}
   proc + {zero u v} {
      set res {}
      foreach x $u y $v {
         lappend res [expr {$x+$y}]
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{variadic_plus}
%   Alternatively, one could define the addition operation to be 
%   variadic, but this incurs a bit of overhead.
%   \begin{tcl}
   proc variadic_plus {zero args} {
      if {![llength $args]} then {return $zero}
      set res [lindex $args 0]
      foreach term [lrange $args 1 end] {
         set sum {}
         foreach x $res y $term {
            lappend sum [expr {$x+$y}]
         }
         set res $sum
      }
      return $res
   }
%   \end{tcl}
%   It is notable here that the |zero| vector is needed within an 
%   operation where one might think that the necessary information 
%   should be available from other arguments; there need not always 
%   be any!
% \end{proc}
% 
% \begin{proc}{-}
%   Subtraction is a trivial modification of addition.
%   \begin{tcl}
   proc - {zero u v} {
      set res {}
      foreach x $u y $v {
         lappend res [expr {$x-$y}]
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{=}
%   Two vectors are equal if corresponding elements are equal.
%   \begin{tcl}
   proc = {zero u v} {
      foreach x $u y $v {
         if {$x != $y} then {return 0}
      }
      return 1
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{.}
%   A vector space requires a `multiply by scalar' operation.
%   \begin{tcl}
   proc . {zero t u} {
      set res {}
      foreach x $u {lappend res [expr {$t*$x}]}
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{scalar}
%   And there must of course be a way of accessing the underlying 
%   ring of scalars. This could have been done as an alias, had it not 
%   been for the fact that methods of $\mathbb{R}^n$ take a |zero| 
%   parameter which methods of $\mathbb{R}$ do not.
%   \begin{tcl}
   proc scalar {zero args} {
      tailcall ::mtmtcl::rings::float {*}$args
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{innerprod}
%   Though not required for an abstract Lie algebra, it is natural to 
%   equip the tangent space with an inner product, as many Lie groups 
%   of practical interest are Riemannian manifolds. The standard 
%   inner product on $\mathbb{R}^n$ is the euclidean inner product.
%   \begin{tcl}
   proc innerprod {zero u v} {
      set res 0.0
      foreach x $u y $v {set res [expr {$res + $x*$y}]}
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{distance}
%   From the inner product, one gets a euclidean distance.
%   \begin{tcl}
   proc distance {zero u v} {
      set d [- $zero $u $v]
      return [::tcl::mathfunc::sqrt [innerprod $zero $d $d]]
   }
%   \end{tcl}
% \end{proc}
% 
% A slightly different caregory of operations on $\mathbb{R}^n$ are 
% those that equip it with a standard basis. These are specified in 
% the \APIref{free ring-module}{2.1} interface.
% 
% \begin{proc}{coeff}
%   A convenient choice of indices for the basis is to use the list 
%   indices, since that means extracting a coefficient is merely a 
%   matter of indexing into the list.
%   \begin{tcl}
   proc coeff {zero i u} {lindex $u $i}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{basiselement}
%   Similarly, producing a basis vector is merely a matter of 
%   changing one element in the |zero| vector.
%   \begin{tcl}
   proc basiselement {zero i} {lset zero $i 1.0}
%   \end{tcl}
%   Here there may be a point in remarking upon how the above takes 
%   advantage of the way \Tcllogo\ handles values. In \Tcllogo, all 
%   values are immutable, so operations like |lset| that change the 
%   value of a variable must be prepared to manufacture a new value. 
%   It does so lazily, so the result of |basiselement| will 
%   memory-wise share all elements with the zero vector, except 
%   that which was changed. This reduces the amount of data that 
%   need to be physically copied, while not opening up for values that 
%   you hold to be mutated by other pieces of the program when you're 
%   not looking.
% \end{proc}
% 
% \begin{proc}{support}
%   The support of a vector is the list of those basis indices for 
%   which the corresponding |coeff|icient is nonzero.
%   \begin{tcl}
   proc support {zero u} {
      set res {}
      set i 0
      foreach x $u {
         if {$x != 0.0} then {lappend res $i}
         incr i
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{basis}
%   The final thing required for a basis is the set of indices 
%   enumerating that basis, as a structure. Since this set is of the 
%   form $\{0,1,\dotsc, n -\nobreak 1\}$, one can consider it 
%   implemented by the |finite_ordinal| structure.
%   \begin{tcl}
   proc basis {zero args} {
      tailcall ::mtmtcl::sets::finite_ordinal [llength $zero] {*}$args
   }
%   \end{tcl}
% \end{proc}
% 
% Another way to look at $\mathbb{R}^n$ is as the $n$-fold cartesian 
% product of $\mathbb{R}$ with itself. This suggests that the methods 
% specified in the \APIref{direct product}{1.0} interface should be 
% available too.
% 
% \begin{proc}{no.components}
%   The number $n$ of components is simply the list length of the 
%   zero vector.
%   \begin{tcl}
   proc no.components {zero} {llength $zero}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{tuple}
%   The direct product view offers a way of constructing a vector 
%   from its elements, which turns out to be trivial since they have 
%   already been wrapped up in the procedure call. Here it might be 
%   adviceable to check that the number of components is correct.
%   \begin{tcl}
   proc tuple {zero args} {
      if {[llength $zero] == [llength $args]} then {
         return $args
      } else {
         return -code error -errorcode {API "direct product"}\
           "Wrong number of elements in tuple"
      }
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{index}
%   The converse indexing operation turns out to be the same as 
%   |coeff|, but it is easier to define it anew than to create an 
%   alias.
%   \begin{tcl}
   proc index {zero i u} {lindex $u $i}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{component}
%   The various components are all the scalar ring $\mathbb{R}$, so 
%   this is just like the |scalar| command, except that it ignores an 
%   additional argument.
%   \begin{tcl}
   proc component {zero index args} {
      tailcall ::mtmtcl::rings::float {*}$args
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{export}
%   The export format is as a \OMSref{linalg3}{vector} of what one 
%   gets by exporting the elements.
%   \begin{tcl}
   proc export {zero u attrs} {
      dict lappend attrs mtmtcl:path scalar
      set L {}
      foreach x $u {
         lappend L [::mtmtcl::rings::float export $x $attrs]
      }
      return [::mtmtcl::openmath::OM AS linalg3 vector {*}$L]
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{import}
%   The supported import objects are vectors constructed using 
%   \OMSref{linalg3}{vector} or \OMSref{linalg2}{vector}.
%   \begin{tcl}
   proc import {zero path tree} {
      while {[lindex $tree 0] eq "OMATTR"} {
         set tree [lindex $tree 2 1]
      }
      ::mtmtcl::openmath::OMAS_switch $tree {
      } http://www.openmath.org/cd/linalg\[23\]#vector {
         lappend path scalar
         set res {}
         foreach elem [lrange [lindex $tree 2] 1 end] {
            lappend res [::mtmtcl::rings::float import $path $elem]
         }
         if {[llength $res] == [llength $zero]} then {
            return $res
         } else {
            return -code error -errorcode\
              [list API import EDOM [lrange $path 0 end-1] $tree] \
              "Expected [llength $zero] elements in vector,\
                got [llength $res] elements"
         }
      }
      return -code error -errorcode [list API import EDOM $path $tree]\
        "Expected a vector"
   }
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{tclcommand}{ensemble}{space}
%   Now all the various operations that the coordinate space offers 
%   have been defined, so time has come to wrap them up as a 
%   structure. It is convenient to use an ensemble for this.
%   \begin{tcl}
   namespace ensemble create -subcommands {
      = + 0 neg -
%   \end{tcl}
%   Those five commands are what is needed for 
%   \APIref+{additive group}{2.0.1}. One could consider also 
%   implementing |iszero| for the sake of supporting 
%   \APIref+{additive group}{2.1}.
%   \begin{tcl}
      . innerprod scalar
      distance
%   \end{tcl}
%   These four commands additionally give support for 
%   \APIref+{ring-module}{2.1}, \APIref+{inner product space}{1.1}, 
%   and \APIref+{metric space}{1.2}.
%   \begin{tcl}
      basis basiselement coeff support
%   \end{tcl}
%   And those four support \APIref+{free ring-module}{2.1}.
%   \begin{tcl}
      component index no.components tuple
%   \end{tcl}
%   And those four support \APIref+{direct product}{1.1}.
%   \begin{tcl}
      export import API
%   \end{tcl}
%   The |API| method has an explicit map entry, but all other methods 
%   map to the similarly named procedure in the present namespace.
%   \begin{tcl}
   } -command [namespace current]::space -map {
      API {::API::staticn 1 {
         equality              1.0
         "additive group"      2.0.1
         ring-module           2.1
         "inner product space" 1.1
         "metric space"        1.2
         "free ring-module"    2.1
         "direct product"      1.1
         export                2.0
         import                1.0
      }}
   } -parameters {zero} -prefix 0
%   \end{tcl}
% \end{tclcommand}
% 
% \begin{proc}{bracket}
%   The above almost also suffices for turning $\mathbb{R}^n$ into a 
%   Lie algebra\Dash the only thing that's missing is the Lie 
%   |bracket|, which in this case is identically zero.
%   \begin{tcl}
   proc bracket {zero u v} {return $zero}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{improve}
%   For greater similarity with more complicated groups, it is 
%   natural to portray the Lie algebra as a \APIref+{subset}{2.1} of 
%   something, even if that |superset| is just the above |space| on 
%   the exact same set $\mathbb{R}^n$.
%   \begin{tcl}
   proc improve {zero u} {return $u}
%   \end{tcl}
% \end{proc}
% 
% \begin{tclcommand}{ensemble}{algebra}
%   Not surprisingly, the command implementing the Lie algebra 
%   structure is another ensemble.
%   \begin{tcl}
   namespace ensemble create -subcommands {
      = + 0 neg -
      . scalar *
%   \end{tcl}
%   Inheriting from the \APIref{ring-algebra}{2.0} interface, 
%   \APIref{Lie algebra}{1.0} requires the bracket to be named |*|; 
%   this is achieved through an explicit |-map| entry below.
%   \begin{tcl}
      innerprod
      basis basiselement coeff support
%   \end{tcl}
%   It makes perfect sense for a Lie algebra to support the 
%   \APIref{ring-module}{2.1} and \APIref{inner product space}{1.1} 
%   interfaces, whereas \APIref{direct product}{1.1} is more 
%   questionable; though this is not formally required by anything, 
%   one might stylistically expect that a direct product that is a 
%   Lie algebra should also be a direct product of Lie algebras.
%   \begin{tcl}
      superset improve
      export import API
   } -command [namespace current]::algebra -map {
      * bracket
      superset space
      API {::API::staticn 1 {
         equality              1.0
         "additive group"      2.0.1
         ring-module           2.1
         ring-algebra          2.0
         "Lie algebra"         1.0
         "inner product space" 1.1
         "free ring-module"    2.1
         subset                2.1
         export                2.0
         import                1.0
      }}
   } -parameters {zero} -prefix 0
%   \end{tcl}
% \end{tclcommand}
% 
% This brings us to the crowing pieces: the \emph{group}. This 
% requires a few more method implementations, even if they are 
% numerically trivial.
% 
% \begin{proc}{identity_ignoring_chart}
%   First, there are the point-to-coordinates and 
%   coordinates-to-point translation maps, which in $\mathbb{R}^n$ 
%   are just the identity map.
%   \begin{tcl}
   proc identity_ignoring_chart {zero chart u} {return $u}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{charts}
%   Next, there's the |charts|. $\mathbb{R}^n$ can make do with a 
%   single |global| chart.
%   \begin{tcl}
   proc charts {args} {return "global"}
%   \end{tcl}
% \end{proc}
% 
% So much for \APIref{manifold}{1.0}. The \APIref{Lie group}{1.1} 
% itself requires in addition only the |exp|onent map.
% 
% \begin{proc}{exp}
%   The exponent on $\mathbb{R}^n$ is again just an identity map and 
%   could have been implemented using |identity_ignoring_chart|, but 
%   it is clearer to define it explicitly.
%   \begin{tcl}
   proc exp {zero u} {return $u}
%   \end{tcl}
% \end{proc}
% 
% \begin{tclcommand}{ensemble}{group}
%   The group aspect of $\mathbb{R}^n$ has a more extensive mapping 
%   of subcommands, so it is easiest to just list everything there, 
%   even the few things which are mapped to themselves.
%   \begin{tcl}
   namespace ensemble create -map {
      =        =
      *        +
      1        0
      inverse  neg
      /        -
%   \end{tcl}
%   The group structure is precisely the additive group of the vector 
%   space, but since \APIref{Lie group}{1.1}s use multiplicative 
%   notation it becomes necessary to remap the basic operations. 
%   Mapping |*| to |variadic_plus| instead would extend the support 
%   to \APIref+{group}{1.1}. Additionally throwing in a mapping to 
%   subtraction will bring support for the \APIref{division}{1.0} 
%   interface (which is perhaps not so useful, but neither likely to 
%   hurt in any way).
%   \begin{tcl}
      charts   charts
      coord    space
      c2p      identity_ignoring_chart
      p2c      identity_ignoring_chart
      tangent  algebra
      exp      improve
%   \end{tcl}
%   The \APIref{manifold}{1.0} structure requires another bunch of 
%   remappings. After that, the \APIref{Lie group}{1.1} structure 
%   only needs the |tangent| method mapped to the Lie algebra 
%   ensemble |algebra| and |exp| mapped to |improve|.
%   \begin{tcl}
      distance distance
%   \end{tcl}
%   The \APIref{metric space}{1.2} structure only requires exposing 
%   the euclidean |distance| command.
%   \begin{tcl}
      API {::API::staticn 1 {
         equality           1.0
         group              1.0
         division           1.0
         manifold           1.0
         "Lie group"        1.1
         "metric space"     1.2
         export             2.0
         import             1.0
         subset             2.1
      }}
      superset space
      improve  improve
      export   export
      import   import
%   \end{tcl}
%   For reasons of later convenience, it furthermore turns out to be 
%   a good idea to give the Lie group $\mathbb{R}^n$ the interface of 
%   a \APIref+{subset}{2.1} of the inner product space 
%   $\mathbb{R}^n$: this makes it more similar to the various matrix 
%   groups defined below.
%   
%   \begin{tcl}
   } -command [namespace current]::group -parameters {zero} -prefix 0
%   \end{tcl}
% \end{tclcommand}
% 
% 
% 
% \begin{proc}{make}
%   All that remains now is to define a constructor command for 
%   $\mathbb{R}^n$ in the various guises set up above. This is 
%   formally the only public command in this package, and it has the 
%   call syntax
%   \begin{displaysyntax}
%     mtmtcl::Lie::Rn::make \begin{regblock}
%       group \regalt algebra \regalt space
%     \end{regblock} \word{$n$}
%   \end{displaysyntax}
%   What this returns is a command prefix for $\mathbb{R}^n$ as a 
%   formal structure, where $n$ thus is the dimension of the desired 
%   space. In the \texttt{group} case, that structure will be a Lie 
%   group, in the \texttt{algebra} case that structure will be a Lie 
%   algebra, and in the \texttt{space} case that structure will be an 
%   inner product space.
%   
%   \begin{tcl}
   proc make {what dimension} {
      set zero [lrepeat $dimension [::mtmtcl::rings::float 0]]
      switch -- $what group - algebra - space {
         return [list [namespace which $what] $zero]
      } default {
         return -code error "Unknown view '$what' of R^n"
      }
   }
%   \end{tcl}
% \end{proc}
% 
% 
% 
% Here ends the |namespace eval| block, and the package as a whole.
% \begin{tcl}
}
%</Rn>
% \end{tcl}
% 
% 
% 
% \section{Complex matrix groups as real Lie groups}
% 
% Many classical Lie groups are matrix groups, some of which are real 
% and others of which are complex. Complex elements often open up for 
% more interesting possibilities, as for example the unitary group 
% $\mathrm{U}(n)$ is connected whereas its real counterpart the 
% orthogonal group $\mathrm{O}(n)$ is not. Manifolds also come in 
% both real and complex varieties, but here it is rather the real 
% ones that are practically interesting, as a complex structure 
% imposes additional restrictions. Hence we arrive at the case of 
% complex matrix groups seen as real Lie groups.
% 
% 
% \subsection{The real vector space of complex matrices}
% 
% For matrix Lie groups, the tangent spaces are also naturally 
% identified with sets of matrices. Hence spaces of matrices appear 
% underneath the main Lie group structure in several places, and thus 
% it makes sense to start out with defining a generic complex matrix 
% structure. However, since the aim is towards real manifolds, the 
% complex matrices structure should sport the interface of a 
% \emph{real} vector space. To that end, there is the package
% \begin{quote}
%   |mtmtcl::Lie::complex_matrix_real_space|
% \end{quote}
% which defines a structure that serves as |superset| of the actual 
% matrix groups, but also serves as a repository of operations.
% 
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::complex_matrix_real_space 1.2 CMRS
%</docstrip.tcl::catalogue>
%<*CMRS>
package require Tcl 8.6
package require API 1.0
package require mtmtcl::rings::float 1.0
package require mtmtcl::rings::complex 1.0
package require mtmtcl::sets::cartesian_product 1.1
package require mtmtcl::sets::finite_ordinal 1.0
namespace eval ::mtmtcl::Lie::complex_matrix_real_space {
% \end{tcl}
% \setnamespace{mtmtcl::Lie::complex_matrix_real_space}
% 
% Matrices are list of lists, in row-major order. A matrix element is 
% a |complex| number, so a two-element list of real and imaginary 
% part; knowing this inner structure is relied upon in places below.
% 
% \begin{tclcommand}{alias}{complex}
%   However, where convenient the code makes use of the 
%   |mtmtcl::rings::complex| command implementation of operations on 
%   complex numbers. Therefore an alias is created to that command so 
%   that it is readily available.
%   \begin{tcl}
   interp alias {} [namespace current]::complex {}\
     ::mtmtcl::rings::complex
%   \end{tcl}
% \end{tclcommand}
% 
% The complex matrix structure command itself will be an ensemble 
% with one parameter: the zero matrix for the space in question. It 
% would be possible to let that parameter merely be the side of the 
% matrix instead, because everything else can be deduced from that, 
% but having a full zero matrix simplifies the implementation of 
% several methods. This suggests the following contruction command.
% 
% \begin{proc}{make}
%   The syntax of the call to construct a space of complex matrices is
%   \begin{displaysyntax}
%     |mtmtcl::Lie::complex_matrix_real_space::make| \word{n}
%   \end{displaysyntax}
%   and it returns a command prefix for the structure of $n \times 
%   n$ complex matrices ($\mathbb{C}^{n \times n}$), seen as a real 
%   inner product space.
%   
%   For the time being (later versions of the package may change this), 
%   the ensemble shares its name with its namespace. Most of the 
%   work below goes into constructing the ensemble parameter.
%   \begin{tcl}
   proc make {n} {
      incr n 0
      set zero [complex 0]
      set L {}
      for {set i 0} {$i < $n} {incr i} {lappend L $zero}
      set Zero {}
      for {set i 0} {$i < $n} {incr i} {lappend Zero $L}
      return [list [namespace current] $Zero]
   }
%   \end{tcl}
% \end{proc}
% 
% Note that the |complex| command above does not have the right 
% syntax for being a subcommand of the |complex_matrix_real_space| 
% ensemble (the parameter would be misinterpreted as the method 
% name). Hence the list of subcommands of the ensemble (created in 
% Subsubsection~\ref{Sssec:CMRS-ensemble} below) should probably be 
% explicitly specified.
% 
% 
% \subsubsection{Additive group operations}
% 
% \begin{proc}{=}
%   Starting with the elementary stuff, testing two matrices $A$ and 
%   $B$ for equality is a matter of looping over all elements. 
%   Employing |complex| would be possible, but is probably not so 
%   practical.
%   \begin{tcl}
   proc = {Zero A B} {
      foreach arow $A brow $B {
         foreach a $arow b $brow {
            forach ac $a bc $b {
               if {$ac != $bc} then {return 0}
            }
         }
      }
      return 1
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{neg}
%   The same is true for negating a matrix.
%   \begin{tcl}
   proc neg {Zero A} {
      set res {}
      foreach arow $A {
         set rrow {}
         foreach a $arow {
            set z {}
            foreach ac $a {lappend z [expr {-$ac}]}
            lappend rrow $z
         }
         lappend res $rrow
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{+}
%   And again for adding two matrices $A$ and $B$ together. 
%   Moreover, the overhead for supporting variadic addition is 
%   negligible.
%   \begin{tcl}
   proc + {Zero args} {
      if {[llength $args]<2} then {
         if {[llength $args] == 1} then {
            return [lindex $args 0]
         } else {
            return $Zero
         }
      }
      set A [lindex $args 0]
      foreach B [lrange $args 1 end] {
         set Sum {}
         foreach arow $A brow $B {
            set srow {}
            foreach a $arow b $brow {
               set s {}
               foreach ac $a bc $b {
                  lappend s [expr {$ac + $bc}]
               }
               lappend srow $s
            }
            lappend Sum $srow
         }
         set A $Sum
      }
      return $A
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{0}
%   Returning the zero matrix is by design trivial.
%   \begin{tcl}
   proc 0 {Zero} {return $Zero}
%   \end{tcl}
%   Note that having it at hand also greatly simplified |+|.
% \end{proc}
% 
% \begin{proc}{-}
%   Subtraction could be done as a special case of `|+.|' below, but 
%   it is easy enough to do explicitly.
%   \begin{tcl}
   proc - {Zero A B} {
      set Sum {}
      foreach arow $A brow $B {
         set srow {}
         foreach a $arow b $brow {
            set s {}
            foreach ac $a bc $b {
               lappend s [expr {$ac - $bc}]
            }
            lappend srow $s
         }
         lappend Sum $srow
      }
      return $Sum
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{iszero}
%   Having an |iszero| method allows declaring support for 
%   \APIref+{additive group}{2.1}.
%   \begin{tcl}
   proc iszero {Zero A} {
      foreach arow $A brow {
         foreach a $arow {
            forach ac $a {
               if {$ac != 0} then {return 0}
            }
         }
      }
      return 1
   }
%   \end{tcl}
% \end{proc}
% 
% 
% \subsubsection{Vector space operations}
% 
% \begin{proc}{.}
%   Multiplication by scalar is very similar to negating.
%   \begin{tcl}
   proc . {Zero t A} {
      set res {}
      foreach arow $A {
         set rrow {}
         foreach a $arow {
            set z {}
            foreach ac $a {lappend z [expr {$t*$ac}]}
            lappend rrow $z
         }
         lappend res $rrow
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{C.}
%   Multiplication by a |complex| scalar is not the formal 
%   multiply-by-scalar operation here, but nothing prevents 
%   implementing it under the name `|C.|'. To that end, this 
%   procedure has the syntax
%   \begin{displaysyntax}
%     C. \word{zero} \word{$z$} \word{$A$}
%   \end{displaysyntax}
%   which multiplies the matrix $A$ by a |complex| number $z$.
%   \begin{tcl}
   proc C. {Zero z A} {
      set res {}
      foreach arow $A {
         set rrow {}
         foreach a $arow {
            lappend rrow [complex * $z $a]
         }
         lappend res $rrow
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{+.}
%   An operation which often turns out to be convenient is that of 
%   forming a linear combination of elements. Since this is a 
%   combination of |+| and |.|, it is called |+.| and the procedure 
%   implementing it has the syntax
%   \begin{displaysyntax}
%     +. \word{zero} \word{element}\regopt\ \begin{regblock}[\regstar] 
%     \word{coefficient} \word{element} \end{regblock} 
%   \end{displaysyntax}
%   where each \word{coefficient} is a scalar (i.e., a |double|), and 
%   each \word{element} is a matrix. A \word{coefficient} is taken 
%   times the \word{element} following it; if there is one 
%   \word{element} more then this first \word{element} implicitly gets 
%   the coefficient $1$.
%   \begin{tcl}
   proc +. {Zero args} {
      if {![llength $args]} then {return $Zero}
%   \end{tcl}
%   Taking a scalar multiple of the first \word{element} is handled 
%   by the |.| procedure, \dots
%   \begin{tcl}
      if {[llength $args] % 2} then {
         set A [lindex $args 0]
         set start 1
      } else {
         set A [. $Zero [lindex $args 0] [lindex $args 1]]
         set start 2
      }
%   \end{tcl}
%   \dots\ but subsequent terms of the linear 
%   combination are handled internally.
%   \begin{tcl}
      foreach {c B} [lrange $args $start end] {
         set Sum {}
         foreach arow $A brow $B {
            set srow {}
            foreach a $arow b $brow {
               set s {}
               foreach ai $a bi $b {
                  lappend s [expr {$ai + $c*$bi}]
               }
               lappend srow $s
            }
            lappend Sum $srow
         }
         set A $Sum
      }
      return $A
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{+R2.}
%   Another alternative linear combination operation is to view 
%   $\mathbb{C}^{n \times n}$ as an \(\mathbb{R}^2 = \mathbb{R} 
%   \times \mathbb{R}\) module, with the first component acting on 
%   element real parts and the second acting on element imaginary 
%   parts. This can be used for such things as complex conjugating a 
%   matrix, by using a coefficient of $(1,-1)$.
%   
%   The call syntax for this operation is
%   \begin{displaysyntax}
%     +R2. \word{zero} \word{element}\regopt\ \begin{regblock}[\regstar] 
%     \word{coefficient} \word{element} \end{regblock} 
%   \end{displaysyntax}
%   where each \word{coefficient} is a pair (length $2$ list) of real 
%   numbers, and each \word{element} is a matrix. If there is one 
%   \word{element} more than there are \word{coefficient}s then the 
%   first \word{element} implicitly gets the coefficient $1$ (or 
%   perhaps that should rather be $(1,1)$, as that is the identity in 
%   the ring $\mathbf{R}^2$).
%   \changes{2012/06/18}{CMRS 1.2}{Command added. (LH)}
%   \begin{tcl}
   proc +R2. {Zero args} {
      if {![llength $args]} then {return $Zero}
      if {[llength $args] % 2} then {
         set A [lindex $args 0]
         set start 1
      } else {
         set A {}
         foreach brow [lindex $args 1] {
            set arow {}
            foreach b $brow {
               set a {}
               foreach bi $b ci [lindex $args 0] {
                  lappend a [expr {$ci*$bi}]
               }
               lappend arow $a
            }
            lappend A $arow
         }
         set start 2
      }
      foreach {c B} [lrange $args $start end] {
         set Sum {}
         foreach arow $A brow $B {
            set srow {}
            foreach a $arow b $brow {
               set s {}
               foreach ai $a bi $b ci $c {
                  lappend s [expr {$ai + $ci*$bi}]
               }
               lappend srow $s
            }
            lappend Sum $srow
         }
         set A $Sum
      }
      return $A
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{innerprod}
%   A very elementary inner product on $\mathbb{C}^{n \times n}$ is 
%   to implicitly flatten the complex matrices to vectors of $2n^2$ 
%   real numbers, and apply the ordinary euclidean dot-product on 
%   these. The implementation is trivial.
%   \begin{tcl}
   proc innerprod {Zero A B} {
      set res 0.0
      foreach arow $A brow $B {
         foreach aelem $arow belem $brow {
            foreach a $aelem b $belem {
               set res [expr {$res + $a*$b}]
            }
         }
      }
      return $res
   }
%   \end{tcl}
%   What is slightly less trivial is that this seemingly 
%   element-arithmetical inner product also has a matrix-algebraic 
%   definition. Given \(z = x+iy\) and \(w = u+iv\), one may observe 
%   that \(xu + yv = \operatorname{Re}(\bar{z} w)\), and hence
%   \begin{multline*}
%     \texttt{[innerprod $A$ $B$]} =
%     \operatorname{Re} \sum_{k=1}^n \sum_{l=1}^n
%       \overline{ A_{kl} } B_{kl} = \\ =
%     \operatorname{Re} \sum_{l=1}^n \sum_{k=1}^n (A^*)_{lk} B_{kl} =
%     \operatorname{Re} \sum_{l=1}^n (A^* B)_{ll} =
%     \operatorname{Re} \operatorname{tr} (A^* B)
%   \end{multline*}
%   ---the real part of the trace of the matrix product $A^* B$, 
%   where $A^*$ denotes the Hermitian conjugate of $A$. This 
%   is called the \emph{Frobenius inner product} of two matrices.
%   
%   Because \(\operatorname{tr}(AB) = \operatorname{tr}(BA)\), it 
%   follows that \(\langle A^*, B \rangle = \langle B^*, A\rangle\), 
%   which by symmetry is equal to $\langle A, B^*\rangle$. Moreover 
%   if $U$ is any unitary matrix then
%   \[
%     \langle UA, UB \rangle = 
%     \operatorname{Re} \operatorname{tr} \bigl( (UA)^* (UB) \bigr) =
%     \operatorname{Re} \operatorname{tr} ( A^* U^* U B ) =
%     \operatorname{Re} \operatorname{tr} ( A^* B ) =
%     \langle A, B \rangle \text{,}
%   \]
%   so the Frobenius inner product is unitarily invariant.
% \end{proc}
% 
% 
% \begin{proc}{Frobenius_norm}
%   With an inner product comes a corresponding norm, as the square 
%   root of the inner product of something with itself.
%   \begin{tcl}
   proc Frobenius_norm {Zero A} {
      ::tcl::mathfunc::sqrt [innerprod $Zero $A $A]
   }
%   \end{tcl}
%   This is an algebra norm in the sense that \(\lVert AB\rVert 
%   \leqslant \lVert A\rVert \, \lVert B\rVert\) for all \(A,B \in 
%   \mathbb{C}^{n \times n}\). One thing to keep in mind is however 
%   that \(\lVert I\rVert = \sqrt{n}\) rather than $1$.
% \end{proc}
% 
% \begin{proc}{Frobenius_distance}
%   Where there is a norm, it might also be nice to make a 
%   correponding distance function.
%   \begin{tcl}
   proc Frobenius_distance {Zero A B} {
      Frobenius_norm $Zero [- $Zero $A $B]
   }
%   \end{tcl}
% \end{proc}
% 
% 
% 
% 
% \subsubsection{Matrix multiplication and the like}
% 
% \begin{proc}{*}
%   General multiplication of matrices is however something different; 
%   here one is thankful to have |complex| arithmetic available. Given 
%   that, the overall structure ends up being not all that different 
%   from |+|.
%   \begin{tcl}
   proc * {Zero args} {
      if {[llength $args]<2} then {
         if {[llength $args] == 1} then {
            return [lindex $args 0]
         } else {
            return [1 $Zero]
         }
      }
      set A [lindex $args 0]
      foreach B [lrange $args 1 end] {
%   \end{tcl}
%   The main difference lies in how the |foreach| loops computing the 
%   $AB$ matrix product |Prod| are organised. The outermost loop is 
%   over rows of $A$ only, and each iteration computes one row of 
%   |Prod|. The middle loop is simultaneously over columns of $A$ and 
%   rows of $B$; each iteration adds a multiple of the $B$-row |brow| 
%   to the current partially summed |Prod|-row |prow|. The inner loop 
%   is over columns of $B$ and |Prod|, performing the row-to-row 
%   additions.
%   \begin{tcl}
         set Prod {}
         foreach arow $A {
            set prow [lindex $Zero 0]
            foreach a $arow brow $B {
               set srow {}
               foreach p $prow b $brow {
                  lappend srow [complex + $p [complex * $a $b]]
               }
               set prow $srow
            }
            lappend Prod $prow
         }
         set A $Prod
      }
      return $A
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{1}
%   Constructing the unit matrix is a matter of changing some entries 
%   in the |Zero| matrix to $1$. The trick is used that the length of 
%   a list (the result |res|) is also the index of the next element 
%   |lappend|ed to it, so that is also the column index of the 
%   diagonal element to set to $1$.
%   \begin{tcl}
   proc 1 {Zero} {
      set res {}
      foreach row $Zero {
         lset row [llength $res] 0 1.0
         lappend res $row
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{inverse}
%   The first really nontrivial operation is that of inverting a 
%   matrix. The algorithm used is plain old Gauss--Jordan elimination 
%   with augmented matrix and pivoting to the largest (in absolute 
%   value) element in what remains in the column.
%   
%   The first step is to construct the augmented matrix $G$, which is 
%   $n \times 2n$ for inverting an $n \times n$ matrix. The extra $n$ 
%   columns start out as an identity matrix.
%   \begin{tcl}
   proc inverse {Zero A} {
      set G {}
      foreach arow $A {
         set zrow [lindex $Zero 0]
         lset zrow [llength $G] 0 1.0
         lappend arow {*}$zrow
         lappend G $arow
      }
%   \end{tcl}
%   Then begins the main loop over the columns of $A$ (as appearing 
%   in $G$). Conceptually each iteration changes the column at index 
%   $k$ to have $1$ on the diagonal and be $0$ otherwise, i.e., the 
%   Gauss and Jordan eliminations are not separated. Technically, 
%   though, each $A$ column is dropped after having been used to 
%   select row operations. This saves a bit of work, as there is no 
%   need to compute and keep track of matrix elements that are anyway 
%   known from start to be $0$ or $1$. It also means the current 
%   column is always the first in the current $G$.
%   \begin{tcl}
      for {set k 0} {$k < [llength $A]} {incr k} {
%   \end{tcl}
%   For each column, one must first find the pivot row $i_0$. This 
%   is also a nice place to detect that the matrix is singular, even 
%   if that hardly ever happens for numerical data; the procedure will 
%   happily continue to work with matrix elements smaller than the 
%   epsilon of the |double|s.
%   \begin{tcl}
         set best 0.0
         for {set i $k} {$i < [llength $A]} {incr i} {
            set abs [complex abs [lindex $G $i 0]]
            if {$abs > $best} then {
               set best $abs
               set i0 $i
            }
         }
         if {$best <= 0.0} then {
            return -code error -errorcode {API division nosolution}\
              "No nonzero pivot after $k columns"
         }
%   \end{tcl}
%   If it is not $k$, then swap the two.
%   \begin{tcl}
         if {$i0 != $k} then {
            set pivot [lindex $G $i0]
            lset G $i0 [lindex $G $k]
            lset G $k $pivot
         }
%   \end{tcl}
%   Now perform the elementary row operations that would make the 
%   current column $1$ on the diagonal and $0$ in other elements.
%   \begin{tcl}
         set dinv [complex inverse [lindex $G $k 0]]
         set drow [lrange [lindex $G $k] 1 end]
         set Gnew {}
         foreach row $G {
            set nrow {}
            if {[llength $Gnew] == $k} then {
               foreach c $drow {
                  lappend nrow [complex * $dinv $c]
               }
            } else {
               set mul [complex * [lindex $row 0] $dinv]
               foreach c [lrange $row 1 end] d $drow {
                  lappend nrow [complex - $c [complex * $mul $d]]
               }
            }
            lappend Gnew $nrow
         }
         set G $Gnew
      }
%   \end{tcl}
%   After completing the loop over columns of $A$, only the 
%   augmentation columns of $G$ remain, so the current $G$ is exactly 
%   the wanted inverse.
%   \begin{tcl}
      return $G
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{det}
%   Computing the determinant can be done in pretty much the same 
%   way, except there is of course no need to augment the matrix 
%   first. Nor is there any need to do the Jordan elimination part, 
%   and as a matter of fact there is not even any need to retain a 
%   row after it has been used to eliminate a column. Hence the main 
%   column index (which was $k$ above) can always be taken to be $1$.
%   
%   What has to be added is a variable |res| for the result (a 
%   complex number); this will be the product of the diagonal 
%   elements in the matrix, as they emerge as leading elements, but 
%   as any good empty product it starts out as $1$.
%   \begin{tcl}
   proc det {Zero A} {
      set res [complex 1]
%   \end{tcl}
%   Then begins the main loop over the columns of $A$. Each iteration 
%   performs a Guass elimination (with pivot to row with largest 
%   element) in the first column, during which the first row and 
%   column of $A$ are dropped, whereas |res| is multiplied by the 
%   diagonal element.
%   \begin{tcl}
      for {} {[llength $A]>1} {} {
%   \end{tcl}
%   The first step is to find the pivot row $i_0$. In the event that 
%   all elements are $0$ then $\det A$ is known to be $0$ too.
%   \begin{tcl}
         set best 0.0
         set i 0
         foreach row $A {
            set abs [complex abs [lindex $row 0]]
            if {$abs > $best} then {
               set best $abs
               set i0 $i
            }
            incr i
         }
         if {$best <= 0.0} then {return [complex 0]}
%   \end{tcl}
%   If the best row was not the first, then swap the two, and 
%   remember to negate the result accordingly.
%   \begin{tcl}
         if {$i0 != 0} then {
            set pivot [lindex $A $i0]
            lset A $i0 [lindex $A 0]
            lset A 0 $pivot
            set res [complex neg $res]
         }
%   \end{tcl}
%   Now perform the elementary row operations that would make the 
%   current column $1$ on the diagonal and $0$ in other elements.
%   \begin{tcl}
         set res [complex * $res [lindex $A 0 0]]
         set dinv [complex inverse [lindex $A 0 0]]
         set drow [lrange [lindex $A 0] 1 end]
         set Anew {}
         foreach row [lrange $A 1 end] {
            set nrow {}
            set mul [complex * [lindex $row 0] $dinv]
            foreach c [lrange $row 1 end] d $drow {
               lappend nrow [complex - $c [complex * $mul $d]]
            }
            lappend Anew $nrow
         }
         set A $Anew
      }
%   \end{tcl}
%   After that, $A$ has side $1$ and the result can be computed with 
%   one additional complex multiplication.
%   \begin{tcl}
      return [complex * $res [lindex $A 0 0]]
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{/}
%   Another operation which can efficiently be done using the same 
%   Gauss--Jordan elimination algorithm is division---to compute 
%   $A^{-1}B$---since all one has to change relative to the 
%   implementation of |inverse| is that one augments with $B$ instead 
%   of the identity! The row operations that transform $I$ to 
%   $A^{-1}$ are also those that transform $B$ to $A^{-1}B$.
%   \begin{tcl}
   proc / {Zero B A} {
      set G {}
      foreach arow $A brow $B {
         lappend arow {*}$brow
         lappend G $arow
      }
      return [reduce_augmented_matrix $G]
   }
%   \end{tcl}
%   However, the same idea might also be used to simultaneously 
%   compute $A^{-1}B_1$, $A^{-1}B_2$, \dots, and $A^{-1}B_k$ for any 
%   number $k$ of matrices, so in anticipation of that being needed 
%   some day, the actual reduction is split off to a helper procedure 
%   |reduce_augmented_matrix| (which |inverse| could be changed to 
%   use as well).
% \end{proc}
% 
% \begin{proc}{reduce_augmented_matrix}
%   This procedure takes as its only argument an $n \times (n 
%   +\nobreak m)$ matrix $G$, performs Gauss--Jordan elimination on 
%   that, and returns the $n \times m$ submatrix of the result that 
%   one gets by dropping the first $n$ columns (as the dropped 
%   columns should anyway just be an identity matrix). Hence if
%   \[
%     G = \begin{bmatrix} A & B \end{bmatrix}
%     \qquad\text{then}\qquad
%     \texttt{[reduce\_augmented\_matrix $G$]} = A^{-1}B
%     \text{.}
%   \]
%   \begin{tcl}
   proc reduce_augmented_matrix {G} {
%   \end{tcl}
%   The whole body is one big loop (over the columns that are 
%   dropped). Conceptually each iteration changes the column at index 
%   $k$ to have $1$ on the diagonal and be $0$ otherwise, i.e., the 
%   Gauss and Jordan eliminations are not separated, but technically 
%   the reduced column is never explicitly computed. This means the 
%   current column is always the first in the current $G$.
%   \begin{tcl}
      for {set k 0} {$k < [llength $G]} {incr k} {
%   \end{tcl}
%   For each column, one must first find the pivot row $i_0$. This 
%   is also a nice place to detect that the matrix is singular, even 
%   if that hardly ever happens for numerical data; the procedure will 
%   happily continue to work with matrix elements smaller than the 
%   epsilon of the |double|s.
%   \begin{tcl}
         set best 0.0
         for {set i $k} {$i < [llength $G]} {incr i} {
            set abs [complex abs [lindex $G $i 0]]
            if {$abs > $best} then {
               set best $abs
               set i0 $i
            }
         }
         if {$best <= 0.0} then {
            return -code error -errorcode {API division unimplemented}\
              "No nonzero pivot after $k columns"
%   \end{tcl}
%   An interesting difference to |inverse| is that this operation 
%   should use the |unimplemented| error code rather than |nosolution| 
%   when it fails to find a pivot row, because it doesn't absolutely 
%   for sure know that there is no solution, only that the algorithm 
%   it applies cannot find it.
%   \begin{tcl}
         }
%   \end{tcl}
%   If it is not $k$, then swap the two.
%   \begin{tcl}
         if {$i0 != $k} then {
            set pivot [lindex $G $i0]
            lset G $i0 [lindex $G $k]
            lset G $k $pivot
         }
%   \end{tcl}
%   Now perform the elementary row operations that would make the 
%   current column $1$ on the diagonal and $0$ in other elements.
%   \begin{tcl}
         set dinv [complex inverse [lindex $G $k 0]]
         set drow [lrange [lindex $G $k] 1 end]
         set Gnew {}
         foreach row $G {
            set nrow {}
            if {[llength $Gnew] == $k} then {
               foreach c $drow {
                  lappend nrow [complex * $dinv $c]
               }
            } else {
               set mul [complex * [lindex $row 0] $dinv]
               foreach c [lrange $row 1 end] d $drow {
                  lappend nrow [complex - $c [complex * $mul $d]]
               }
            }
            lappend Gnew $nrow
         }
         set G $Gnew
      }
      return $G
   }
%   \end{tcl}
% \end{proc}
% 
% 
% 
% \subsubsection{Matrices as operators}
% 
% A matrix \(A \in \mathbb{C}^{n \times n}\) acts as a linear 
% operator on $\mathbb{C}^n$ by matrix--vector multiplication.
% 
% \begin{proc}{Mvprod}
%   This procedure implements multiplying a matrix by a column 
%   vector, encoded as a list of |complex| numbers. The syntax is
%   \begin{displaysyntax}
%     Mvprod \word{zero} \word{matrix} \word{vector}
%   \end{displaysyntax}
%   i.e., what one would expect for |.| in $\mathbb{C}^n$ viewed as a 
%   $\mathbb{C}^{n \times n}$-module.
%   \begin{tcl}
   proc Mvprod {zero A v} {
      set res {}
      foreach row $A {
         set sum [complex 0]
         foreach x $row y $v {
            set sum [complex + $sum [complex * $x $y]]
         }
         lappend res $sum
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{vMprod}
%   Anternatively, one may consider multiplying a row vector, encoded 
%   as a list of |complex| numbers, by a matrix. This procedure has 
%   the syntax
%   \begin{displaysyntax}
%     vMprod \word{zero} \word{vector} \word{matrix}
%   \end{displaysyntax}
%   and the return value is another row vector encoded just like the 
%   input \word{vector}.
%   \begin{tcl}
   proc vMprod {zero v A} {
      set res {}
      foreach col [lindex $zero 0] {
         set sum [complex 0]
         foreach x $v row $A {
            set sum [complex + $sum [complex * $x [
               lindex $row [llength $res]
            ]]]
         }
         lappend res $sum
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{Mcvprod}
%   It could however be argued that |vMprod| is doing it wrong, because 
%   a |vMprod| is the same thing as an |Mvprod| with the \emph{transpose} 
%   of the matrix, whereas the proper operation for switching rows and 
%   columns in $\mathbb{C}^{n \times n}$ is the Hermitian 
%   \emph{conjugate}. Well, there is no reason not to provide both 
%   options, so there is also
%   \begin{displaysyntax}
%     Mcvprod \word{zero} \word{matrix} \word{vector}
%   \end{displaysyntax}
%   which returns the product of the hermitian conjugate of the 
%   \word{matrix} by the \word{vector}.
%   \begin{tcl}
   proc Mcvprod {zero A v} {
      set res {}
      foreach col [lindex $zero 0] {
         set sum [complex 0]
         foreach x $v row $A {
            set sum [complex + $sum [complex * $x [
               complex conjugate [lindex $row [llength $res]]
            ]]]
         }
         lappend res $sum
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% Speaking of the Hermitian conjugate, surely that should be 
% available as a separate operation as well.
% 
% 
% \begin{proc}{conjugate}
%   The worst part of computing the Hermitian conjugate $C$ of a matrix 
%   is to do the transposition, but it turns out this too can be done 
%   with |foreach|. The idea is to loop over over the rows and 
%   columns on the result (using |Zero| as a template), fetching the 
%   element to conjugate using an explicit |lindex| into $A$.
%   \begin{tcl}
   proc conjugate {Zero A} {
      set C {}
      foreach row $Zero {
         set crow {}
         foreach zero $row {
            lappend crow [complex conjugate [
               lindex $A [llength $crow] [llength $C]
            ]]
         }
         lappend C $crow
      }
      return $C
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{hermitian_part}
% \begin{proc}{antihermitian_part}
%   A similar idea can be used to compute the Hermitian and 
%   anti-Hermitian parts of a matrix. Here it is more practical to 
%   use $A$ as template, since half of what goes into an element of 
%   the result $C$ comes from the corresponding element of $A$. The 
%   three numerical operations involved in the matrix level formula 
%   $\frac{1}{2}(A +\nobreak A^*)$ (halving, negating the imaginary 
%   part, and adding) are futhermore too easy to combine into a 
%   single |expr| to not do so.
%   \begin{tcl}
   proc hermitian_part {Zero A} {
      set C {}
      foreach row $A {
         set crow {}
         foreach z $row {
            lappend crow [list [
               expr {0.5 * ([lindex $z 0] +\
                 [lindex $A [llength $crow] [llength $C] 0])}
            ] [
               expr {0.5 * ([lindex $z 1] -\
                 [lindex $A [llength $crow] [llength $C] 1])}
            ]]
         }
         lappend C $crow
      }
      return $C
   }
   proc antihermitian_part {Zero A} {
      set C {}
      foreach row $A {
         set crow {}
         foreach z $row {
            lappend crow [list [
               expr {0.5 * ([lindex $z 0] -\
                 [lindex $A [llength $crow] [llength $C] 0])}
            ] [
               expr {0.5 * ([lindex $z 1] +\
                 [lindex $A [llength $crow] [llength $C] 1])}
            ]]
         }
         lappend C $crow
      }
      return $C
   }
%   \end{tcl}
% \end{proc}\end{proc}
% 
% \begin{proc}{vvcprod}
%   The procedure computes the matrix-valued product $uv^*$ of \(u,v 
%   \in \mathbb{C}^n\). It has the syntax
%   \begin{displaysyntax}
%     vvcprod \word{zero} \word{vector} \word{vector}
%   \end{displaysyntax}
%   \begin{tcl}
   proc vvcprod {zero u v} {
      set vc {}
      foreach z $v {lappend vc [complex conjugate $z]}
      set res {}
      foreach w $u {
         set row {}
         foreach z $vc {
            lappend row [complex * $w $z]
         }
         lappend res $row
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{maxrowsumnorm}
%   This procedure computes the matrix norm that is the maximum over 
%   the rows of the sum of the absolute values of the elements in that 
%   row.
%   \begin{tcl}
   proc maxrowsumnorm {Zero A} {
      set res 0.0
      foreach row $A {
         set sum 0.0
         foreach z $row {
            set sum [expr {$sum + [complex abs $z]}]
         }
         if {$sum > $res} then {set res $sum}
      }
      return $res
   }
%   \end{tcl}
%   This is the operator norm corresponding to the $\ell^\infty$ 
%   norm (also known as max norm) on $\mathbb{C}^n$, since for any 
%   given row $(A_{i1},\dotsc,A_{in})$ of $A$ it is possible to pick 
%   a vector \((x_1,\dotsc,x_n) \in \mathbb{C}^n\) with all elements 
%   of absolute value $1$ (and thus the vector has norm $1$) such that 
%   \((A_{i1},\dotsc,A_{in}) \cdot (x_1,\dotsc,x_n)^{\mathrm{T}}
%   = \sum_{j=1}^n \lvert A_{ij}\rvert\). That this is the worst 
%   possible follows trivially from the triangle inequality.
% \end{proc}
% 
% \begin{proc}{maxcolsumnorm}
%   This procedure computes the matrix norm that is the maximum over 
%   the columns of the sum the absolute values of the elements in that 
%   column.
%   \begin{tcl}
   proc maxcolsumnorm {Zero A} {
      set res 0.0
      for {set k 0} {$k < [llength $A]} {incr k} {
         set sum 0.0
         foreach row $A {
            set sum [expr {$sum + [complex abs [lindex $row $k]]}]
         }
         if {$sum > $res} then {set res $sum}
      }
      return $res
   }
%   \end{tcl}
%   This is the operator norm corresponding to the $\ell^1$ norm 
%   (also known as sum norm) on $\mathbb{C}^n$, since if $j$ is the 
%   column attaining the maximum sum then the norm of $A \mathbf{e}_j$ 
%   will be precisely that maximum. Conversely if \(\mathbf{x} = 
%   \sum_{i=1}^n x_i \mathbf{e}_i \in \mathbb{C}^n\) is a vector of 
%   unit norm then \(\sum_{i=1}^n \lvert x_i\rvert = 1\) and hence
%   \[
%     \lVert A\mathbf{x} \rVert = 
%     \biggl\| \sum_{i=1}^n x_i A \mathbf{e}_i \biggr\| \leqslant
%     \sum_{i=1}^n \lvert x_i\rvert \, \lVert A\mathbf{e}_i \rVert
%     \leqslant 
%     \biggl( \sum_{i=1}^n \lvert x_i\rvert \biggr)
%       \max_{1 \leqslant i \leqslant n} \lVert A\mathbf{e}_i \rVert
%     = \lVert A\mathbf{e}_j \rVert
%     \text{.}
%   \]
% \end{proc}
% 
% 
% \subsubsection{Lie operations}
% 
% \begin{proc}{exp}
%   Computing the matrix exponential is a somewhat trickier matter. 
%   Following Higham~\cite[Ch.~10]{Higham}, this will be done by 
%   combining the Pad\'e approximant \(r_m(x) = p_m(x) \big/ q_m(x)\) 
%   of $e^x$, where
%   \begin{align*}
%     p_m(x) ={}& \sum_{j=0}^m 
%       \frac{(2m-j)!\, m!}{(2m)! \, (m-j)!} \frac{x^j}{j!} =
%     \frac{m!}{(2m)!} \sum_{j=0}^m \frac{(2m-j)!}{(m-j)!} \frac{x^j}{j!}
%       \quad\text{and}\\
%     q_m(x) ={}& \sum_{j=0}^m 
%       \frac{(2m-j)!\, m!}{(2m)! \, (m-j)!} \frac{(-x)^j}{j!} 
%       = p_m(-x) \text{,}
%   \end{align*}
%   with scaling and squaring. 
%   Because \(q_m(x) = p_m(-x)\), it follows that \(p_m(A) = B+C\) 
%   and \(q_m(A) = B-C\) where $B$ is the even part (even powers of 
%   $A$) of $p_m(A)$ and $C$ is the odd part (odd powers of $A$). 
%   Therefore the computation of these $B$ and $C$ constitutes an 
%   important intermediate goal for much of the code below, since from 
%   there one obtains $r_m(A)$ as $(B -\nobreak C)^{-1} 
%   (B +\nobreak C)$.
%   
%   \begin{tcl}
   proc exp {Zero A} {
      set squarings 0
      set norm [maxcolsumnorm $Zero $A]
      if {$norm <= 1.5e-2} then {
%   \end{tcl}
%   It is natural that the choice of $m$ for the Pad\'e approximant 
%   $r_m$ is made dependent on the norm of $A$, as small exponents 
%   are well cared for also by simpler (and thus computationally 
%   cheaper) approximants. With $64$-bit IEEE floats and a norm as 
%   above, it is sufficient to take \(m=3\). Following 
%   \cite[Table~10.4]{Higham}, the coefficients are normalised to 
%   make that of $A^m$ equal to $1$, which corresponds to dropping 
%   the constant $m!/(2m!)$ factor in the above formula for $p_m$.
%   \begin{tcl}
         set A2 [* $Zero $A $A]
         set A0 [1 $Zero]
         set B [+. $Zero  12.0 $A2  120.0 $A0]
         set C [* $Zero $A [+. $Zero  $A2  60.0 $A0]]
%   \end{tcl}
%   For any \(2k>3\), one can compute the odd and even parts of 
%   $p_{2k+1}$ in the same number of matrix multiplications as ditto 
%   of $p_{2k}$, so it only makes sense to have separate cases for 
%   odd $m$. The next case is thus \(m=5\), which needs one 
%   additional matrix multiplication to compute $A^4$.
%   \begin{tcl}
      } elseif {$norm <= 2.5e-1} then {
         set A0 [1 $Zero]
         set A2 [* $Zero $A $A]
         set A4 [* $Zero $A2 $A2]
         set B [+. $Zero  30.0 $A4  3360.0 $A2  30240.0 $A0]
         set C [* $Zero $A [+. $Zero  $A4  420.0 $A2  15120.0 $A0]]
%   \end{tcl}
%   For \(m=7\), one almost gets up to norm $1$.
%   \begin{tcl}
      } elseif {$norm <= 9.5e-1} then {
         set A0 [1 $Zero]
         set A2 [* $Zero $A $A]
         set A4 [* $Zero $A2 $A2]
         set A6 [* $Zero $A4 $A2]
         set B [+. $Zero 56.0 $A6 252e2 $A4 199584e1 $A2 1729728e1 $A0]
         set C [* $Zero $A\
           [+. $Zero $A6 1512.0 $A4 2772e2 $A2 864864e1 $A0]]
%   \end{tcl}
%   For \(m=9\), one barely gets past norm $2$.
%   \begin{tcl}
      } elseif {$norm <= 2.1} then {
         set A0 [1 $Zero]
         set A2 [* $Zero $A $A]
         set A4 [* $Zero $A2 $A2]
         set A6 [* $Zero $A4 $A2]
         set A8 [* $Zero $A4 $A4]
         set B [+. $Zero  9e1 $A8  11088e1 $A6  3027024e1 $A4 \
           20756736e2 $A2  176432256e2 $A0]
         set C [* $Zero $A\
           [+. $Zero  $A8  396e1 $A6  216216e1 $A4  3027024e2 $A2 \ 
             88216128e2 $A0]]
      } else {
%   \end{tcl}
%   Taking \(m=11\) would give sufficient accuracy for norms up to $3.6$, 
%   but it turns out that another arrangement of the required six matrix 
%   multiplication suffice for computing $p_{13}$ and $q_{13}$, which 
%   are good for norms up to $5.4$. Beyond that the cost in matrix 
%   multiplications for squaring starts to become smaller than for 
%   improving the Pad\'e approximant, so the \(m=13\) case is the 
%   last approximant to be implemented.
%   \begin{tcl}
         set factor 1.0
         while {$norm*$factor > 5.4} {
            set factor [expr {$factor*0.5}]
            incr squarings
         }
         if {$squarings} then {set A [. $Zero $factor $A]}
         set A0 [1 $Zero]
         set A2 [* $Zero $A $A]
         set A4 [* $Zero $A2 $A2]
         set A6 [* $Zero $A4 $A2]
         set B [+. $Zero [* $Zero $A6 [
            +. 182.0 $A6  96096e1 $A4  132324192e1 $A2  6704425728e2 $A0
         ]]  129060195264e3 $A4  77717703038976e2 $A2  6476475253248e4 $A0]
         set C [* $Zero $A [+. $Zero [* $Zero $A6 [
            +.  $A6  1638e1 $A4  408408e2 $A2  3352212864e1 $A0
         ]]  105594705216e2 $A4  11873537964288e2 $A2  3238237626624e4 $A0]]
      }
%   \end{tcl}
%   Now only the division and squarings remain.
%   \begin{tcl}
      set X [* $Zero [
         inverse $Zero [- $Zero $B $C]
      ] [
         + $Zero $B $C
      ]]
      for {} {$squarings > 0} {incr squarings -1} {
         set X [* $Zero $X $X]
      }
      return $X
   }
%   \end{tcl}
%   It should be observed that the squaring step may give rise to 
%   numerical instability; it is apparently in general an open problem 
%   in which cases this happens~\cite[p.~247--250]{Higham}.
%   
%   \medskip
%   
%   Maintenance-wise, a complicated part of the code above is the 
%   coefficients in the various Pad\'e approximants. The following 
%   procedures can be used to compute these for any $p_m$:
%   \begin{tcl}
%</CMRS>
%<*develop>
proc tcl::mathfunc::fact {n} {
   set res 1
   for {set i 1} {$i<=$n} {incr i} {
      set res [expr {$res*$i}]
   }
   return $res
}
proc Pade {m} {
   set res {}
   for {} {[llength $res] <= $m} {} {
      lappend res [expr {fact(2*$m-[llength $res]) /\
        fact([llength $res]) / fact($m-[llength $res])}]
   }
   return $res
}
%</develop>
%<*CMRS>
%   \end{tcl}
%   Using them is likely to be far more reliable than copying numbers 
%   from a book.
%   
%   \medskip
%   
%   Finally, it should be verified that this \emph{matrix} exponential 
%   function also is a \emph{Lie group} exponential map, since that 
%   is strongly suggested by the present context. Thus we need to 
%   consider the curve
%   \[
%     \theta(t) := e^{tA} = \sum_{k=0}^\infty \frac{(tA)^k}{k!}
%     \text{.}
%   \]
%   That this satisfies \(\theta(s +\nobreak t) = \theta(s) \cdot
%   \theta(t)\) follows from the power series expansion just as for 
%   the formal power series exponential function:
%   \begin{multline*}
%     \theta(s+t) =
%     \sum_{k=0}^\infty \frac{\bigl( (s+t) A \bigr)^k}{k!} =
%     \sum_{k=0}^\infty \frac{(sA + tA)^k}{k!} = \\ =
%     \sum_{k=0}^\infty \frac{1}{k!} \sum_{l=0}^k \binom{k}{l} 
%       (sA)^{k-l} (tA)^l = 
%     \sum_{0 \leqslant l \leqslant k} \frac{1}{(k-l)! \, l!} 
%       (sA)^{k-l} (tA)^l 
%       \stackrel{(k-l=m)}= \\ =
%     \sum_{0 \leqslant m} \sum_{0 \leqslant l} 
%       \frac{(sA)^m}{m!} \frac{(tA)^l}{l!} = 
%     \biggl( \sum_{m=0}^\infty \frac{(sA)^m}{m!} \biggr) 
%       \biggl( \sum_{l=0}^\infty \frac{(tA)^l}{l!} \biggr) =
%     \theta(s) \cdot \theta(t) \text{.}
%   \end{multline*}
%   Similarly for the derivative,
%   \begin{multline*}
%     \theta'(0) =
%     \lim_{t \to 0} \frac{\theta(t) - \theta(0)}{t} =
%     \lim_{t \to 0} \frac{1}{t}\biggl( 
%       \sum_{k=0}^\infty \frac{(tA)^k}{k!} - I \biggr) =
%     \lim_{t \to 0} \frac{1}{t} \sum_{k=1}^\infty \frac{(tA)^k}{k!} 
%       = \\ =
%     \lim_{t \to 0} \sum_{k=1}^\infty \frac{A (tA)^{k-1}}{k!} = 
%     \sum_{k=1}^\infty \frac{A (0A)^{k-1}}{k!} = 
%     \frac{A}{1!} = A
%     \text{.}
%   \end{multline*}
%   Hence $\theta$ is indeed the one-parameter subgroup that figures 
%   in the definition of the Lie |exp |$A$.
% \end{proc}
% 
% 
% Having established the exponential map, one can use it to extend 
% derivations at the identity (the space of which is isomorphic to the 
% |tangent| space, i.e., plain old matrices) to vector fields. In 
% the modern differential geometry setting, a \emph{vector field} on 
% a manifold is an operator on the ring of smooth functions on that 
% manifold, so one way to define it is to give a formula for the real 
% number one gets back when applying the vector field to a function 
% and a point. Thus a defining equation for a vector field $L^A$ can 
% syntactically be
% \begin{equation}
%   L^A(f)(P) = \lim_{t \rightarrow 0} \frac{f(P e^{tA}) - f(P)}{t}
% \end{equation}
% where \(f\colon \mathbb{C}^n \longrightarrow \mathbb{R}\) is the 
% function, \(P \in \mathbb{C}^n\) is the point at which $L^A(f)$ is 
% evaluated, and \(A \in \mathbb{C}^n\) is the tangent at the identity 
% which gets extended to the vector field $L^A$. By substituting 
% \(P=I\) one sees that the value of $L^A(f)$ at $I$ is indeed the 
% directional derivative at $I$ of $f$ in the $A$ direction.
% 
% Merely having thrown up a syntactically correct formula for an 
% operator on the ring of smooth functions does of course not mean 
% that said formula really defines a vector field, but it's not far 
% from it, as any operator which is linear and satisfies the product 
% rule fully qualifies as a vector field. Linearity is a trivial 
% exercise. For the product rule \(L^A(f \cdot\nobreak g) = L^A(f) 
% \cdot g + f \cdot L^A(g)\), one may (essentially by following the 
% elementary calculus proof of the ordinary product rule) observe 
% that
% \begin{align*}
%   L^A(f \cdot g)(P) ={}&
%   \lim_{t \rightarrow 0} 
%   \frac{(f \cdot g)(P e^{tA}) - (f \cdot g)(P)}{t}
%   = \\ ={}&
%   \lim_{t \rightarrow 0} 
%   \frac{f(P e^{tA}) g(P e^{tA}) - f(P) g(P)}{t}
%   = \displaybreak[0]\\ ={}&
%   \lim_{t \rightarrow 0} 
%   \frac{f(P e^{tA}) g(P e^{tA}) - f(P) g(P e^{tA})}{t}
%   +
%   \lim_{t \rightarrow 0} 
%   \frac{f(P) g(P e^{tA}) - f(P) g(P)}{t}
%   = \displaybreak[0]\\ ={}&
%   \lim_{t \rightarrow 0} \frac{f(P e^{tA}) - f(P)}{t}
%   \lim_{t \rightarrow 0} g(P e^{tA})
%   +
%   f(P) \lim_{t \rightarrow 0} \frac{g(P e^{tA}) - g(P)}{t}
%   = \\ ={}&
%   L^A(f)(P) g(P) + f(P) L^A(g)(P)
%   =
%   \bigl( L^A(f) \cdot g + f \cdot L^A(g) \bigr)(P)
% \end{align*}
% and thus every such $L^A$ is indeed a vector field.
% 
% For vector fields as operators to be of interest, one would need 
% some kind of explicit representation of functions for them to 
% operate on, but that is not available here, so what use are they? 
% Well, it turns out that vector fields support some nontrivial 
% operations. From the definition of vector fields as operators, it 
% follows for example that one from two vector fields $L^A$ and $L^B$ 
% can form their composition $L^A \circ L^B$, which maps some 
% function $f$ to $L^A\bigl( L^B(f) \bigr)$. While the composition of 
% two vector fields is not itself a vector field (because it fails to 
% satisfy the product rule), the so-called \emph{commutator} 
% \([X,Y] := X \circ Y - Y \circ X\) of two vector 
% fields $X$ and $Y$ is again a vector field:
% \begin{align*}
%   [X,Y](f \cdot g) 
%   ={}&
%   X\bigl( Y(f \cdot g) \bigr) - Y\bigl( X(f \cdot g) \bigr)
%   = \\ ={}&
%   X\bigl( Y(f) \cdot g + f \cdot Y(g) \bigr) 
%   - Y\bigl( X(f) \cdot g + f \cdot X(g) \bigr)
%   = \displaybreak[0]\\ ={}&
%   X\bigl( Y(f) \cdot g\bigr) + X\bigl( f \cdot Y(g) \bigr) 
%   - Y\bigl( X(f) \cdot g\bigr) - Y\bigl( f \cdot X(g) \bigr)
%   = \displaybreak[0]\\ ={}&
%   X\bigl( Y(f) \bigr) \cdot g + Y(f) \cdot X(g) 
%   + X(f) \cdot Y(g) + f \cdot X\bigl( Y(g) \bigr) 
%     + \\ & \quad{}
%   - Y\bigl( X(f) \bigr) \cdot g - X(f) \cdot Y(g) 
%   - Y(f) \cdot X(g) - f \cdot Y\bigl( X(g) \bigr)
%   = \displaybreak[0]\\ ={}&
%   \Bigl( X\bigl( Y(f) \bigr) - Y\bigl( X(f) \bigr) \Bigr) \cdot g 
%   + f \cdot \Bigl( X\bigl( Y(g) \bigr) - Y\bigl( X(g) \bigr) \Bigr)
%   = \\ ={}&
%   [X,Y](f) \cdot g + f \cdot [X,Y](g)
% \end{align*}
% as required by the product rule. Since a vector field determines a 
% derivation at the identity, and thus a |tangent| element, this 
% gives rise to another \(\mathbb{C}^n \times \mathbb{C}^n  
% \longrightarrow \mathbb{C}^n\) operation, and one which is 
% intrinsically linked to the Lie algebra structure to boot! But what 
% is this operation in terms of the matrix elements?
% 
% 
% \begin{proc}{commutator}
%   For working out the concrete effect of composing vector fields, 
%   it is convenient to first consider the case that the function $f$ 
%   is linear. In that case one gets
%   \begin{align*}
%     L^A\bigl( L^B(f) \bigr)(P) 
%     ={}&
%     \lim_{t \to 0} \frac{ L^B(f)(P e^{tA}) - L^B(f)(P) }{ t }
%     = \displaybreak[0]\\ ={}&
%     \lim_{t \to 0} \frac{ 
%       \lim_{s \to 0} \frac{ f( P e^{tA} e^{sB} ) - f(P e^{tA}) }{s}
%       -
%       \lim_{s \to 0} \frac{ f( P e^{sB} ) - f(P) }{s}
%     }{ t }
%     = \displaybreak[0]\\ ={}&
%     \lim_{t \to 0} \frac{ 
%       \lim_{s \to 0} f\left( P e^{tA} \frac{ e^{sB} - I }{s} \right)
%       -
%       \lim_{s \to 0} f\left( P \frac{ e^{sB} - I }{s} \right)
%     }{ t }
%     = \displaybreak[0]\\ ={}&
%     \lim_{t \to 0} \frac{ 
%       f( P e^{tA} B) - f(P B)
%     }{ t }
%     = 
%     \lim_{t \to 0} \frac{ 
%       f( P e^{tA} B - P B)
%     }{ t }
%     = \displaybreak[0]\\ ={}&
%     \lim_{t \to 0} f\left( P \frac{e^{tA} - I}{t} B \right)
%     = \\ ={}&
%     f(P AB)
%     = \displaybreak[0]\\ ={}&
%     \lim_{t \to 0} f\left( P \frac{e^{tAB} - I}{t} \right)
%     = \\ ={}&
%     \lim_{t \to 0} \frac{ f( P e^{tAB} ) - f(P) }{t} 
%     =
%     L^{AB}(f)(P) \text{.}
%   \end{align*}
%   It follows that \([L^A,L^B](f) = L^{AB-BA}(f)\) for linear $f$. 
%   Since the set of linear functions include the component functions 
%   (|coeff| below), and since the components of $P$ together 
%   determine $P$, it follows that a general real-valued function of 
%   $P$ can be viewed as a composition of some function 
%   \(\mathbb{R}^{2n^2} \longrightarrow \mathbb{R}\) with the $2n^2$ 
%   standard component functions, and hence \([L^A,L^B](f) = 
%   L^{AB-BA}(f)\) holds for general $f$ by the ordinary multivariate 
%   chain rule. (The same argument does not yield \( (L^A 
%   \circ\nobreak L^B)(f) = L^{AB}(f)\) for general $f$, because $L^A 
%   \circ L^B$ is not a vector field.)
%   
%   So\dots\ the Lie bracket of two matrices is simply what one gets 
%   from the elementary commutator formula \([A,B] = AB - BA\):
%   \begin{tcl}
   proc commutator {Zero A B} {
      - $Zero [* $Zero $A $B] [* $Zero $B $A]
   }
%   \end{tcl}
%   How droll! Why go through all those calculations, if all that had 
%   to be done was to replace composition $\circ$ by matrix 
%   multiplication? Aren't they even the same??
%   
%   Well, it's not quite that straightforward. It turns out that what 
%   formula one gets depends on which family of vector fields one 
%   uses. An equally valid alternative choice of vector fields would 
%   be the family
%   \begin{equation*}
%     R^A(f)(P) = \lim_{t \rightarrow 0} \frac{f(e^{tA} P) - f(P)}{t}
%   \end{equation*}
%   and these (as becomes apparent if one goes through the analogous 
%   calculations) rather satisfy \([R^A,R^B] = R^{BA-AB}\), which is 
%   the opposite operation on matrices. So it is not simply a matter 
%   of the operator composition being equal to matrix multiplication, 
%   even though the final result may give that impression.
%   On the other hand, the $L^A$ (left-invariant vector fields) and 
%   $R^A$ (right-invariant vector fields) are in a sense the only two 
%   canonical choices for vector fields in this construction, and 
%   since the brackets they give rise to are each other's negations, 
%   the |commutator| above is up to isomorphism the only one that it 
%   makes sense to define.
% \end{proc}
% 
% 
% \subsubsection{Import and export}
% 
% A less mathematical issue is that the space of complex matrices 
% should be equipped with a standard basis. A suitable choice of 
% indices is the |lindex| indices that selects a real number 
% component from the element, e.g.~the imaginary part of $A_{1,2}$ 
% has index `|0 1 1|' (remember that |lindex| indices are zero-based).
% 
% \begin{proc}{coeff}
%   That choice makes |coeff| trivial.
%   \begin{tcl}
   proc coeff {Zero index A} {lindex $A $index}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{basiselement}
%   Constructing a basis element is also extremely easy, since it 
%   suffices to replace one element of the |Zero| matrix.
%   \begin{tcl}
   proc basiselement {Zero index} {lset Zero $index 1.0}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{support}
%   Computing the |support| of some matrix $A$ is straightforward, 
%   but requires looping over three levels of list elements.
%   \begin{tcl}
   proc support {Zero A} {
      set res {}
      set i 0
      foreach row $A {
         set j 0
         foreach cell $row {
            set k 0
            foreach part $cell {
               if {$part != 0.0} then {
                  lappend res [list $i $j $k]
               }
               incr k
            }
            incr j
         }
         incr i
      }
      return $res
   }
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{basis}
%   A structure for the chosen set of indices can be conveniently 
%   implemented as the |mtmtcl::sets::cartesian_product| of three 
%   |mtmtcl::sets::finite_ordinal|s with cardinalities $n$, $n$, and 
%   $2$ respectively; this alone accounts for two of the dependencies 
%   of this package.
%   \begin{tcl}
   proc basis {Zero args} {
      tailcall ::mtmtcl::sets::cartesian_product [list [
         list ::mtmtcl::sets::finite_ordinal [llength $Zero]
      ] [
         list ::mtmtcl::sets::finite_ordinal [llength $Zero]
      ] {::mtmtcl::sets::finite_ordinal 2}] {} {*}$args
   }
%   \end{tcl}
% \end{proc}
% 
% 
% 
% \begin{proc}{export}
%   A natural export format is to use \OMSref{linalg2}{matrix}, i.e., 
%   to express the matrix as a list of rows 
%   (\OMSref{linalg2}{matrixrow}) of whatever a |complex| number is 
%   exported as.
%   \begin{tcl}
   proc export {Zero A attr} {
      set oattr $attr
      dict lappend attr mtmtcl:path C
      set rowL {}
      foreach row $A {
         set cellL {}
         foreach cell $row {
            lappend cellL [complex export $cell $attr]
         }
         lappend rowL\
           [::mtmtcl::openmath::OM AS linalg2 matrixrow {*}$cellL]
      }
      return [list OMA $oattr [linsert $rowL 0 [
         ::mtmtcl::openmath::OM mS linalg2 matrix $oattr {}
      ]]]
   }
%   \end{tcl}
%   One point above that may need a second though is the handling of 
%   common attributes. Since a |C| is appended to the |mtmtcl:path| 
%   handed over to |complex export|, the structure of matrices should 
%   have a method by that name which gives access to |complex|. One 
%   might also wonder whether the handling of attributes (put them on 
%   the root |OMA| and its first child) is optimal.
% \end{proc}
% 
% \begin{proc}{C}
%   Well, defining the |C| method for accessing |complex| is just a 
%   matter of throwing away the |Zero| parameter of the complex 
%   matrix structure.
%   \begin{tcl}
   proc C {Zero args} {tailcall complex {*}$args}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{import}
%   For importing, this structure also accepts the 
%   \OMSref{linalg3}{matrix}, i.e., a matrix as a list of columns.
%   \begin{tcl}
   proc import {Zero path tree} {
      set epath [linsert $path end C]
      while {[lindex $tree 0] eq "OMATTR"} {
         set tree [lindex $tree 2 1]
      }
      ::mtmtcl::openmath::OMAS_switch $tree {
      } http://www.openmath.org/cd/linalg2#matrix {
%   \end{tcl}
%   Unlike the case with vectors, the \OMSref{linalg2}{matrix} and 
%   \OMSref{linalg3}{matrix} need separate treatment. The handling of 
%   the former is straightforward, since its data structure matches 
%   that of the wanted result.
%   \begin{tcl}
         set res {}
         foreach rowtree [lrange [lindex $tree 2] 1 end] {
            while {[lindex $rowtree 0] eq "OMATTR"} {
               set rowtree [lindex $rowtree 2 1]
            }
            ::mtmtcl::openmath::OMAS_switch $rowtree {
            } http://www.openmath.org/cd/linalg2#matrixrow {
               set row {}
               foreach celltree [lrange [lindex $rowtree 2] 1 end] {
                  lappend row [complex import $epath $celltree]
               }
               if {[llength $row] != [llength $Zero]} then {
                  return -code error -errorcode\
                    [list API import EDOM $path $rowtree] \
                    "Expected [llength $Zero] elements in row,\
                      got [llength $row] elements"
               }
               lappend res $row
               continue
%   \end{tcl}
%   That |continue| is effectively a |goto| past the following error 
%   message, which is common for the not-an-\texttt{OMA} and 
%   \texttt{OMA}-with-wrong-function cases of error. A similar error 
%   message, for the corresponding situation one level higher, comes 
%   at the end of the procedure.
%   \begin{tcl}
            }
            return -code error -errorcode\
              [list API import EDOM $path $rowtree] \
              "Expected an OMA for matrixrow@linalg2"
         }
         if {[llength $res] == [llength $Zero]} then {
            return $res
         } else {
            return -code error \
              -errorcode [list API import EDOM $path $tree] \
              "Expected [llength $Zero] rows in matrix,\
                got [llength $res] rows"
         }
%   \end{tcl}
%   A matrix of columns is a bit trickier to import. The approach 
%   used here is add elements in the order they are read, which means 
%   the rows of the matrix will be iterated over several times. (An 
%   alternative approach could be to start with |Zero| and overwrite 
%   elements as they are parsed.)
%   \begin{tcl}
      } http://www.openmath.org/cd/linalg3#matrix {
         set res {}
         if {[llength [lindex $tree 2]]-1 != [llength $Zero]} then {
            return -code error \
              -errorcode [list API import EDOM $path $tree] \
              "Expected [llength $Zero] columns in matrix,\
                got [expr {[llength [lindex $tree 2]]-1}] columns"
         }
         foreach coltree [lrange [lindex $tree 2] 1 end] {
            while {[lindex $coltree 0] eq "OMATTR"} {
               set rowtree [lindex $coltree 2 1]
            }
            ::mtmtcl::openmath::OMAS_switch $coltree {
            } http://www.openmath.org/cd/linalg3#matrixcolumn {
               set cols [lrange [lindex $coltree 2] 1 end]
               if {[llength $cols] != [llength $Zero]} then {
%   \end{tcl}
%   For this kind of matrix, the length of a column is checked before 
%   its elements are parsed.
%   \begin{tcl}
                  return -code error -errorcode\
                    [list API import EDOM $path $coltree] \
                    "Expected [llength $Zero] elements in column,\
                      got [llength $cols] elements"
               }
               set nextres {}
               foreach celltree $cols {
%   \end{tcl}
%   The following command employs the fact that |lindex| from a position 
%   beyond the end of the list returns an empty string, which is also 
%   an empty list and thus precisely what one wants for |row| in the 
%   first column.
%   \begin{tcl}
                  set row [lindex $res [llength $nextres]]
                  lappend row [complex import $epath $celltree]
                  lappend nextres $row
               }
               set res $nextres
               continue
            }
            return -code error -errorcode\
              [list API import EDOM $path $coltree] \
              "Expected an OMA for matrixcolumn@linalg3"
         }
         return $res
      }
      return -code error -errorcode [list API import EDOM $path $tree]\
        "Expected an OMA for matrix@linalg2 or @linalg3"
   }
%   \end{tcl}
% \end{proc}
% 
% 
% \subsubsection{The ensemble}
% \label{Sssec:CMRS-ensemble}
% 
% \setnamespace{mtmtcl::Lie}
% 
% \begin{tclcommand}{ensemble}{complex_matrix_real_space}
%   Now the only command left to define is the overall ensemble.
%   \begin{tcl}
   namespace ensemble create -subcommands {
      = neg + 0 - iszero
%   \end{tcl}
%   Those fulfill \APIref+{equality}{1.0} and \APIref+{additive 
%   group}{2.1}.
%   \begin{tcl}
      scalar . C C. +. +R2.
%   \end{tcl}
%   Those fulfill the \APIref+{ring-module}{2.1} interface. |C|, |C.|, 
%   |+.|, and |+R2.| are not covered by interfaces.
%   \begin{tcl}
      innerprod Frobenius_norm distance
%   \end{tcl}
%   Those fulfill the \APIref+{inner product space}{1.1} and 
%   \APIref+{metric space}{1.2} interfaces. |Frobenius_norm| is not 
%   covered by an interface.
%   \begin{tcl}
      * 1 inverse det /
%   \end{tcl}
%   Those fulfill the \APIref+{ring}{2.0}, \APIref+{monoid}{1.1}, 
%   \APIref+{semigroup}{1.1}, and \APIref+{division}{1.0} interfaces. 
%   |inverse| and |det| are not covered by an interface.
%   \begin{tcl}
      Mvprod vMprod conjugate hermitian_part antihermitian_part
      Mcvprod vvcprod maxrowsumnorm maxcolsumnorm
      exp commutator
%   \end{tcl}
%   None of these are covered by an interface.
%   \begin{tcl}
      basis basiselement coeff support
%   \end{tcl}
%   These fulfill the \APIref+{free ring-module}{2.1} interface.
%   \begin{tcl}
      export import
%   \end{tcl}
%   These fulfill the \APIref+{export}{2.0} and \APIref+{import}{1.0} 
%   interfaces.
%   \begin{tcl}
      API
   } -map {
      API {::API::staticn 1 {
         equality              1.0
         "additive group"      2.1
         ring                  2.0
         monoid                1.1
         semigroup             1.1
         division              1.0
         ring-module           2.1
         ring-algebra          2.0
         "inner product space" 1.1
         "metric space"        1.2
         export                2.0
         import                1.0
      }}
      distance   Frobenius_distance
   } -parameters {Zero} -prefix 0
%   \end{tcl}
% \end{tclcommand}
% 
% 
% 
% \begin{tcl}
}
%</CMRS>
% \end{tcl}
% 
% 
% \subsection{The group of unitary matrices}
% 
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::unitary 1.0 unitary
%</docstrip.tcl::catalogue>
% \end{tcl}
% For implementing the operations of this Lie group and algebra, one 
% frequently wants to make use of the offerings of the 
% |complex_matrix_real_space| package, so that namespace is installed 
% in the |namespace path|.
% \begin{tcl}
%<*unitary>
package require Tcl 8.6
package require mtmtcl::sets::cartesian_product 1.1
package require mtmtcl::sets::finite_ordinal 1.0
package require mtmtcl::support::subset 1.0
package require mtmtcl::Lie::complex_matrix_real_space 1.0
namespace eval ::mtmtcl::Lie::unitary {
   namespace path ::mtmtcl::Lie::complex_matrix_real_space
}
% \end{tcl}
% \setnamespace{mtmtcl::Lie::unitary}
% 
% 
% \subsubsection{The algebra}
% 
% The Lie algebra $\mathfrak{u}(n)$ is mathematically a structure 
% that depends on the Lie group $\mathrm{U}(n)$, so it might seem odd 
% to start an exposition with the algebra, but it turns out that the 
% implementations of several operations in the group are hard to 
% explain without reference to what the tangent space looks like, and 
% that is the major part of explaining the algebra.
% 
% A unitary matrix $U$ is characterised by the property that \(U^* U 
% = I\), where $U^*$ denotes the Hermitian conjugate of $U$. If $A$ 
% is a tangent at $I$ to the unitary group, then \(U = I + 
% \varepsilon A\) (where $\varepsilon$ is a formal infinitesimal 
% satisfying \(\varepsilon^2=0\)) must also satisfy the same 
% equation, so
% \[
%   I = 
%   (I + \varepsilon A)^* (I + \varepsilon A) =
%   (I + \varepsilon A^*) (I + \varepsilon A) =
%   I + \varepsilon A + \varepsilon A^* + \varepsilon^2 A^* A =
%   I + \varepsilon (A + A^*)
%   \text{.}
% \]
% Since \(\varepsilon \neq 0\), it follows that \(A + A^* = 0\), or 
% equivalently \(A^* = -A\), i.e., $A$ must be antihermitian. 
% Conversely any antihermitian matrix is tangent to $\mathrm{U}(n)$ 
% at $I$ by the same calculation, so it follows that 
% $\mathfrak{u}(n)$ can be identified with the set of antihermitian 
% matrices.
% 
% \begin{tclcommand}{ensemble}{algebra}
%   This means enough methods of the Lie algebra are already 
%   available that it makes sense to proceed to setting up the 
%   ensemble. As with |complex_matrix_real_space|, this will have as 
%   its lone parameter a zero matrix of the correct size:
%   \begin{displaysyntax}
%     ::mtmtcl::Lie::unitary::algebra \word{zero} \word{method}
%     \word{argument}\regstar
%   \end{displaysyntax}
%   since this allows sharing many method implementations.
%   
%   Indeed, there are so many methods that can be shared outright 
%   that it is easier to attach this ensemble to the 
%   |complex_matrix_real_space| namespace and map in a few specialty 
%   methods from the |unitary| namespace than to do the (more 
%   conventional) opposite.
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::complex_matrix_real_space {
   namespace ensemble create -map {
%   \end{tcl}
%   First, there are the methods for an \APIref+{additive group}{2.1},
%   \begin{tcl}
      =      =
      +      +
      0      0
      neg    neg
      -      -
      iszero iszero
%   \end{tcl}
%   then the extra methods for a \APIref+{ring-algebra}{2.1},
%   \begin{tcl}
      .      .
      scalar scalar
      *      commutator
%   \end{tcl}
%   and the methods for an \APIref+{inner product space}{1.1} and 
%   \APIref+{metric space}{1.2}.
%   \begin{tcl}
      innerprod innerprod
      distance  Frobenius_distance
%   \end{tcl}
%   As |superset| of this algebra, for the \APIref+{subset}{2.1} 
%   interface, one preferably uses the ever present 
%   |complex_matrix_real_space|. 
%   The corresponding |improve| method will be the first to make use 
%   of information specific to the unitary case.
%   \begin{tcl}
      superset  ::mtmtcl::Lie::complex_matrix_real_space
      improve   antihermitian_part
%   \end{tcl}
%   Now, this |improve| is clearly a projection of $\mathbb{C}^{n 
%   \times n}$ onto $\mathfrak{u}(n)$, but does it necessarily 
%   produce the antihermitian matrix most closely approximated by its 
%   argument? This will of course depend on the metric used, but 
%   since \(B - \texttt{[antihermitian\_part $B$]} = 
%   \texttt{[hermitian\_part $B$]}\), it is worth observing that for 
%   an antihermitian matrix $A$ and a Hermitian matrix $H$,
%   \begin{multline*}
%     \langle A,H\rangle =
%     \operatorname{Re} \operatorname{tr} (A^* H) =
%     \operatorname{Re} \operatorname{tr} (-A H) =
%     -\operatorname{Re} \operatorname{tr} (A H) = \\ =
%     -\operatorname{Re} \operatorname{tr} (H A) =
%     -\operatorname{Re} \operatorname{tr} (H^* A) =
%     -\langle H, A\rangle =
%     -\langle A, H\rangle \text{,}
%   \end{multline*}
%   and thus this inner product is $0$; a Hermitian matrix is always 
%   orthogonal to an antihermitian matrix. Hence |antihermitian_part| 
%   performs an orthogonal projection, and \emph{that} we know how it 
%   is the closest approximation.
%   
%   Importing data into $\mathfrak{u}(n)$ is not a straightforward 
%   operation, since any way of handling matrices that are not 
%   antihermitian runs the risk of making inappropriate assumptions. 
%   Therefore it is better to let the user import the data into the 
%   |superset|, and then explicitly proceed according to whichever 
%   assumptions are appropriate. Exporting data is not similarly 
%   troublesome, but one should tag the data as rather having been 
%   exported from the |superset|.
%   \begin{tcl}
      export    {::mtmtcl::support::subset::superexport1p\
                   ::mtmtcl::Lie::complex_matrix_real_space}
%   \end{tcl}
%   So, which are the interfaces that this Lie algebra supports? 
%   \begin{tcl}
      API {::API::staticn 1 {
         equality              1.0
         "additive group"      2.1
         ring                  2.0
         ring-module           2.1
         ring-algebra          2.0
         "Lie algebra"         1.0
         "inner product space" 1.1
         "metric space"        1.2
         subset                2.1
         export                2.0
         "free ring-module"    2.1
      }}
%   \end{tcl}
%   What remains for this ensemble to |-map| is thus only the methods 
%   for a \APIref+{free ring-module}{2.1}.
%   \begin{tcl}
      basiselement ::mtmtcl::Lie::unitary::basiselement
      basis        ::mtmtcl::Lie::unitary::basis
      coeff        ::mtmtcl::Lie::unitary::coeff
      support      ::mtmtcl::Lie::unitary::support
%   \end{tcl}
%   Of course, fetching most method implementations from 
%   |complex_matrix_real_space| is no reason to put the ensemble 
%   command there.
%   \begin{tcl}
   } -command ::mtmtcl::Lie::unitary::algebra -parameters Zero -prefix 0
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% The only nontrivial problem implementation-wise is that of chosing 
% a basis for the Lie algebra $\mathfrak{u}(n)$, and an index set for 
% that basis. To that end, it is useful to observe that the real part 
% of an antihermitian matrix is antisymmetric, whereas the imaginary 
% part is symmetric. Hence the imaginary part is determined by what 
% is on and above the main diagonal, whereas the real is determined 
% by what is below the diagonal. An alternative encoding of 
% antihermitian matrices would thus be as a real matrix, with the 
% subdiagonal elements being real parts of the corresponding elements, 
% whereas the diagonal and superdiagonal elements are the imaginary 
% parts of those elements:
% \[
%   \begin{pmatrix}
%     a & b \\ c & d
%   \end{pmatrix}
%   \quad\text{encodes}\quad
%   \begin{pmatrix}
%     0 & -c \\ c & 0
%   \end{pmatrix} + i \begin{pmatrix}
%     a & b \\ b & d
%   \end{pmatrix}
%   =
%   \begin{pmatrix}
%     ia & -c + ib \\ c + ib & id
%   \end{pmatrix}
%   \text{.}
% \]
% Using that for computations is not so attractive, but it can be 
% used to suggest a basis for the antihermitian matrices: use what 
% would be encoded as the standard basis of $\mathbb{R}^{n \times n}$ 
% under this encoding! This means the indices are pairs of natural 
% numbers $< n$.
% 
% \begin{proc}{basis}
%   A structure for the chosen set of indices can thus be conveniently 
%   implemented as the |mtmtcl::sets::cartesian_product| of two 
%   |mtmtcl::sets::finite_ordinal|s with cardinality $n$.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::basis {Zero args} {
   tailcall ::mtmtcl::sets::cartesian_product [list [
      list ::mtmtcl::sets::finite_ordinal [llength $Zero]
   ] [
      list ::mtmtcl::sets::finite_ordinal [llength $Zero]
   ]] {} {*}$args
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{coeff}
%   A nice thing about this basis is that the coefficient can be 
%   extracted by a single |lindex|, which uses the basis index to 
%   select a matrix element, and the relation between the indices to 
%   tell if it is the real or the imaginary part from that element 
%   that is wanted.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::coeff {Zero index A} {
   lindex $A {*}$index [::tcl::mathop::<= {*}$index]
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{support}
%   A similar idea can be used when computing the |support| of an 
%   element.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::support {Zero A} {
   set res {}
   set i 0
   foreach row $A {
      set j 0
      foreach cell $row {
         if {[lindex $cell [::tcl::mathop::<= $i $j]] != 0} then {
            lappend res [list $i $j]
         }
         incr j
      }
      incr i
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{basiselement}
%   What requires a bit more thought is the |basiselement| method.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::basiselement {res index} {
   lassign $index i j
   if {$i == $j} then {
      lset res $i $i 1 1.0
%   \end{tcl}
%   Diagonal elements are, as remarked above, imaginary.
%   \begin{tcl}
   } elseif {$i < $j} then {
%   \end{tcl}
%   Superdiagonal elements are imaginary too, but they have to be 
%   mirrored in the subdiagonal part, so there need to be two nonzero 
%   matrix elements.
%   \begin{tcl}
      lset res $i $j 1 1.0
      lset res $j $i 1 1.0
   } else {
%   \end{tcl}
%   Subdiagonal elements are conversely mirrored in the superdiagonal 
%   part, so again there need to be two nonzero matrix elements, but 
%   here the elements are real and therefore need to have the 
%   opposite sign above the diagonal.
%   \begin{tcl}
      lset res $i $j 0 1.0
      lset res $j $i 0 -1.0
   }
   return $res
}
%   \end{tcl}
%   From this, one can see that the chosen basis of $\mathfrak{u}(n)$ 
%   is orthogonal but not orthonormal. It is quite possible to 
%   normalise it, but doing so would complicate the |coeff| method 
%   and make use of the constant $\sqrt{2}$ in several places.
% \end{proc}
% 
% 
% \subsubsection{The group}
% 
% Given what has already been defined above, the trickiest part of 
% the Lie group structure is that it is a manifold: how might one, 
% for an arbitrary $n$, create a set of $n^2$-dimensional charts that 
% cover a variety in $\mathbb{R}^{2n^2}$?!? An $n$-sphere is easy, 
% but can anyone even imagine what a beast like $\mathrm{U}(n)$ looks 
% like? Perhaps not in general, but close to any given point we know 
% that it looks roughly like the tangent space at that point, and at 
% the identity we know that this tangent space is the set of 
% antihermitian matrices! This suggests the following approach:
% \begin{itemize}
%   \item
%     A coordinate system covering a neighbourhood of the identity 
%     can be constructed simply by taking the antihermitian part of a 
%     point (unitary matrix) as its coordinate; this correponds to 
%     making an orthogonal projection of that neightbourhood into the 
%     tangent space at the identity.
%   \item
%     Coordinate systems covering neighbourhoods of a general point 
%     $P$ can be constructed by left translation of that point back 
%     to the identity, and then using the identity coordinate system.
%   \item
%     Hence, the problem of how to cover the entire manifold can be 
%     solved by letting every point define a chart which places that 
%     point at the origin. Also, the natural coordinate space turns 
%     out to be $\mathfrak{u}(n)$.
% \end{itemize}
% 
% \begin{proc}{p2c}
%   Therefore the procedure for computing the chart $C$ coordinate of 
%   a point $P$ can be to take the antihermitian part of \(C^{-1}P = 
%   C^* P\).
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::p2c {Zero chart point} {
   antihermitian_part $Zero [* $Zero [conjugate $Zero $chart] $point]
}
%   \end{tcl}
% \end{proc}
% 
% When going the other way, taking the chart into account simply 
% means to multiply by $C$, but the initial step of decoding 
% coordinates for the identity chart turns out to be trickier. 
% Basically, the problem is to find a unitary matrix with given 
% antihermitian part $A$, i.e., to find a hermitian part $H$ that goes 
% with $A$. This $H$ has to solve
% \[
%   I = 
%   (H + A)^* (H + A) =
%   (H - A) (H + A) =
%   H^2 + HA - AH - A^2
% \]
% Separating hermitian and antihermitian parts of this equality, one 
% arrives at \(H^2 = I + A^2\) and \(AH = HA\). The former has the 
% formal power series solution \(H = \sum_{k=0}^\infty \binom{1/2}{k} 
% A^{2k}\) that obviously commutes with $A$; hence one need only 
% worry about the hermitian equation, and the problem is apparently 
% to compute a matrix square root.
% 
% Computing the binomial series can be recast as a simple iteration 
% with just one matrix multiplication per step, but unfortunately the 
% convergence of this is merely linear. For faster convergence, one may 
% instead consider the Newton iteration~\cite[p.~140]{Higham}
% \[
%   H_{k+1} = \tfrac{1}{2}\bigl( H_k + H_k^{-1} (I + A^2) \bigr)
%   \text{,}\qquad
%   H_0 = I
% \]
% which (by general theory) converges quadratically. But how many 
% concrete iterations would that need? In order to answer that, it can 
% be a good idea to consider the eigenstructure of a unitary matrix.
% 
% Suppose $U$ is the unitary matrix we are trying to reconstruct as 
% $H+A$. Clearly, if $\mathbf{v}$ is an eigenvector of $U$ with 
% eigenvalue $\lambda$, then $\mathbf{v}$ is also an eigenvector of 
% \(U^{-1} = U^*\) with eigenvalue \(\lambda^{-1} = \bar{\lambda}\) 
% (remember that any eigenvalue of a unitary matrix has absolute 
% value $1$). Hence $\mathbf{v}$ will be an eigenvector also for \(H 
% = \tfrac{1}{2}( U +\nobreak U^* )\) and \(A 
% = \tfrac{1}{2}( U -\nobreak U^* )\), with eigenvalues 
% \(\tfrac{1}{2}( \lambda +\nobreak \bar{\lambda} ) = 
% \operatorname{Re} \lambda\) and \(\tfrac{1}{2}( \lambda -\nobreak 
% \bar{\lambda} ) = i \operatorname{Im} \lambda\) respectively. Thus 
% all matrices occuring in the iteration will have the same 
% eigenvectors, and it is possible to consider each eigenvalue in 
% isolation; one finds that \(H_k \mathbf{v} = h_k \mathbf{v}\), 
% where $h_k$ is given by the iteration
% \[
%   h_0 = 1 \text{,}\qquad
%   h_{k+1} = \tfrac{1}{2}\Bigl( h_k + 
%     h_k^{-1} \bigl( 1 + (i \operatorname{Im} \lambda)^2 \bigr) 
%   \Bigr)
%   \text{.}
% \]
% Given that \(\lambda = h + ia\), it can be a good idea to make the 
% substitution \(h_k = h + x_k\) in this iteration, as in the 
% variable $x$ it simplifies to
% \begin{multline*}
%   x_{k+1} =
%   h_{k+1} - h =
%   \tfrac{1}{2}\bigl( h_k + h_k^{-1}(1-a^2) \bigr) - h 
%   = \\ =
%   \tfrac{1}{2} x_k - \tfrac{1}{2} h + \frac{1-a^2}{2(h + x_k)} =
%   \frac{ x_k^2 - h^2 + 1 - a^2 }{ 2(h + x_k) } =
%   \frac{ x_k^2 }{ 2(h + x_k) }
% \end{multline*}
% as \(h^2 + a^2 = \lvert\lambda\rvert^2 = 1\), making the quadratic 
% convergence explicit. A brute force computation reveals that the 
% error $x_5$ is of the same magnitude as the epsilon of |double|s 
% (for $h$ in the interval $[\tfrac{1}{2},1]$ as discussed below)
% whereas $x_6$ is much smaller, so it seems there would not be much 
% point in doing more than $5$ iterations.
% 
% \begin{proc}{c2p}
%   Having settled for five iterations being sufficient, and keeping 
%   in mind that deciding whether fewer iterations suffice also 
%   carries a cost, it seems easiest to always do five iterations.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::c2p {Zero chart A} {
%   \end{tcl}
%   The first step is to compute the matrix $A^2+I$. Adding $I$ is 
%   done in the slightly ugly way of explicitly adding $1$ to the 
%   real parts of the diagonal elements, but adding $0$ to all the 
%   rest felt like a bit of a waste. The matrix $A^2+2I$ is computed 
%   simultaneously.
%   \begin{tcl}
   set A2plusI {}; set A2plus2I {}
   foreach row [* $Zero $A $A] {
      lset row [llength $A2plusI] 0\
        [expr {1 + [lindex $row [llength $A2plusI] 0]}]
      lappend A2plusI $row
      lset row [llength $A2plus2I] 0\
        [expr {1 + [lindex $row [llength $A2plus2I] 0]}]
      lappend A2plus2I $row
   }
%   \end{tcl}
%   The next step is the iterations to compute $H$. Since \(H_0 = I\), 
%   the first iteration can be unrolled into \(H_1 = 
%   \tfrac{1}{2}\bigl( I +\nobreak (I +\nobreak A^2) \bigr)\), so the 
%   initial $H$ is half of |A2plus2I|, and that is why the latter was 
%   computed above.
%   \begin{tcl}
   set H [. $Zero 0.5 $A2plus2I]
   foreach k {2 3 4 5} {
      set H [+. $Zero 0.5 $H 0.5 [/ $Zero $A2plusI $H]]
   }
%   \end{tcl}
%   Then $H$ and $A$ are added together, the |chart| is taken into 
%   account, and the final result is |improve|d (see below) before it 
%   is returned.
%   \begin{tcl}
   return [improve $Zero [* $Zero $chart [+ $Zero $H $A]]]
}
%   \end{tcl}
% \end{proc}
% 
% For completing the \APIref{manifold}{1.0} interface, one needs a 
% way of testing whether a set of points are covered by a given 
% chart, and that boils down to picking a domain within which the 
% |c2p| defined above correctly recovers the original point, so how 
% far out can one go? The isolated eigenvalue calculation suggests 
% it will get it right for all \(h \geqslant 0.52\), which can be 
% rephrased in terms of $\lambda$ as \(\lvert 1 -\nobreak \lambda 
% \rvert < 0.979\). Hence a working condition would be that the 
% spectral radius of $I-U$ is at most that, but computing the 
% spectral radius (absolute value of greatest eigenvalue) is a bit 
% heavy; other norms are need not be sharp in this respect, but are 
% much easier. Thus the problem translates very nicely to a distance 
% calculation.
% 
% For maximal simplicity, one would furthermore want the distance used 
% to be unitarily invariant, as that means one can compute $d(C,P)$ 
% rather than $d(C^* P, I)$ and thus save one matrix multiplication. 
% This rules out the $\ell^1$ and $\ell^\infty$ norms, which leaves 
% us with the Frobenius norm.
% 
% A unitary matrix $U$ is diagonalisable, so the Frobenius norm of 
% $I-U$ is equal to $\left( \sum_{k=1}^n \lvert 1 - \lambda_k 
% \rvert^2 \right)^{1/2}$; it will therefore be equal to the spectral 
% radius if and only if at most one eigenvalue is not $1$, and 
% otherwise it will be greater than the spectral radius. Thus no 
% great harm is done if the Frobenious distance bound is set to $1$ 
% rather than $0.979$: the extra area covered is very far ``out in 
% the corners'', and even if the square root iteration doesn't quite 
% get to the mark in five iterations, it will still be within a few 
% epsilons, which the |improve| at the end of |c2p| should take care 
% of.
% 
% \begin{proc}{charts}
%   The main algorithm in this |charts| procedure is therefore to 
%   return those points given which have |Frobenius_distance| less 
%   than $1$ to all other points. There is only the exceptional case 
%   that no points are given, in which case the chart centered at the 
%   indentity is returned.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::charts {Zero args} {
   if {![llength $args]} then {return [1 $Zero]}
%   \end{tcl}
%   In order to avoid computing the same distance more than once, an 
%   array |D| indexed by pairs of indices into |args| is used to 
%   cache comparison results: |0| means the points are within the 
%   allowed distance, |1| means they are not, and unset entries have 
%   not been checked yet. |k| and |l| are the indices in |args| of 
%   |C| and |P| respectively, and |D($k,$l)| is the currently 
%   considered distance, so if it has been computed before, then the 
%   result will have been cached in |D($l,$k)|.
%   \begin{tcl}
   set res {}
   set k -1; foreach C $args {incr k
      set D($k,$k) 0
      set ok 1
      set l -1; foreach P $args {incr l
         set D($k,$l) [expr { [info exists D($l,$k)] ? $D($l,$k) :\
            [Frobenius_distance $Zero $C $P]>=1 }]
         if {$D($k,$l)} then {
            set ok 0
            break
         }
      }
      if {$ok} then {lappend res $C}
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% There is however also another issue to consider regarding |c2p|, 
% namely whether the iteration is numerically \emph{stable}. Again 
% by~\cite[p.~144]{Higham}, the above Newton iteration for $(I 
% +\nobreak A^2)^{1/2}$ is stable if for any two eigenvalues 
% $\kappa_i$ and $\kappa_j$ of $I+A^2$ it holds that \(\tfrac{1}{2} 
% \left\vert 1 - \kappa_i^{1/2} \kappa_j^{-1/2} \right\vert < 1\), 
% i.e., if \(3 > \kappa_i^{1/2} \kappa_j^{-1/2} > -1\), where the 
% right inequality is void since $\kappa_i$ and $\kappa_j$ are both 
% positive. In fact, \(\kappa_i = 1 - (\operatorname{Im} 
% \lambda_i)^2\), hence \(\tfrac{1}{2} < \kappa_i^{1/2},\kappa_j^{1/2} 
% \leqslant 1\) and thus these matrices are well within the stable 
% region. The boundary is however not that far away; allowing 
% \(\lvert 1 -\nobreak \lambda \rvert = 1.155\) could mean we've 
% passed it! Hence there seems to be little point in extending the 
% charts to cover larger patches, even if one would be prepared to 
% make more iterations.
% 
% 
% \begin{proc}{improve}
%   For |improve|ing a near-unitary matrix $P$, one approach is to 
%   take the average of $P$ and $(P^*)^{-1}$, since these would be 
%   the same for a unitary matrix.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::improve {Zero P} {
   . $Zero 0.5 [+ $Zero $P [inverse $Zero [conjugate $Zero $P]]]
}
%   \end{tcl}
%   One can also argue that this is what one gets from applying 
%   Newton's method to \(f(P) = P^* P - I\), but how good is it? By 
%   polar decomposition, any matrix $P$ can be written as $U(I 
%   +\nobreak H)$, where $U$ is unitary and $H$ is 
%   Hermitian;\footnote{
%     One may even require that $I+H$ is positive semidefinite, but 
%     we won't need that.
%   } this is natural, since the tangent space at $U$ has the form 
%   $UA$ and the normal space at $U$ has the form $UH$. Clearly,
%   \begin{multline*}
%     P + (P^*)^{-1} =
%     U(I+H) + \Bigl( \bigl( U(I+H) \bigr)^* \Bigr)^{-1} = \\ =
%     U(I+H) + \bigl( (I+H) U^* \bigr)^{-1} = 
%     U(I+H) + U (I+ H)^{-1} = \\ =
%     U\bigl( I + H + I - H + H^2 - \mathcal{O}(H^3) \bigr) =
%     2U\bigl( I + \mathcal{O}(H^2) \bigr)
%   \end{multline*}
%   and thus the convergence of $\tfrac{1}{2} \bigl( P +\nobreak 
%   (P^*)^{-1} \bigr)$ to the unitary factor $U$ is indeed quadratic. 
%   In particular, there is \emph{no} tangential drift of the point 
%   when improving it this way.
% \end{proc}
%   
% It can similarly be checked that $\tfrac{1}{2}(3P -\nobreak P P^* 
% P)$ is another iteration with quadratic convergence, but even 
% though the operations involved are ``simpler'' (matrix 
% multiplication rather than matrix inverse) it is not obvious that 
% this would be more efficient, since it requires two matrix 
% multiplications; two calls to |::mtmtcl|\namespaceseparator 
% |Lie|\namespaceseparator 
% |complex_matrix_real_space|\namespaceseparator |*| will make $2n^3$ 
% calls to |::mtmtcl|\namespaceseparator |rings|\namespaceseparator 
% |complex|\namespaceseparator |*|, wheras one call to 
% |::mtmtcl|\namespaceseparator |Lie|\namespaceseparator 
% |complex_matrix_real_space|\namespaceseparator |inverse| ``only'' 
% makes $\tfrac{3}{2}n^3$ calls to |::mtmtcl|\namespaceseparator 
% |rings|\namespaceseparator |complex|\namespaceseparator |*|.
% 
% \begin{tclcommand}{ensemble}{group}
%   But |improve| was the last procedure needed to implement the 
%   |group| structure. Everything else was already available, and 
%   the number of |complex_matrix_real_space| commands needed is 
%   small enough that one wouldn't gain much from attaching the 
%   ensemble to that namespace (as was done with |algebra|), so it is 
%   put here instead.
%   \begin{tcl}
namespace eval ::mtmcl::Lie::unitary {
   namespace ensemble create -command ::mtmcl::Lie::unitary::group -map {
%   \end{tcl}
%   The basic group operations are however fetched from 
%   |complex_matrix_real_space|. That is in fact a \APIref+{group}{1.1}, 
%   since we have a variadic |*|.
%   \begin{tcl}
      =         ::mtmtcl::Lie::complex_matrix_real_space::=
      *         ::mtmtcl::Lie::complex_matrix_real_space::*
      1         ::mtmtcl::Lie::complex_matrix_real_space::1
      inverse   ::mtmtcl::Lie::complex_matrix_real_space::conjugate
%   \end{tcl}
%   Taking advantage of the definition of unitary matrix, the 
%   |inverse| can of course be to |conjugate|.
%   
%   The \APIref{manifold}{1.0} operations are however implemented 
%   here.
%   \begin{tcl}
      charts    charts
      p2c       p2c
      c2p       c2p
      coord     algebra
%   \end{tcl}
%   The |tangent| space is again the Lie algebra $\mathfrak{u}(n)$, 
%   but the exponent map is again something mapped in from the 
%   general complex matrix namespace.
%   \begin{tcl}
      tangent   algebra
      exp       ::mtmtcl::Lie::complex_matrix_real_space::exp
%   \end{tcl}
%   The application below will require the unitary group to also be a 
%   \APIref{metric space}{1.0}, and in addition it is a 
%   \APIref+{subset}{2.1}. 
%   \begin{tcl}
      distance  ::mtmtcl::Lie::complex_matrix_real_space::Frobenius_distance
      superset  ::mtmtcl::Lie::complex_matrix_real_space
      improve   improve
%   \end{tcl}
%   With |export| as in the |algebra| and an |API| method, that is 
%   actually all we need in this ensemble.
%   \begin{tcl}
      export     {::mtmtcl::support::subset::superexport1p\
                   ::mtmtcl::Lie::complex_matrix_real_space}
      API {::API::staticn 1 {
         equality       1.0
         semigroup      1.1
         monoid         1.1
         group          1.1
         manifold       1.0
         "Lie group"    1.1
         "metric space" 1.2
         subset         2.1
         export         2.0
      }}
   } -prefix 0 -parameters {Zero}
}
%   \end{tcl}
% \end{tclcommand}
% 
% \begin{proc}{make}
%   The package can however do with one more command: the one that 
%   |make|s a command prefix for a concrete structure. As for 
%   $\mathbb{R}^n$, this command has the syntax
%   \begin{displaysyntax}
%     ::mtmtcl::Lie::unitary::make 
%     \begin{regblock} algebra \regalt group \end{regblock}
%     \word{side}
%   \end{displaysyntax}
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary::make {what n} {
   incr n 0
   if {$n < 1} then {
      return -code error "0-by-0 matrices are not supported"
   }
   set zero [complex 0]
   set L {}
   for {set i 0} {$i < $n} {incr i} {lappend L $zero}
   set Zero {}
   for {set i 0} {$i < $n} {incr i} {lappend Zero $L}
   switch -- $what group - algebra {
      return [list [namespace which $what] $Zero]
   } default {
      return -code error "Unknown aspect '$what':\
        must be algebra or group"
   }
}
%</unitary>
%   \end{tcl}
% \end{proc}
% 
% 
% 
% \subsection{Unitary matrices fixing the $\mathbf{1}$-vector}
% 
% By $\mathrm{U}^\mathbf{1}(n)$ is denoted the subgroup of unitary 
% matrices which map \(\mathbf{1} = \sum_{k=1}^n \mathbf{e}_k\) to 
% itself. The purpose of considering this subgroup is that it is 
% a more conservative ``continuous generalisation'' of the group of 
% permutations than the full unitary group (in fact it is arguably 
% the smallest such generalisation, but more on that later).
% 
% One way to understand a general matrix $P$ as generalising a 
% permutation $\sigma$ is that the direction of $P \mathbf{e}_k$ 
% (i.e., the $k$th column of $P$) is analogous to the value 
% $\sigma(k)$ of the permutation $\sigma$. The columns of a unitary 
% matrix can point in arbitrary directions (e.g.~backwards), but the 
% columns of some \(P \in \mathrm{U}^\mathbf{1}(n)\) cannot deviate 
% that much from ``the first $2^n$-rant'' $\{ \mathbf{x} \in\nobreak 
% \mathbb{R}^n \mid\nobreak \mathbf{x} \geqslant\nobreak \mathbf{0} 
% \}$, since \(\mathbf{1}^* P \mathbf{e}_k = (P \mathbf{1})^* 
% (P \mathbf{e}_k) = \mathbf{1}^* \mathbf{e}_k = 1 > 0\) and the angle 
% between $\mathbf{1}$ and any $P\mathbf{e}_k$ is thus always acute. 
% $\mathrm{U}^\mathbf{1}(n)$ therefore lives in (the boundary of) a 
% cone circumscribing this first $2^n$-rant, even though that cone 
% \emph{does} get increasingly flat as $n$ increases 
% (\(\lvert\mathbf{1}\rvert = \sqrt{n}\), so the cosine $1/\sqrt{n}$ 
% tends to $0$) and the only vectors in it that are also in the 
% first $2^n$-rant (rather than some neighbouring region) are the 
% standard basis vectors. None the less, this is about as close to 
% the first $2^n$-rant as one can stick within a continuous group.
% 
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::unitary1fixed 1.0 unitary1fixed
%</docstrip.tcl::catalogue>
% \end{tcl}
% As with the |unitary| group, one frequently wants to make use of the 
% offerings of the |complex_matrix_real_space| package, so that namespace 
% is installed in the |namespace path|. This also suggests using the 
% same syntax for the underlying ensembles: one parameter, which is 
% the \(0 \in \mathbb{C}^{n \times n}\).
% \begin{tcl}
%<*unitary1fixed>
package require Tcl 8.6
package require mtmtcl::Lie::complex_matrix_real_space 1.0
package require mtmtcl::support::subset 1.0
package require mtmtcl::sets::cartesian_product 1.1
package require mtmtcl::sets::finite_ordinal 1.0
namespace eval ::mtmtcl::Lie::unitary1fixed {
   namespace path ::mtmtcl::Lie::complex_matrix_real_space
}
% \end{tcl}
% \setnamespace{mtmtcl::Lie::unitary1fixed}
% 
% 
% \subsubsection{The algebra}
% 
% The group $\mathrm{U}^\mathbf{1}(n)$ has the set-theoretic 
% definition
% \[
%   \mathrm{U}^\mathbf{1}(n) =
%   \left\{ \, P \in \mathbb{C}^{n \times n} \,\mid\,
%     P^* P = I \text{ and } P \mathbf{1} = \mathbf{1}
%   \right\}
%   \text{.}
% \]
% This gives rise to two equations that tangent vectors $P(I 
% +\nobreak \varepsilon A)$ must satisfy, namely
% \begin{align*}
%   0 ={}& 
%   \bigl( P (I + \varepsilon A) \bigr)^* P (I + \varepsilon A) - I =
%   (I + \varepsilon A^*) P^* P (I + \varepsilon A) - I 
%     = \\ &\qquad\qquad\qquad {}=
%   (I + \varepsilon A^*)(I + \varepsilon A) - I =
%   \varepsilon (A + A^*)
%     \quad\Longrightarrow\quad A^*=-A
%     \text{,}\\
%   \mathbf{0} ={}&
%   P (I + \varepsilon A) \mathbf{1} - \mathbf{1} =
%   P \mathbf{1} + \varepsilon P A \mathbf{1} - \mathbf{1} =
%   \varepsilon P A \mathbf{1} 
%   \quad\Longrightarrow\quad
%   A \mathbf{1} = \mathbf{0}
%   \text{.}
% \end{align*}
% Hence the corresponding Lie algebra consists of those antihermitian 
% matrices where every row sum is $0$.
% 
% As in $\mathfrak{u}(n)$, it can make sense to consider the real and 
% imaginary parts of this space separately. The imaginary parts are 
% simply real symmetric matrices with all row sums equal to $0$, and 
% since one can always achieve this row sum by adjusting the diagonal 
% elements, it follows that this imaginary subspace is 
% $\binom{n}{2}$-dimensional; letting \(1 \leqslant k < l \leqslant 
% n\), one can construct a set of $\binom{n}{2}$ linearly independent 
% elements as the family of matrices which have $i$ in positions $(k,l)$ 
% and $(l,k)$, and $-i$ in positions $(k,k)$ and $(l,l)$. The real 
% parts are trickier, since these are instead \emph{antisymmetric} real 
% matrices with row sum $0$, so here the diagonal is always $0$ and one 
% cannot use it adjust the row sum. On the other hand, one can set 
% aside the last column for row sum adjustments, and then there is by 
% antisymmetry at most $\binom{n-1}{2}$ degrees of freedom left. 
% Conversely one can for each pair $(k,l)$ where \(1 \leqslant l < k 
% < n\) construct the linearly independent family of matrices which are 
% $1$ in positions $(k,l)$, $(l,n)$, and $(n,k)$ but $-1$ in 
% positions $(l,k)$, $(k,n)$, and $(n,l)$:
% \[
%   \begin{pmatrix}
%     0 & 0 & -1 & 0 & \ldots & 1 \\
%     0 & 0 & 0 & 0 & \ldots & 0 \\
%     1 & 0 & 0 & 0 & \ldots & -1 \\
%     0 & 0 & 0 & 0 & \ldots & 0 \\
%     \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
%     -1 & 0 & 1 & 0 & \ldots & 0
%   \end{pmatrix}
%   \text{;}
% \]
% since these are antisymmetric and have all row sums equal to $0$, 
% they demonstrate that the real part of the Lie algebra space is 
% exactly $\binom{n-1}{2}$-dimensional, and hence the Lie algebra as 
% a whole is $(n -\nobreak 1)^2$-dimensional.
% 
% \begin{proc}{basiselement}
%   This argument has taken care of the grunt work for a 
%   |basiselement| operation which uses the pairs $(k,l)$ as indices 
%   and as with |unitary| decides whether a pair refers to a real or 
%   imaginary part by which element in the pair is larger. As usual, 
%   the \Tcllogo\ indices are base $0$ rather than base~$1$.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::basiselement {res pair} {
   if {[lindex $pair 0] > [lindex $pair 1]} then {
%   \end{tcl}
%   First the real case\dots
%   \begin{tcl}
      lset res [lindex $pair 0] [lindex $pair 1] 0  1.0
      lset res [lindex $pair 1] [lindex $pair 0] 0 -1.0
      lset res [lindex $pair 0] end              0 -1.0
      lset res [lindex $pair 1] end              0  1.0
      lset res end              [lindex $pair 1] 0 -1.0
      lset res end              [lindex $pair 0] 0  1.0
   } else {
%   \end{tcl}
%   \dots and then the imaginary.
%   \begin{tcl}
      lset res [lindex $pair 0] [lindex $pair 1] 1  1.0
      lset res [lindex $pair 1] [lindex $pair 0] 1  1.0
      lset res [lindex $pair 0] [lindex $pair 0] 1 -1.0
      lset res [lindex $pair 1] [lindex $pair 1] 1 -1.0
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% This basis is neither orthogonal (basis elements are orthogonal if 
% the corresponding unordered paris are disjoint) nor of uniform 
% length (the real basis elements have Frobenius norm $\sqrt{6}$, 
% whereas the imaginary ones have Frobenius norm $2$), but its 
% coefficients are again explicit in selected matrix elements.
% 
% \begin{proc}{coeff}
%   Hence the |coeff| method can be implemented as in 
%   $\mathfrak{u}(n)$.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::coeff {Zero index A} {
   lindex $A {*}$index [::tcl::mathop::<= {*}$index]
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{support}
%   Having basis element coefficients explicit in matrix elements is useful 
%   also when computing the |support| of an element, but there are 
%   additional conditions to consider: diagonal elements do not 
%   correspond to basis elements, and neither do elements from the 
%   last row.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::support {Zero A} {
   set res {}
   set i 0
   foreach row $A {
      set j 0
      foreach cell $row {
         if {$i != $j && [lindex $cell [::tcl::mathop::<= $i $j]] != 0} then {
            lappend res [list $i $j]
         }
         incr j
      }
      incr i
      if {$i+1 == [llength $A]} then {break}
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% Another interesting property of the chosen basis is that the 
% $(k,l)$ element with \(k<l\) (i.e., any imaginary basis element) 
% corresponds to the transposition of $k$ and $l$;
% \begin{multline*}
%   \exp \begin{pmatrix} -it & it \\ it & -it \end{pmatrix} =
%   \sum_{k=0}^\infty \frac{(-it)^k}{k!} 
%     \begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix}^k =
%   I + \sum_{k=1}^\infty \frac{(-it)^k}{k!} 2^{k-1} 
%     \begin{pmatrix} 1 & -1 \\ -1 & 1\end{pmatrix}
%     = \\ =
%   I + \tfrac{1}{2} \bigl( e^{-2it} - 1 \bigr)
%     \begin{pmatrix} 1 & -1 \\ -1 & 1\end{pmatrix} =
%   \tfrac{1}{2} \begin{pmatrix}
%     1 + e^{-2it} & 1 - e^{-2it} \\
%     1 - e^{-2it} & 1 + e^{-2it}
%   \end{pmatrix}
% \end{multline*}
% is $\left( \begin{smallmatrix} 1 & 0 \\ 0 & 1 \end{smallmatrix} 
% \right)$ for \(t=0\) and $\left( \begin{smallmatrix} 0 & 1 \\ 1 & 0 
% \end{smallmatrix} \right)$ for \(t = \pi/2\). The real basis 
% elements arise as commutators of imaginary basis elements, so it 
% follows that no smaller Lie algebra could have a direction towards 
% every transposition. This is how $\mathrm{U}^\mathbf{1}(n)$ is the 
% smallest Lie group that generalises the full symmetric group.
% 
% 
% \begin{proc}{basis}
%   The index set for the basis is $\left\{ \, (k,l) \bigm\vert 0 
%   \leqslant k < n-1, 0 \leqslant l < n, k \neq l \,\right\}$, but 
%   how is that best implemented? A 
%   |::mtmtcl::support::subset::byfilter| of the cartesian product of 
%   an $(n-1)$-set and an $n$-set seems easiest.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::basis {Zero args} {
   tailcall ::mtmtcl::support::subset::byfilter [
      list ::mtmtcl::sets::cartesian_product [list [
         list ::mtmtcl::sets::finite_ordinal [expr {[llength $Zero]-1}]
      ] [
         list ::mtmtcl::sets::finite_ordinal [llength $Zero]
      ]] {}
   ] {
      ::apply {kl {ne {*}$kl} ::tcl::mathop}
   } {*}$args
}
%   \end{tcl}
% \end{proc}
% 
% 
% Another matter to solve is how to |improve| a tangent matrix. The 
% equation \(A \mathbf{1} = \mathbf{0}\) defines a subspace of the 
% space of matrices, so it makes sense to try an orthogonal 
% projection onto that. This equation is furthermore a condition on 
% each row of $A$ separately, and also the real and imaginary parts 
% of a row separately. Taking \((\mathbf{u} +\nobreak i\mathbf{v})^* 
% = \mathbf{u}^\mathrm{T} - i\mathbf{v}^\mathrm{T}$ to be a row of $A$, 
% one sees that the condition \((\mathbf{u} +\nobreak i\mathbf{v})^* 
% \mathbf{1} = 0\) merely states that \(\mathbf{u},\mathbf{v} \in 
% \mathbb{R}^n\) are both orthogonal to $\mathbf{1}$. From the 
% element-wise definition of the Frobenius inner product, one moreover 
% sees that it is simply the (real) Euclidean inner product of two 
% vectors, so the part of $\mathbf{u}$ that is perpendicular to 
% $\mathbf{1}$ is
% \[
%   \mathbf{u} - \frac{
%      \mathbf{1}^\mathrm{T} \mathbf{u}
%   }{ \mathbf{1}^\mathrm{T} \mathbf{1} } \mathbf{1}
%   =
%   \mathbf{u} - 
%   \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T} \mathbf{u}
%   =
%   (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}) \mathbf{u}
% \]
% and similarly for $\mathbf{v}$. Remembering that these are column 
% vectors, and that the rows of $A$ are conjugates of these, it 
% follows that one would project $A$ onto the wanted subspace by 
% multiplying it with \(K = I - \tfrac{1}{n} \mathbf{1} 
% \mathbf{1}^\mathrm{T}\) on the \emph{right}. Indeed,
% \[
%   AK \mathbf{1} =
%   A (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}) \mathbf{1} =
%   A \mathbf{1} - 
%   A \mathbf{1} \tfrac{1}{n} \mathbf{1}^\mathrm{T} \mathbf{1} =
%   A \mathbf{1} - A \mathbf{1} \tfrac{n}{n} = 
%   \mathbf{0} \text{.}
% \]
% Merely taking the antihermitian part of $AK$ would however not 
% suffice, because for that times $\mathbf{1}$ to be $\mathbf{0}$ one 
% also requires \(\mathbf{0} = (AK)^*\mathbf{1} = KA^*\mathbf{1}\). 
% This is no coincidence; in addition to \(A \mathbf{1} = 
% \mathbf{0}\), any tangent matrix must also satisfy 
% \(\mathbf{1}^\mathrm{T} A = \mathbf{0}^\mathrm{T}\), because
% \((\mathbf{1}^\mathrm{T} A)^* = A^* \mathbf{1} = -A \mathbf{1} = 
% -\mathbf{0}\). To enforce also that, one needs to multiply by $K$ 
% on the left, and then it is clear that 
% \texttt{[antihermitian\_part $KAK$]} is in the wanted tangent 
% matrix. However,
% \[
%   \tfrac{1}{2}\bigl( KAK - (KAK)^* \bigr) =
%   \tfrac{1}{2}( KAK - KA^*K) =
%   K \tfrac{1}{2}(A-A^*) K
% \]
% and thus one can equally well take the antihermitian part first; 
% this turns out to have some implementational advantages.
% 
% \begin{proc}{algbra_improve}
%   This procedure implements the |improve| operation for the Lie 
%   algebra, and thus it has the call syntax
%   \begin{displaysyntax}
%     |algebra_improve| \word{Zero} \word{$A$}
%   \end{displaysyntax}
%   returning the |improve|d $A$.
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::algebra_improve {Zero A} {
%   \end{tcl}
%   The first step is to compute the antihermitian part $B$ of $A$.
%   \begin{tcl}
   set B [antihermitian_part $Zero $A]
%   \end{tcl}
%   Then comes the main step of multiplying $B$ by \(K = I - 
%   \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}\) on both sides. 
%   However, doing this as two matrix multiplication is unnecessarily 
%   complicated, since multiplication by $I$ is a no-op and 
%   multiplication by $\mathbf{1} \mathbf{1}^\mathrm{T}$ can be more 
%   efficiently expressed using matrix--vector multiplication. Indeed,
%   \[
%     KBK =
%     (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}) B 
%     (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}) =
%     B - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T} B
%     - \tfrac{1}{n}  B \mathbf{1} \mathbf{1}^\mathrm{T} + 
%     \tfrac{1}{n^2} \mathbf{1} \mathbf{1}^\mathrm{T} B
%       \mathbf{1} \mathbf{1}^\mathrm{T}
%   \]
%   so this can be computed through a loop over the elements of which 
%   adjusts it according to the corresponding element of 
%   $\mathbf{1} \mathbf{1}^\mathrm{T} B$ (independent of row), 
%   $B \mathbf{1} \mathbf{1}^\mathrm{T}$ (independent of column), and 
%   $\mathbf{1} \mathbf{1}^\mathrm{T} B \mathbf{1} 
%   \mathbf{1}^\mathrm{T}$ (the same in all positions). Indeed, $B 
%   \mathbf{1}$ is merely the vector of row-sums which is easy enough 
%   to compute, and $\mathbf{1}^\mathrm{T} B \mathbf{1}$ is simply 
%   the sum of all elements of $B$ (and thus the sum of the 
%   row-sums). The vector of column-sums $\mathbf{1}^\mathrm{T} B$ is 
%   a bit trickier since matrices are stored in row-major order, but 
%   it follows from \(B^* = -B\) that \(\mathbf{1}^\mathrm{T} B = 
%   (B^* \mathbf{1})^* = (-B \mathbf{1})^* = - (B \mathbf{1})^* = 
%   -\operatorname{Re}(B \mathbf{1}) + i\operatorname{Im}(B 
%   \mathbf{1})\) and so the column sum vector is almost the same as 
%   the row sum vector. This means two straightforward iterations over 
%   $B$ suffice for computing $KBK$.
%   \begin{tcl}
   set rowaverages {}
   set totalsum [complex 0]
   set ninverse [expr {1.0 / [llength $Zero]}]
   foreach row $B {
      set sum [complex 0]
      foreach cell $row {
         set sum [complex + $sum $cell]
      }
      lappend rowaverages [complex . $ninverse $sum]
      set totalsum [complex + $totalsum $sum]
   }
   set totavg [complex . [expr {$ninverse*$ninverse}] $totalsum]
%   \end{tcl}
%   The final per-cell calculation is unrolled into separate |expr|s 
%   for the real and imaginary parts, since not all terms have the 
%   same sign for both.
%   \begin{tcl}
   set KBK {}
   foreach row $B rowavg $rowaverages {
      set KBKrow {}
      foreach cell $row colavgx $rowaverages {
         lappend KBKrow [list [
            expr {[lindex $cell 0] - [lindex $rowavg 0]\
              + [lindex $colavgx 0] + [lindex $totavg 0]}
         ] [
            expr {[lindex $cell 1] - [lindex $rowavg 1]\
              - [lindex $colavgx 1] + [lindex $totavg 1]}
         ]]
      }
      lappend KBK $KBKrow
   }
   return $KBK
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{tclcommand}{ensemble}{algebra}
%   This is all that is needed for the Lie algebra, so here is the 
%   ensemble implementing that. It is attached to the |unitary1fixed| 
%   namespace.
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::unitary1fixed {
   namespace ensemble create -parameters {Zero} -prefix 0 -map {
%   \end{tcl}
%   The \APIref{additive group}{2.1} and \APIref{ring-algebra}{2.1} 
%   methods are simply the |complex_matrix_real_space| ones of the 
%   same names (except for |*|, which is the |commutator|).
%   \begin{tcl}
      =            ::mtmtcl::Lie::complex_matrix_real_space::=
      +            ::mtmtcl::Lie::complex_matrix_real_space::+
      0            ::mtmtcl::Lie::complex_matrix_real_space::0
      neg          ::mtmtcl::Lie::complex_matrix_real_space::neg
      -            ::mtmtcl::Lie::complex_matrix_real_space::-
      iszero       ::mtmtcl::Lie::complex_matrix_real_space::iszero
      .            ::mtmtcl::Lie::complex_matrix_real_space::.
      scalar       ::mtmtcl::Lie::complex_matrix_real_space::scalar
      *            ::mtmtcl::Lie::complex_matrix_real_space::commutator
%   \end{tcl}
%   The \APIref{free ring-module}{2.1} methods were however 
%   implemented above.
%   \begin{tcl}
      basiselement basiselement
      coeff        coeff
      support      support
      basis        basis
%   \end{tcl}
%   And so was the |improve| method of \APIref+{subset}{2.1}, but the 
%   |superset| method is again back to |complex_matrix_real_space|.
%   \begin{tcl}
      improve      algebra_improve
      superset     ::mtmtcl::Lie::complex_matrix_real_space
%   \end{tcl}
%   The \APIref{inner product space}{1.1} and \APIref{metric 
%   space}{1.2} methods also map back there.
%   \begin{tcl}
      innerprod    ::mtmtcl::Lie::complex_matrix_real_space::innerprod
      distance     
          ::mtmtcl::Lie::complex_matrix_real_space::Frobenius_distance
%   \end{tcl}
%   For \APIref{export}{2.0}, this back-mapping is by way of 
%   |mtmtcl::support::subset| facilities.
%   \begin{tcl}
      export       {::mtmtcl::support::subset::superexport1p\
                      ::mtmtcl::Lie::complex_matrix_real_space}
%   \end{tcl}
%   And the only method that remains is |API|.
%   \begin{tcl}
      API {::API::staticn 1 {
         equality              1.0
         "additive group"      2.1
         ring                  2.0
         ring-module           2.1
         ring-algebra          2.0
         "Lie algebra"         1.0
         "free ring-module"    2.1
         "inner product space" 1.1
         "metric space"        1.2
         subset                2.1
         export                2.0
      }}
%   \end{tcl}
%   \begin{tcl}
   } -command [namespace current]::algebra
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% 
% \subsubsection{The group}
% 
% Taking the analogous order of topics for the group, one first 
% arrives at the \APIref{manifold}{1.0} structure since this is what 
% permits a user to introduce guaranteed group elements in an ordered 
% fashion. This can be done as for the full unitary group.
% 
% \begin{proc}{p2c}
%   In particular, a unitary matrix $P$ with \(P\mathbf{1} = 
%   \mathbf{1}\) also has \(P^*\mathbf{1} = P^{-1}\mathbf{1} = 
%   \mathbf{1}\) and thus the antihermitian part \(A = \tfrac{1}{2}(P 
%   -\nobreak P^*)\) automatically satisfies \(A\mathbf{1} = 
%   \frac{1}{2}( P\mathbf{1} -\nobreak P^*\mathbf{1}) = 
%   \tfrac{1}{2}(\mathbf{1} -\nobreak \mathbf{1}) = \mathbf{0}\).
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::p2c {Zero chart point} {
   antihermitian_part $Zero [* $Zero [conjugate $Zero $chart] $point]
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{c2p}
%   Conversely, if \(A\mathbf{1} = \mathbf{0}\) then the 
%   corresponding hermitian part satisfies \(H^2\mathbf{1} = (I 
%   +\nobreak A^2)\mathbf{1} = \mathbf{1} + A^2\mathbf{1} = 
%   \mathbf{1}\), so again the same formula as for the full unitary 
%   group should suffice.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::c2p {Zero chart A} {
   set A2plusI {}; set A2plus2I {}
   foreach row [* $Zero $A $A] {
      lset row [llength $A2plusI] 0\
        [expr {1 + [lindex $row [llength $A2plusI] 0]}]
      lappend A2plusI $row
      lset row [llength $A2plus2I] 0\
        [expr {1 + [lindex $row [llength $A2plus2I] 0]}]
      lappend A2plus2I $row
   }
   set H [. $Zero 0.5 $A2plus2I]
   foreach k {2 3 4 5} {
      set H [+. $Zero 0.5 $H 0.5 [/ $Zero $A2plusI $H]]
   }
   return [group_improve $Zero [* $Zero $chart [+ $Zero $H $A]]]
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{charts}
%   Hence one may also (with the same caveats) use the same distance 
%   calculations as in the full unitary group for deciding whether a 
%   chart covers a point.
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::charts {Zero args} {
   if {![llength $args]} then {return [1 $Zero]}
   set res {}
   set k -1; foreach C $args {incr k
      set D($k,$k) 0
      set ok 1
      set l -1; foreach P $args {incr l
         set D($k,$l) [expr { [info exists D($l,$k)] ? $D($l,$k) :\
            [Frobenius_distance $Zero $C $P]>=1 }]
         if {$D($k,$l)} then {
            set ok 0
            break
         }
      }
      if {$ok} then {lappend res $C}
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% The issue of how to |improve| the representation of an element of 
% $\mathrm{U}^\mathbf{1}(n)$ does on the other hand introduce some 
% new ideas. One derivation of the following method could be to view 
% it as a combination of the |unitary::improve| formula with projection 
% onto the hyperplane through $I$ that is parallel to the subspace of 
% tangent matrices, but a more convincing derivation can be had from 
% considering the eigenstructure of some \(P \in 
% \mathrm{U}^\mathbf{1}(n)\). In that context, the defining equation 
% \(P\mathbf{1} = \mathbf{1}\) states that $\mathbf{1}$ is an 
% eigenvector of $P$ with eigenvalue $1$, so this is probably a good 
% thing to seek to enforce. Doing so is however much easier if one is 
% working in a coordinate system where the relevant eigenvectors are 
% basis vectors, so let $Q$ be the Householder matrix which reflects 
% $\mathbf{e}_n$ to the unit vector in the direction of $\mathbf{1}$ 
% and vice versa, and consider the matrix \(B = QPQ\). This matrix 
% $B$ is unitary since \(Q = Q^{-1} = Q^*\), and \(B\mathbf{e}_n = 
% QPQ\mathbf{e}_n = QP \tfrac{1}{\sqrt{n}}\mathbf{1} = 
% Q \tfrac{1}{\sqrt{n}}\mathbf{1} = \mathbf{e}_n\). It is immediate 
% from the latter that the last column of $B$ is $\mathbf{e}_n$, but 
% that also holds for the last row of $B$ since \(B^* \mathbf{e}_n = 
% B^{-1}\mathbf{e}_n = B^{-1}B\mathbf{e}_n = \mathbf{e}_n\) by 
% unitarity. Hence such a $B$ has the form
% \[
%   B = \begin{bmatrix} B_{11} & 0 \\ 0 & 1 \end{bmatrix}
% \]
% where the $B_{11}$ block is an element of $\mathrm{U}(n -\nobreak 
% 1)$; no wonder then that $\mathrm{U}^\mathbf{1}(n)$ is $(n -\nobreak 
% 1)^2$-dimensional!
% 
% The |improve|ment procedure this suggests for a matrix $P$ that is 
% approximately in $\mathrm{U}^\mathbf{1}(n)$ would then be as 
% follows:
% \begin{enumerate}
%   \item \label{Steg:KoordinatbyteFram}
%     Compute \(B = Q P Q\) (a simple change of coordinates for $P$).
%   \item \label{Steg:NollstallSista}
%     Fill the last row and last column of $B$ with zeroes, except 
%     for the diagonal position which is set to $1$.
%   \item \label{Steg:NewtonUnitar}
%     Replace the $B_{11}$ block with Newton iterate $\tfrac{1}{2}\bigl( 
%     B_{11} +\nobreak (B_{11}^*)^{-1} \bigr)$.
%   \item \label{Steg:KoordinatbyteTillbaka}
%     Finally compute the \texttt{[improve $P$]} as $QBQ$ (undoing 
%     the coordinate change).
% \end{enumerate}
% Now, it is easy to see that
% \[
%   \begin{bmatrix}
%     \tfrac{1}{2} \bigl( B_{11} + (B_{11}^*)^{-1} \bigr) & 0 \\
%     0 & 1
%   \end{bmatrix}
%   =
%   \tfrac{1}{2} \left(
%     \begin{bmatrix} B_{11} & 0 \\ 0 & 1 \end{bmatrix} +
%     \left( \begin{bmatrix} B_{11} & 0 \\ 0 & 1 \end{bmatrix}^* 
%     \right)^{-1} 
%   \right)
% \]
% so the conjugation and inversion can just as well be carried out 
% for $n \times n$ matrices instead. This is slightly wasteful, but 
% doing it for $(n -\nobreak 1) \times (n -\nobreak 1)$ matrices 
% instead would only save $O(n^2)$ operations, and the practical cost 
% of cutting out the $B_{11}$ block from the big matrix should not be 
% ignored. An advantage of doing step~\ref{Steg:NewtonUnitar} for $n 
% \times n$ matrices instead is that it then commutes with 
% step~\ref{Steg:KoordinatbyteTillbaka}, which means the unitarity 
% and $\mathbf{1}$-is-eigenvector constraints can be enforced 
% separately.
% 
% Step~\ref{Steg:NollstallSista} can be carried out as
% \[
%   \begin{bmatrix} I_{n-1} & 0 \\ 0 & 0 \end{bmatrix} B
%     \begin{bmatrix} I_{n-1} & 0 \\ 0 & 0 \end{bmatrix} +
%   \mathbf{e}_n \mathbf{e}_n^\mathrm{T}
%   =
%   (I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T})  B
%     (I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T}) +
%   \mathbf{e}_n \mathbf{e}_n^\mathrm{T}
% \]
% which means the composition of steps~\ref{Steg:KoordinatbyteFram}, 
% \ref{Steg:NollstallSista}, and~\ref{Steg:KoordinatbyteTillbaka} is
% \begin{multline*}
%   Q \bigl(
%     (I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T})  QPQ
%       (I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T}) +
%     \mathbf{e}_n \mathbf{e}_n^\mathrm{T}
%   \bigr) Q 
%   = \\ =
%   Q(I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T})Q \cdot P \cdot
%     Q(I - \mathbf{e}_n \mathbf{e}_n^\mathrm{T})Q
%   + Q \mathbf{e}_n \mathbf{e}_n^\mathrm{T} Q 
%   = \\ =
%   (I - Q \mathbf{e}_n \mathbf{e}_n^\mathrm{T} Q) P 
%     (I - Q \mathbf{e}_n \mathbf{e}_n^\mathrm{T} Q) +
%   Q \mathbf{e}_n \mathbf{e}_n^\mathrm{T} Q 
%   = 
%   (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}) P
%     (I - \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T})
%   + \tfrac{1}{n} \mathbf{1} \mathbf{1}^\mathrm{T}
%   = \\ =
%   P - 
%   \tfrac{1}{n}\bigl( \mathbf{1} \mathbf{1}^\mathrm{T} P + 
%     P \mathbf{1} \mathbf{1}^\mathrm{T} \bigr) +
%   \mathbf{1} ( 
%     \tfrac{1}{n} + 
%     \tfrac{1}{n^2} \mathbf{1}^\mathrm{T} P \mathbf{1}
%   ) \mathbf{1}^\mathrm{T}
%   \text{;}
% \end{multline*}
% a calculation that avoids computing $Q$ in the first place, and 
% also all matrix--matrix multiplications. Instead it amounts to 
% adjusting each matrix element by a combination of corresponding row 
% sum, corresponding column sum, and total sum.
% 
% \begin{proc}{group_improve}
%   The |group_improve| procedure, which has the syntax
%   \begin{displaysyntax}
%     |group_improve| \word{Zero} \word{$P$}
%   \end{displaysyntax}
%   thus consists of three parts. In the first, the row, column, and 
%   total sums are computed. In the second, these are used to adjust 
%   the elements of $P$. In the third, an average of $P$ and 
%   $(P^{-1})^*$ is taken.
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::group_improve {Zero P} {
%   \end{tcl}
%   Row sums are easy (just two nested |foreach|s over $P$), and 
%   the total sum is the sum of the row sums, but column sums are a 
%   bit trickier. Below, the same |lindex| trick is used as in the 
%   implementation of |conjugate|, which means the inner |foreach| 
%   has an extra iteration over the rows of $P$. Elements in the 
%   |rowsums| and |colsums| list have been multiplied by the 
%   $\frac{1}{n}$ factor, so these are the vectors $\tfrac{1}{n} P 
%   \mathbf{1}$ and $\tfrac{1}{n} \mathbf{1}^\mathrm{T} P$ 
%   respectively.
%   \begin{tcl}
   set rowsums {}
   set colsums {}
   set totalsum [complex 0]
   set ninv [expr {1.0 / [llength $Zero]}]
   foreach row $P {
      set colsum [set rowsum [complex 0]]
      foreach cell $row row2 $P {
         set rowsum [complex + $rowsum $cell]
         set colsum [complex + $colsum [lindex $row2 [llength $colsums]]]
      }
      lappend rowsums [complex . $ninv $rowsum]
      lappend colsums [complex . $ninv $colsum]
      set totalsum [complex + $totalsum $rowsum]
   }
   set totadj [complex cartesian [
      expr {$ninv * (1 + $ninv*[complex Re $totalsum])}
   ] [
      expr {$ninv * $ninv * [complex Im $totalsum]}
   ]]
%   \end{tcl}
%   The |totadj| is the complex number $\tfrac{1}{n} + 
%   \tfrac{1}{n^2} \mathbf{1}^\mathrm{T} P \mathbf{1}$. With this, 
%   one easily computes
%   \begin{math}
%     R = P - 
%     \tfrac{1}{n}\bigl( \mathbf{1} \mathbf{1}^\mathrm{T} P +\nobreak 
%       P \mathbf{1} \mathbf{1}^\mathrm{T} \bigr) +
%     \mathbf{1} ( 
%       \tfrac{1}{n} +\nobreak 
%       \tfrac{1}{n^2} \mathbf{1}^\mathrm{T} P \mathbf{1}
%     ) \mathbf{1}^\mathrm{T}
%   \end{math}.
%   \begin{tcl}
   set R {}
   foreach prow $P rowsum $rowsums {
      set rrow {}
      foreach cell $prow colsum $colsums {
         lappend rrow [complex - [complex + $cell $totadj]\
           [complex + $rowsum $colsum]]
      }
      lappend R $rrow
   }
%   \end{tcl}
%   Finally, there is the Newton step.
%   \begin{tcl}
   return [. $Zero 0.5 [+ $Zero $R [conjugate $Zero [inverse $Zero $R]]]]
}
%   \end{tcl}
% \end{proc}
% 
% Now, might that introduce a systematic error? Luckily no, and for 
% this the $B$ matrix coordinate system is easier to reason about. We 
% know from before that if \(B_{11} = U (I+\nobreak H)\) is a polar 
% decomposition of the $B_{11}$ block then the Newton step preserves the 
% unitary factor $U$. Moreover the tangent space of $\mathrm{U}(n 
% -\nobreak 1)$ embedded in $\mathrm{U}(n)$ is restricted to the 
% first $n-1$ rows and columns, whereas the changes wrought by 
% step~\ref{Steg:NollstallSista} only affects the last row or column. 
% Hence that difference is always Frobenius-orthogonal to the tangent 
% space, and should therefore not cause any drift when viewed from 
% within $\mathrm{U}^\mathbf{1}(n)$.
% 
% 
% \begin{tclcommand}{ensemble}{group}
%   Thus we are ready the define the |group| structure. 
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::unitary1fixed {
   namespace ensemble create -parameters {Zero} -map {
%   \end{tcl}
%   Only the basic \APIref{group}{1.1} operations are fetched from 
%   |complex_matrix_real_space|.
%   \begin{tcl}
      =         ::mtmtcl::Lie::complex_matrix_real_space::=
      *         ::mtmtcl::Lie::complex_matrix_real_space::*
      1         ::mtmtcl::Lie::complex_matrix_real_space::1
      inverse   ::mtmtcl::Lie::complex_matrix_real_space::conjugate
%   \end{tcl}
%   The \APIref{manifold}{1.0} operations are implemented here.
%   \begin{tcl}
      charts    charts
      p2c       p2c
      c2p       c2p
      coord     algebra
%   \end{tcl}
%   The |tangent| space is again the Lie algebra, and the exponent map 
%   is something mapped in from the general complex matrix namespace.
%   \begin{tcl}
      tangent   algebra
      exp       ::mtmtcl::Lie::complex_matrix_real_space::exp
%   \end{tcl}
%   The application below will require the unitary group to also be a 
%   \APIref{metric space}{1.0}, and in addition it is a 
%   \APIref+{subset}{2.1}. 
%   \begin{tcl}
      distance  ::mtmtcl::Lie::complex_matrix_real_space::Frobenius_distance
      superset  ::mtmtcl::Lie::complex_matrix_real_space
      improve   group_improve
%   \end{tcl}
%   With |export| as in the |algebra| and an |API| method, that is 
%   actually all we need in this ensemble.
%   \begin{tcl}
      export     {::mtmtcl::support::subset::superexport1p\
                   ::mtmtcl::Lie::complex_matrix_real_space}
      API {::API::staticn 1 {
         equality       1.0
         semigroup      1.1
         monoid         1.1
         group          1.1
         manifold       1.0
         "Lie group"    1.1
         "metric space" 1.2
         subset         2.1
         export         2.0
      }}
   } -prefix 0 -command [namespace current]::group
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% \subsubsection{The constructor}
% 
% \begin{proc}{make}
%   The final (and only public) command in this package is the usual 
%   constructor that |make|s a command prefix for a concrete structure. 
%   This command has the syntax
%   \begin{displaysyntax}
%     ::mtmtcl::Lie::unitary1fixed::make 
%     \begin{regblock} algebra \regalt group \end{regblock}
%     \word{side}
%   \end{displaysyntax}
%   \begin{tcl}
proc ::mtmtcl::Lie::unitary1fixed::make {what n} {
   incr n 0
   if {$n < 1} then {
      return -code error "0-by-0 matrices are not supported"
   }
   set zero [complex 0]
   set L {}
   for {set i 0} {$i < $n} {incr i} {lappend L $zero}
   set Zero {}
   for {set i 0} {$i < $n} {incr i} {lappend Zero $L}
   switch -- $what group - algebra {
      return [list [namespace which $what] $Zero]
   } default {
      return -code error "Unknown aspect '$what':\
        must be algebra or group"
   }
}
%</unitary1fixed>
%   \end{tcl}
% \end{proc}
% 
% 
% 
% 
% 
% \section{Golden section search}
% 
% A problem that arises in many contexts is that of finding the 
% minimum (at least a local one) of a function. Different algorithms 
% for this have different requirements, and one that provides an 
% excellent fit for the context of a Lie group is the golden section 
% search method. Technically, this method merely searches a 
% one-dimensional submanifold (i.e., a curve) for a local minimum, 
% but it can be combined with a gradient computation to make a 
% steepest descent minimum finder.
% 
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::golden 1.0 golden
%</docstrip.tcl::catalogue>
%<*golden>
package require Tcl 8.5
namespace eval ::mtmtcl::Lie::golden {}
% \end{tcl}
% \setnamespace{mtmtcl::Lie::golden}
% 
% 
% \subsection{Usage}
% 
% The way to use this package is to start with the call
% \begin{displaysyntax}
%   \describestring*[proc][mtmtcl::Lie::golden]{minimising}
%   mtmtcl::Lie::golden::minimising \word{function} \word{group} 
%   \word{point} \word{stepdir} \word{unit}\regopt
% \end{displaysyntax}
% where \word{function} is a command prefix implementing the function 
% to minimise, \word{group} is a command prefix for the 
% \APIref{Lie group}{1.0} on which the \word{function} is defined, 
% \word{point} is the point at which to start, \word{stepdir} is 
% a `\texttt{\meta{group} tangent}' determining the direction in 
% which to search (and the length of the initial step), and the 
% optional \word{unit} is described under Requirements below. The 
% \word{function} must have the call syntax
% \begin{displaysyntax}
%   \meta{function} \word{point}
% \end{displaysyntax}
% and return its value as a native \Tcllogo\ number (typically a 
% |double|). Mathematically, the \word{function} need not be 
% differentiable or anything like that, but it would probably be odd 
% to apply this machinery to a function that isn't at least piecewise 
% continuous.
% 
% The curve on which the above seeks to find a minimum of the 
% function is
% \begin{center}
%   \texttt{[\meta{group} * \word{point} [\meta{group} exp 
%   [\meta{group} tangent .\@ $t$ \word{stepdir}]]]}
% \end{center}
% for \(t \geqslant 0\), with a preference for the interval \(0 
% \leqslant t \leqslant 1\); in other words it is the integral curve 
% of the left-invariant vector field $L^{\text{\word{stepdir}}}$ that 
% goes through the \word{point} at \(t=0\).
% 
% What the |minimising| command returns is not the minimum found, but 
% rather a value that represents the state of the minimisation 
% process. This can then be operated upon to perform another search 
% step or queried for what the best point found so far is. The 
% commands which do that are
% \begin{displaysyntax}
%   mtmtcl::Lie::golden::next \word{state} \word{new-var}
%   \par
%   mtmtcl::Lie::golden::bestpoint \word{state}
%   \par
%   mtmtcl::Lie::golden::bestvalue \word{state}
%   \par
%   \describestring*[proc][mtmtcl::Lie::golden]{stepsize}
%   mtmtcl::Lie::golden::stepsize \word{state}
%   \par
%   \describestring*[proc][mtmtcl::Lie::golden]{trend}
%   mtmtcl::Lie::golden::trend \word{state}
% \end{displaysyntax}
% The \describestring+[proc][mtmtcl::Lie::golden]{next} command 
% returns a boolean, which is true as long as the process can 
% meaningfully continue another step.\footnote{
%   Actually, it returns one of \texttt{0}, \texttt{1}, and 
%   \texttt{2}. The difference between \texttt{1} and \texttt{2} 
%   (both valid as boolean true) is that \texttt{2} is returned to 
%   signal that the \texttt{bestpoint} has changed, which can be 
%   useful if the search progress is being displayed to the user.
% } The \word{new-var} is the name 
% of a variable in the calling context which will be set to the new 
% state of the minimisation process. Hence a full search round might 
% be coded as
% \begin{quote}
%   \small\ttfamily
%   set state [mtmtcl::Lie::golden::minimising $f$ $G$ $p$ $d$]\\
%   |while {[mtmtcl::Lie::golden::next $state state]} {|\\
%   \verb"   if {[mtmtcl::Lie::golden::stepsize $state] < 0.0001}"^^A
%   \verb" then {break}"\\
%   |}|\\
%   |set foundpoint [mtmtcl::Lie::golden::bestpoint $state]|
% \end{quote}
% if getting within a distance of $0.0001$ from the minimum is 
% sufficient.
% 
% The \describestring+[proc][mtmtcl::Lie::golden]{bestvalue} and 
% \describestring+[proc][mtmtcl::Lie::golden]{bestpoint} commands 
% return the best function value computed so far, and the point at 
% which it was attained respectively. 
% The \describestring+[proc][mtmtcl::Lie::golden]{stepsize} command 
% returns the current step size, i.e., the length of the vector 
% $\mathit{\Delta t} d$, where $d$ is the specified \word{stepdir} 
% vector and $\mathit{\Delta t}$ is what would be the difference in 
% parameter $t$ between the two most recently considered points. This 
% is an estimate on the distance between those two points, which 
% should be fairly accurate for close points, and in all cases be an 
% upper bound on the shortest distance.
% 
% The \describestring+[proc][mtmtcl::Lie::golden]{trend} command 
% returns |1| if the function, as far as currently examined, only seems 
% to be increasing in the search interval, |-1| if it only seems to 
% be decreasing, and |0| otherwise (i.e., the currently considered 
% interval contains a minimum). This is most useful immediately after 
% a |minimising| call, and can when one is solving several similar 
% minimisation problems be used to adjust the initial step size: |1| 
% means the initial step is probably too long, |-1| means it is 
% probably too short, and |0| means it is about right.
% 
% Being a value, there is no need to explicitly dispose of a 
% \word{state} once you're done with it.
% 
% 
% \subsubsection{Requirements}
% 
% The \word{group} $G$ must satisfy a number of requirements for the 
% above commands to work, namely:
% \begin{itemize}
%   \item
%     $G$ must be a \APIref+{Lie group}{1.0} and a 
%     \APIref+{subset}{2.1}.
%     
%   \item
%     $G$ must also be a \APIref+{metric space}{1.0}, and satisfy
%     \begin{equation*}
%       \text{\texttt{[$G$ distance $b$ $c$]}} =
%       \text{\texttt{[$G$ distance [$G$ * $a$ $b$] [$G$ * $a$ $c$]]}}
%     \end{equation*}
%     for all \(a,b,c \in G\). In other words, the metric must be 
%     invariant under the left action of $G$ upon itself.
%     
%     From combining this with the triangle inequality, it follows 
%     that the distance from $a^n$ to the identity is at most $n$ 
%     times the distance from $a$ to the identity. From combining it 
%     with symmetry of distance, it follows that $a$ and $a^{-1}$ 
%     have the same distance to the identity.
%     
%   \item
%     The `\texttt{$G$ tangent}' space must be an 
%     \APIref+{inner product space}{2.1} over 
%     |::mtmtcl::rings::float| (in principle it could also be some 
%     other implementation of ``the real numbers'', but any value it 
%     supports must be a legal \Tcllogo\ |double|, and it must accept 
%     every |double| as a legal value).
%     
%   \item
%     The |distance| in $G$ and the inner product on the 
%     |tangent| space must be related such that
%     \begin{equation*}
%       U = \lim_{v \to \text{\texttt{[$G$ tangent 0]}}}
%       \frac{
%         \text{\texttt{[$G$ distance [$G$ 1] [$G$ exp $v$]]}}^2
%       }{
%         \text{\texttt{[$G$ tangent innerprod $v$ $v$]}}
%       }
%     \end{equation*}
%     exists and is positive.
%     
%     In the important case that the inner product on the tangent 
%     space and the distance in $G$ are both derived from the same 
%     inner product on some superset of $G$, then this requirement 
%     is automatically fulfilled with \(U=1\). 
% \end{itemize}
% A consequence of the last condition is that
% \begin{equation*}
%    \text{\texttt{[$G$ distance [$G$ 1] [$G$ exp $v$]]}}
%    \leqslant 
%    \sqrt{U} \sqrt{
%      \text{\texttt{[$G$ tangent innerprod $v$ $v$]}}
%    }
% \end{equation*}
% because the left hand side is bounded from above by $n$ times the 
% distance from the unit to \texttt{[$G$ exp $\frac{1}{n}v$]}, and 
% for any $\varepsilon > 0$ there is some $n$ such that the latter 
% is less than or equal to $\sqrt{1 + \varepsilon} \sqrt{U} 
% \sqrt{ \text{\texttt{[$G$ tangent innerprod $\tfrac{1}{n}v$ 
% $\tfrac{1}{n}v$]}} }$. Hence $\sqrt{U}$ says how many `\texttt{$G$ 
% distance}' units correspond to one `\texttt{$G$ tangent 
% innerprod}' unit, and that is precisely the ideal value for the 
% \word{unit} argument of the |minimising| command. 
% 
% In practice one may however want to add a small tolerance factor, 
% since the reason these distances are being computed is to guard 
% against a certain instability in the algorithm, but it matters 
% little whether that guard reacts at step $n$ or step $n+1$. On the 
% other hand, one would not want to make the guard so sensitive that 
% it is prone to react on numerical errors in the computation of the 
% distance (cancellation is likely to occur) rather than an actual 
% signal. Therefore the default for \word{unit} is $1.1$, which adds 
% a $10\%$ tolerance to \(\sqrt{U} = 1\).
% 
% 
% \subsection{Implementation}
% 
% \begin{tclcommand}{alias}{next}
% \begin{tclcommand}{alias}{stepsize}
% \begin{tclcommand}{alias}{bestvalue}
% \begin{tclcommand}{alias}{bestpoint}
%   The operations on search states are implemented using the 
%   data-is-code technique. Therefore these are technically aliases 
%   to |namespace inscope| calls to similarly named namespaces, and 
%   the actual implementations of the operations are provided by the 
%   procedures in those namespaces.
%   
%   The following loop was put in a lambda to keep the loop variable 
%   local.
%   \begin{tcl}
apply {args {
   foreach op $args {
      namespace eval $op {}
      interp alias {} [namespace current]::$op {}\
        namespace inscope [namespace current]::$op
   }
} ::mtmtcl::Lie::golden} next stepsize bestvalue bestpoint
%   \end{tcl}
% \end{tclcommand}\end{tclcommand}\end{tclcommand}\end{tclcommand}
% 
% 
% \setnamespace{mtmtcl::Lie::golden::next}
% 
% \begin{variable}{phi}
%   The constant \(\phi = \frac{1}{2}\left( 1 + \sqrt{5} \right)\) 
%   will be used by all |next| operations, so it might as well be 
%   precomputed.
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::golden::next {
   variable phi [expr {0.5*(1+sqrt(5))}]
}
%   \end{tcl}
% \end{variable}
% 
% 
% \subsubsection{To the bottom of the valley}
% 
% The normal state of operation for the golden section (and many 
% other minimum-finding) algorithm(s) is that it has located a 
% ``valley'' described by three points $a$, $b$, and $c$, where $b$ 
% is between $a$ and $c$, and \(f(a) > f(b) < f(c)\); in this 
% situation $b$ is the |bestpoint|, $f(b)$ is the |bestvalue|, and it 
% is known that $f$ has a local minimum between $a$ and $c$. By 
% picking a new point $d$ in the valley, and comparing $f(d)$ to 
% $f(b)$, one can pick a smaller interval that is also a valley, and 
% thereby get tighter bounds on where a minimum can be found; the 
% basic rule is that if \(f(d) < f(b)\) then one should drop the 
% endpoint that is on the other side of $b$ from $d$, replacing it 
% with $b$ while $d$ becomes the new middle, whereas if \(f(d) > 
% f(b)\) then one should drop the endpoint that is on the same side 
% of $b$ as $d$, and replace it with $d$ in the description of the 
% valley. Since this preserves the valley structure, it will 
% eventually find a minimum, even though there is no guarantee that 
% it finds the \emph{least} minimum within the original valley if 
% there was more than one; a wide subvalley is more likely to be found 
% than a narrow one, even if the latter should turn out to be deeper.
% 
% On the real line, what is special about the golden section is that 
% it preserves the proportions between the subintervals, thus making 
% the rate of convergence fixed and dependable. A valley with width 
% $1$ would have two parts of widths \(\phi^{-1} \approx 0.618\) 
% and \(\phi^{-2} = 1 - \phi^{-1} \approx 0.382\) respectively. 
% A golden section of the larger produces a partition $\phi^{-2} + 
% \phi^{-3} + \phi^{-2}$ of $1$, where both the subinterval consisting 
% of the first two parts and the subinterval consisting of the last 
% two parts has length $\phi^{-1}$, split by the given points into 
% one part of length $\phi^{-2}$ and one part of length $\phi^{-3}$. 
% Hence regardless of which endpoint is dropped, the points remain as 
% evenly spread as they were in the step before.
% 
% In a Lie group, the golden section arrangement has the additional 
% advantage that the new point $d$ can be computed as $a b^{-1} c$, 
% i.e, using only \APIref{group}{1.0} operations; in terms of the 
% curve parameter $t$, this corresponds to \(t_d = t_a - t_b + t_c\), 
% which is merely the fourth point needed to make the arrangement 
% symmetric around the midpoint between $t_a$ and $t_c$. Other ways 
% of partitioning an interval, for example picking out the midpoint 
% (bisecting), involve the taking of fractional multiples of real 
% numbers, and thus correspond to fractional exponents (square roots 
% or worse) in the Lie group. The exponential map |exp| could be used 
% to compute what one needs, but the golden section makes it possible 
% to stick with plain group operations for the iterations, and only 
% use the typically more expensive exponential map to find the first 
% two subintervals (which happens in the |minimising| command).
% 
% Therefore the \word{state} need not keep track of absolute $t$ 
% values, and a valley state can have the structure
% \begin{displaysyntax}
%   valley \word{left} \word{middle} \word{right} \word{group} 
%   \word{function} \word{middle-value} \word{stepsize}
% \end{displaysyntax}
% where \word{left}, \word{middle}, and \word{right} are the three 
% points known in the valley; the interval from \word{left} to 
% \word{middle} shall be the larger part and that from \word{middle} 
% to \word{right} the smaller part. The \word{group} is the group in 
% which calculations are made and \word{function} is the function of 
% which a minimum is sought. The \word{middle-value} is the value of 
% the \word{function} at \word{middle}. The \word{stepsize} is the 
% current |stepsize|.
% 
% The reason for keeping track of the \word{stepsize} is that the 
% computationally cheap formula \(d = a b^{-1} c\) comes at a price, 
% in that it opens up the risk that the points drift away due to 
% accumulated errors. Even in the one-dimensional iteration of \(t_d = 
% t_a - t_b + t_c\), it is only for an arrangement in exact golden 
% ratio that this process converges; any deviation from the exact 
% ratio is instead magnified by the process, by the same factor of 
% $\phi$ as the desired proportions are being shrunk. Hence it is 
% only a matter of time before the golden ratio signal is drowned in 
% random noise! The \word{stepsize} provides a way of detecting when 
% the noise becomes noticable, as the distance from $b$ to $d$ can be 
% measured and should, as long as the iteration stays on track, not 
% exceed the \word{stepsize}.
% 
% When the process seizes to converge at the predicted rate, the 
% |next| command returns false and the \word{state} is changed to
% \begin{displaysyntax}
%   derailed \word{point} \word{value} \word{stepsize} \word{counter}
% \end{displaysyntax}
% where the \word{point}, \word{value}, and \word{stepsize} are the 
% data extracted by |bestpoint|, |bestvalue|, and |stepsize| 
% respectively. The \word{counter} is a guard against poorly written 
% callers who keep calling |next| even though it returns false: when 
% this reaches $3$, it will throw an outright error rather than 
% continue to do nothing.
% 
% 
% \begin{proc}{valley}
%   Thus enough has been specified that the |valley| implementation 
%   of the |next| operation can be given. Combining the above, it 
%   follows that the call syntax of this procedure shall be
%   \begin{displaysyntax}
%     mtmtcl::Lie::golden::next::valley \word{left} \word{middle} 
%     \word{right} \word{group} \word{function} \word{middle-value} 
%     \word{stepsize} \word{varname}
%   \end{displaysyntax}
%   Notable here is that the \word{varname} refers to a variable two 
%   levels up on the context stack, as one level up is the 
%   |namespace inscope ::mtmtcl::Lie::golden::next|.
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::next::valley {a b c G f fb step varname} {
   upvar 2 $varname newstate
   variable phi
%   \end{tcl}
%   First order of business is to compute the new point \(d = a 
%   b^{-1} c\), the function value $f(d)$, the distance from $b$ to 
%   $d$, and the new stepsize. The point $d$ is |improve|d once, to 
%   keep it at least on the Lie group (even if not necessarily on the 
%   target curve).
%   \begin{tcl}
   set d [{*}$G improve [
      {*}$G * $a [{*}$G * [{*}$G inverse $b] $c]
   ]]
   set fd [{*}$f $d]
   set dist [{*}$G distance $b $d]
   set step [expr {$step/$phi}]
%   \end{tcl}
%   Then execution branches into cases corresponding to how the 
%   things computed above compare. That |dist| exceeds |step| means we 
%   are now |derailed|, but $d$ could still be a better point than 
%   $b$.
%   \begin{tcl}
   if {$dist > $step} then {
      if {$fd < $fb} then {
         set newstate [list derailed $d $fd $step 0]
      } else {
         set newstate [list derailed $b $fb $step 0]
      }
      return 0
   } elseif {$fd < $fb} then {
%   \end{tcl}
%   If $d$ is the new \word{middle} of the valley, then $a$ will 
%   remain the \word{left} and $b$ will become the new \word{right}.
%   \begin{tcl}
      set newstate [list valley $a $d $b $G $f $fd $step]
      return 2
   } else {
%   \end{tcl}
%   If instead $b$ remains the \word{middle}, then it is $c$ that 
%   will become the new \word{left} and $d$ which will become the new 
%   \word{right}, because $c$ is farther away from $b$ than $d$ is. 
%   This means the direction on the curve is reversed, but the old 
%   state didn't know which direction was the original anyway, so it 
%   makes absolutely no difference.
%   \begin{tcl}
      set newstate [list valley $c $b $d $G $f $fb $step]
      return 1
   }
}
%   \end{tcl}
%   Only switching \word{middle} when a strictly lower value is found 
%   has the effect that the first point to hit a flat section will 
%   also be the reported minimum. Since points on both sides of it 
%   are being examined, it really is a local minimum (even if only 
%   one of many).
% \end{proc}
% 
% 
% \begin{proc}{derailed}
%   It was mentioned above that a state that has been |derailed| for 
%   two cycles will throw an error if one tries to advance it a third 
%   time.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::next::derailed {point value step count varname} {
   incr count
   if {$count >= 3} then {
      return -code error -errorcode {mtmtcl::Lie::golden derailed}\
        "I've told you twice already that the golden section\
        is off track"
   }
   uplevel 2 [list ::set $varname\
     [list derailed $point $value $step $count]]
   return 0
}
%   \end{tcl}
% \end{proc}
% 
% 
% 
% \subsubsection{When a valley is yet to be found}
% 
% However, not every triplet of points describe a valley. One 
% slightly disappointing situation that might obviously occur is that 
% the best point found so far is the starting point, in which case 
% all the data gathered looks as if the chosen direction is just an 
% uphill slope. On the other hand, it may be assumed that the user 
% has reason to expect the function to decrease in the given 
% direction, so presumably there is a valley near that starting 
% point, even if the other two points are apparently located at higher 
% altitudes in the slope on the other side of the valley. Hence what 
% one should do is to scale down towards the starting point until the 
% middle starts to dip below the starting level.
% 
% \begin{proc}{uphill}
%   Practically, this uphill situation is a separate family of 
%   states, even though the particulars are very close to those of 
%   the |valley| states. An |uphill| \word{state} has the form
%   \begin{displaysyntax}
%     uphill \word{left} \word{middle} \word{right} \word{group} 
%     \word{function} \word{left-value} \word{stepsize}
%   \end{displaysyntax}
%   which is different from |valley| only in that the cached value is 
%   associated with the \word{left} point rather than the 
%   \word{middle} point.
%   
%   The actual calculations are also mostly the same.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::next::uphill {a b c G f fa step varname} {
   upvar 2 $varname newstate
   variable phi
   set d [{*}$G improve [
      {*}$G * $a [{*}$G * [{*}$G inverse $b] $c]
   ]]
   set fd [{*}$f $d]
   set dist [{*}$G distance $b $d]
   set step [expr {$step/$phi}]
   if {$dist > $step} then {
      if {$fd < $fa} then {
         set newstate [list derailed $d $fd $step 0]
      } else {
         set newstate [list derailed $a $fa $step 0]
      }
      return 0
   } else {
%   \end{tcl}
%   The part where there are some differences (other than in the name 
%   of the |fa| variable) is in the forming of the |newstate|. When a 
%   point $d$ is found with \(f(d) < f(a)\) then the state switches 
%   of a |valley| one, but until that time the interval just shrinks 
%   by dropping the \word{right} endpoint.
%   \begin{tcl}
      if {$fd < $fa} then {
         set newstate [list valley $a $d $b $G $f $fd $step]
         return 2
      } else {
         set newstate [list uphill $a $d $b $G $f $fa $step]
         return 1
      }
   }
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{downhill}
%   The other, and in a sense much nicer, way in which a valley may 
%   fail to emerge is that the function values seem to decrease the 
%   further right you go; it looks as though the surveyed interval is 
%   just part of the left side of a rather large valley. What one 
%   preferably does in this case is the exact opposite of the 
%   previous one, namely to \emph{grow} the interval by computing a new 
%   point outside it. This too can be done entirely using group 
%   operations; if the known points for analogy with the above are 
%   denoted $a$, $d$, and $b$, then what is required to preserve the 
%   proportions is a point $c$ such that \(d = a b^{-1} c\), i.e., 
%   one wishes to compute \(c = b a^{-1} d\). If \(f(c) > f(b)\) then 
%   $(c,b,d)$ (direction reversal because of relative sizes) constitutes 
%   the sought |valley|, and otherwise $(a,b,c)$ is a larger |downhill| 
%   section.
%   
%   The structure of a |downhill| state is
%   \begin{displaysyntax}
%     downhill \word{left} \word{middle} \word{right} \word{group} 
%     \word{function} \word{right-value} \word{stepsize}
%   \end{displaysyntax}
%   thus forming a symmetric set together with |uphill| and |valley|. 
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::next::downhill {a d b G f fb step varname} {
   upvar 2 $varname newstate
   set c [{*}$G improve [
      {*}$G * $b [{*}$G * [{*}$G inverse $a] $d]
   ]]
   set fc [{*}$f $c]
   if {$fc > $fb} then {
      set newstate [list valley $c $b $d $G $f $fb $step]
      return 1
   }
%   \end{tcl}
%   No derailment check is performed in the case that the |newstate| 
%   becomes a |valley|, because there would be no great harm in taking 
%   one more step before declaring derailment. There is furthermore 
%   the issue that the meaning of the subsequently visible |stepsize| 
%   becomes unclear; what one would have compared against is $\phi$ 
%   times the old stepsize, but if we stay on track the this 
%   multiplication should not be carried over to the |newstate|.
%   
%   If instead the |downhill| continues then there is no such 
%   ambiguity, as the |stepsize| was compared against the two closest 
%   points.
%   \begin{tcl}
   variable phi
   set dist [{*}$G distance $b $c]
   set step [expr {$step*$phi}]
   if {$dist > $step} then {
      set newstate [list derailed $c $fc $step 0]
      return 0
   } else {
      set newstate [list downhill $a $b $c $G $f $fc $step]
      return 2
   }
}
%   \end{tcl}
% \end{proc}
% 
% 
% \subsubsection{Setting up the search}
% 
% \setnamespace{mtmtcl::Lie::golden}
% 
% \begin{proc}{minimising}
%   Thanks to the fantastic properties of the golden section, 
%   constructing a new state from an old one is easy, but creating a 
%   state from scratch requires a bit more. First one must compute 
%   the intial trio of points and the corresponding stepsize. \(c = a 
%   \exp(\mathit{dir})\) and \(b = a \exp(\phi^{-1} \mathit{dir})\), 
%   whereas the stepsize is an upper bound on the distance from $b$ to 
%   $c$, i.e., an upper bound on the distance from the identity to 
%   $\exp( \phi^{-2} \mathit{dir})$.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::minimising {f G a dir {unit 1.1}} {
   set phiinv [expr {2 / (1 + sqrt(5))}]
   set c [{*}$G * $a [{*}$G exp $dir]]
   set b [{*}$G * $a [{*}$G exp [{*}$G tangent . $phiinv $dir]]]
   set step [expr {$unit * $phiinv*$phiinv * sqrt([
      {*}$G tangent innerprod $dir $dir
   ])}]
%   \end{tcl}
%   Then the process branches out into a number of cases, depending 
%   on how $f(a)$, $f(b)$, and $f(c)$ compare. The state-driven code 
%   structure used above actually simplifies the implementation, as 
%   a more traditional code structure with separate loops 
%   corresponding to |valley|, |uphill|, and |downhill| states becomes 
%   a bit complicated.
%   \begin{tcl}
   set fa [{*}$f $a]
   set fb [{*}$f $b]
   if {$fa < $fb} then {
      return [list uphill $a $b $c $G $f $fa $step]
%   \end{tcl}
%   If \(f(a) < f(b)\) then there is an |uphill| structure. One could 
%   make the effort to compute $f(c)$ also in the hope that this is 
%   even smaller and thus allows reclassifying the thing as a 
%   |downhill| structure, but I suspect this would be a very rare 
%   occurrence, so it's better to stick with what we know (or at 
%   least presume): that $f$ is decreasing at $a$, and that there 
%   therefore is a minimum between $a$ and $b$.
%   
%   Otherwise the choice is between |valley| and |downhill|. The case 
%   where this choice is perhaps not entirely obious is that \(f(c) = 
%   f(b)\), since it could in principle happen that $f$ is decreasing 
%   from $a$ to $b$, then constant from $b$ to $c$, before it starts 
%   decreasing again; this would qualify as |downhill|. On the other 
%   hand, that is not a very likely scenario, and it would also 
%   qualify as a |valley| (in that the point that |valley| locates is 
%   a local minimum).
%   \begin{tcl}
   }
   set fc [{*}$f $c]
   if {$fc < $fb} then {
      return [list downhill $a $b $c $G $f $fc $step]
   } else {
      return [list valley $a $b $c $G $f $fb $step]
   }
}
%   \end{tcl}
% \end{proc}
% 
% 
% \subsubsection{Extracting the results}
% 
% What remains now is only to define the procedures implementing the 
% |bestpoint|, |bestvalue|, and |stepsize| operations on a state.
% 
% \setnamespace{mtmtcl::Lie::golden::bestpoint}
% 
% \begin{proc}{valley}
%   The |bestpoint| of a |valley| is the middle.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestpoint::valley {a b c G f fb step} {
   return $b
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{uphill}
%   The |bestpoint| in an |uphill| slope the left.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestpoint::uphill {a b c G f fa step} {
   return $a
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{downhill}
%   The |bestpoint| in a |downhill| slope the right.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestpoint::downhill {a b c G f fc step} {
   return $c
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{derailed}
%   And after becoming |derailed|, there is only one point.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestpoint::derailed {p fp step count} {
   return $p
}
%   \end{tcl}
% \end{proc}
% 
% \setnamespace{mtmtcl::Lie::golden::bestvalue}
% 
% \begin{proc}{valley}
% \begin{proc}{uphill}
% \begin{proc}{downhill}
%   The |bestvalue| is always the only value that the state 
%   remembers. Because of the great structural similarity between the 
%   three main states, they could all be the same command, but 
%   defining them separately isn't any longer.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestvalue::valley {a b c G f fb step} {
   return $fb
}
proc ::mtmtcl::Lie::golden::bestvalue::uphill {a b c G f fa step} {
   return $fa
}
proc ::mtmtcl::Lie::golden::bestvalue::downhill {a b c G f fc step} {
   return $fc
}
%   \end{tcl}
% \end{proc}\end{proc}\end{proc}
% 
% \begin{proc}{derailed}
%   The |derailed| state has the value in another position.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::bestvalue::derailed {p fp step count} {
   return $fp
}
%   \end{tcl}
% \end{proc}
% 
% \setnamespace{mtmtcl::Lie::golden::stepsize}
% 
% \begin{proc}{valley}
% \begin{proc}{uphill}
% \begin{proc}{downhill}
%   The situation for |stepsize| is quite similar.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::stepsize::valley {a b c G f fb step} {
   return $step
}
proc ::mtmtcl::Lie::golden::stepsize::uphill {a b c G f fa step} {
   return $step
}
proc ::mtmtcl::Lie::golden::stepsize::downhill {a b c G f fc step} {
   return $step
}
%   \end{tcl}
% \end{proc}\end{proc}\end{proc}
% 
% \begin{proc}{derailed}
%   Ditto for |derailed|.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::stepsize::derailed {p fp step count} {
   return $step
}
%   \end{tcl}
% \end{proc}
% 
% 
% \setnamespace{mtmtcl::Lie::golden}
% 
% \begin{proc}{trend}
%   The |trend| command just need to look at the first element of the 
%   \word{state}, so a full dispatch is unnecessarily complicated.
%   \begin{tcl}
proc ::mtmtcl::Lie::golden::trend {state} {
   switch -- [lindex $state 0] {
      uphill   {return 1}
      downhill {return -1}
      default  {return 0}
   }
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{tcl}
%</golden>
% \end{tcl}
% 
% 
% 
% \section{Products of Lie groups}
% 
% The cartesian product of two Lie groups is again a Lie group, and 
% this can be used to create a unified interface for composite data; 
% several variables (which may have quite different domains) can be 
% combined into one, for purposes of for example running 
% |mtmtcl::Lie::golden| minimisation.
% The natural encoding of a value in a cartesian product is as a list 
% of the component values, and this fact is part of the official 
% interface of the |mtmtcl::Lie::product| package that users may rely 
% upon, even though the standard methods of the 
% \APIref{direct product}{1.0} formal interface are available too.
% \begin{tcl}
%<*docstrip.tcl::catalogue>
pkgProvide mtmtcl::Lie::product 1.0 product
%</docstrip.tcl::catalogue>
%<*product>
package require API 1.0
% \end{tcl}
% \setnamespace{mtmtcl::Lie::product}
% 
% 
% \subsection{The group structure}
% 
% \begin{tclcommand}{ensemble}{group}
%   As usual, the group structure is implemented as an ensemble, but 
%   unlike those defined above it will take lots and lots of 
%   parameters. The reason for this is that there are lots and lots of 
%   subordinate structures which the ensemble provides access to, and 
%   these are packaged into the parameteres. Not all structures have a 
%   separate parameter\Ldash all the component groups are packed into 
%   just one\Rdash but there is also the tangent space, the coordinate 
%   space, and the superset to consider. Therefore the |group| ensemble 
%   has the syntax
%   \begin{displaysyntax}
%     group \word{algebra} \word{coordinate-space} \word{superset} 
%     \word{component groups} \word{API-dict} \word{method} 
%     \word{arg}\regstar
%   \end{displaysyntax}
%   
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::product {
   namespace ensemble create -subcommands {
%   \end{tcl}
%   The list of subcommands should be pretty obvious: first the 
%   methods of a \APIref{Lie group}{1.1} (duh),
%   \begin{tcl}
      = * 1 inverse charts p2c c2p coord tangent exp
%   \end{tcl}
%   second the methods of a \APIref{direct product}{1.1},
%   \begin{tcl}
      no.components component index tuple
%   \end{tcl}
%   third the methods of a \APIref+{subset}{2.1} and \APIref{metric 
%   space}{1.2} (remember that the aim is to produce a structure that 
%   can support |mtmtcl::Lie::golden|),
%   \begin{tcl}
      superset improve distance
%   \end{tcl}
%   and finally some miscellaneous methods.
%   \begin{tcl}
      export import API
   } -parameters {
      LieAlgebra CoordinateSpace Superset ComponentGroupList API
   } -map {
%   \end{tcl}
%   The |API| method has an obvious mapping implementation.
%   \begin{tcl}
      API {::API::nstatic 4}
%   \end{tcl}
%   The various methods for accessing an underlying structure are 
%   perhaps also best implemented as a mapping through a lambda. 
%   \begin{tcl}
      coord {::apply {{Alg Cspace Super CGL API args} {
         tailcall {*}$Cspace {*}$args
      } ::}}
      tangent {::apply {{Alg Cspace Super CGL API args} {
         tailcall {*}$Alg {*}$args
      } ::}}
      superset {::apply {{Alg Cspace Super CGL API args} {
         tailcall {*}$Super {*}$args
      } ::}}
      component {::apply {{Alg Cspace Super CGL API index args} {
         if {[llength $CGL] <= [incr index 0] || $index<0} then {
            return -code error "Invalid component index: $index"
         }
         tailcall {*}[lindex $CGL $index] {*}$args
      } ::}}
%   \end{tcl}
%   That last one is perhaps a stretch, but still fairly reasonable 
%   to bundle with the others.
%   \begin{tcl}
   } -command ::mtmtcl::Lie::product::group -prefix 0
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% The actual method implementations are then very straightforward 
% (even annoyingly repetitive, after a while): loop over components, 
% perform corresponding component operation, and combine.
% 
% \begin{proc}{*}
%   As a case in point, here is how the product group operation is 
%   implemented.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::* {Alg Cspace Super CGL API left right} {
   set res {}
   foreach l $left r $right G $CGL {
      lappend res [{*}$G * $l $r]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{1}
%   And here is how one constructs the identity.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::1 {Alg Cspace Super CGL API} {
   set res {}
   foreach G $CGL {lappend res [{*}$G 1]}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{=}
%   Testing for equality is marginally different, due in part to the 
%   shortcut evaluation when returning false.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::= {Alg Cspace Super CGL API left right} {
   foreach l $left r $right G $CGL {
      if {![{*}$G = $l $r]} then {return 0}
   }
   return 1
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{inverse}
%   But then it is back to the routine.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::inverse {Alg Cspace Super CGL API arg} {
   set res {}
   foreach a $arg G $CGL {
      lappend res [{*}$G inverse $a]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{exp}
%   In terms of a typified signature, the |exp|onent map is very 
%   different from the |inverse| (since its argument is a Lie algebra 
%   element rather than a Lie group element), but one could easily 
%   unify the two. Then again, doing so would probably hurt 
%   maintainability more than it might help, so here it is on its own.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::exp {Alg Cspace Super CGL API arg} {
   set res {}
   foreach a $arg G $CGL {
      lappend res [{*}$G exp $a]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{improve}
%   Improving is another operation which falls into the same routine.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::improve {Alg Cspace Super CGL API arg} {
   set res {}
   foreach a $arg G $CGL {
      lappend res [{*}$G improve $a]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% So what might one do to shake this monotony? Well, one might 
% consider the operation which is mathematically nontrivial, and that 
% happens to be |distance|.
% 
% \begin{proc}{distance}
%   The basic approach for defining a metric on a cartesian product 
%   of metric spaces is to take the sum of the component distances as 
%   the combined distance, but if the underlying component distances 
%   are defined from inner products, and one wishes the distance on 
%   the product group to match a combined inner product on the 
%   |tangent| space as required by the |mtmtcl::Lie::golden| package, 
%   then it would be better if the product |distance| were defined in 
%   such a way that it similarly fits with the combined inner 
%   product. This can for that case be achieved by using the pythagorean 
%   sum (square root of sum of squares) of component distances 
%   instead of the straight sum, as then the combined distance $D$ is 
%   then
%   \[
%     D(a,b) = 
%     \biggl( \sum_{j=1}^k d_j(a,b)^2 \biggr)^{1/2} =
%     \biggl( \sum_{j=1}^k \lvert a_j-b_j \rvert^2 \biggr)^{1/2} =
%     \lvert a - b \rvert \text{,}
%   \]
%   but is this a metric also for component metrics not derved from 
%   inner products? It turns out that it is.
%   
%   The tricky thing to verify is that the thus combined metric $D$ 
%   still satisfies the triangle inequality \(D(a,b) + D(b,c) 
%   \geqslant D(a,c)\). However, in the case that \(D(x,y) = \sqrt{ 
%   d_1(x,y)^2 + d_2(x,y)^2 }\) one finds that
%   \begin{align*}
%     \bigl( D(a,b) + D(b,c) \bigr)^2 
%     ={}&
%     D(a,b)^2 + D(b,c)^2 + 2D(a,b)D(b,c) 
%     = \\ ={}&
%     \begin{aligned}[t]
%       & d_1(a,b)^2 + d_2(a,b)^2 + d_1(b,c)^2 + d_2(b,c)^2 + \\
%       & \qquad{}+ 
%       2\sqrt{d_1(a,b)^2 + d_2(a,b)^2} \sqrt{d_1(b,c)^2 + d_2(b,c)^2}
%       \geqslant 
%     \end{aligned}
%     \\ \geqslant{}&
%     d_1(a,b)^2 + d_2(a,b)^2 + d_1(b,c)^2 + d_2(b,c)^2 + 
%       \\ & \qquad{}+
%     2d_1(a,b)d_1(b,c) + 2d_2(a,b)d_2(b,c) 
%     = \\ ={}&
%     \bigl( d_1(a,b) + d_1(b,c) \bigr)^2 +
%     \bigl( d_2(a,b) + d_2(b,c) \bigr)^2 
%     \geqslant \\ \geqslant{}&
%     d_1(a,c)^2 + d_2(a,c)^2 
%     =
%     D(a,c)^2 \text{,}
%   \end{align*}
%   and the same conclusion for the case of more than two components 
%   follows using a trivial induction. Hence
%   \begin{tcl}
proc ::mtmtcl::Lie::product::distance\
  {Alg Cspace Super CGL API left right} {
   set sum 0.0
   foreach l $left r $right G $CGL {
      set sum [expr {$sum + [{*}$G distance $l $r] ** 2}]
   }
   return [expr {sqrt($sum)}]
}
%   \end{tcl}
%   really defines a |distance| function.
% \end{proc}
% 
% 
% \begin{proc}{p2c}
% \begin{proc}{c2p}
%   More trivialities arise for conversions between point and 
%   coordinate; here one need only note that the charts are also 
%   lists of component charts.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::p2c\
  {Alg Cspace Super CGL API chart point} {
   set res {}
   foreach p $point h $chart G $CGL {
      lappend res [{*}$G p2c $h $p]
   }
   return $res
}
proc ::mtmtcl::Lie::product::c2p\
  {Alg Cspace Super CGL API chart coord} {
   set res {}
   foreach c $coord h $chart G $CGL {
      lappend res [{*}$G c2p $h $c]
   }
   return $res
}
%   \end{tcl}
% \end{proc}\end{proc}
% 
% \begin{proc}{charts}
%   Compiling a list of charts is slightly different, since the 
%   operation for combining two lists of charts is the cartesian 
%   product. 
%   
%   The first part computes the projections onto the various 
%   components of the points specified.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::charts {Alg Cspace Super CGL API points} {
   set projections {}
   foreach dummy $CGL {
      set L {}
      foreach p $points {lappend L [lindex $p [llength $projections]]}
      lappend projections $L
   }
%   \end{tcl}
%   The second part computes the cartesian product of the lists of 
%   component charts. This can easily come out as a very large set, 
%   but that is unavoidable at least in the case that |points| is 
%   empty, since the product of $k$ groups with $2$ components each 
%   has $2^k$ components in total, and |charts| is supposed to return 
%   one chart for each of these.
%   \begin{tcl}
   set res {{}}
   foreach G $CGL projection $projections {
      set res2 {}
      foreach chart [{*}$G charts {*}$projection] {
         foreach old $res {
            lappend res2 [linsert $old end $chart]
         }
      }
      set res $res2
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{proc}{no.components}
%   The |no.components| method is easy, but at least not in the same 
%   pattern as usual operations.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::no.components {Alg Cspace Super CGL API} {
   llength $CGL
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{index}
%   The same is true for |index| and |tuple|.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::index {Alg Cspace Super CGL API i p} {
   lindex $p $i
}
proc ::mtmtcl::Lie::product::tuple {Alg Cspace Super CGL API args} {
   return $args
}
%   \end{tcl}
% \end{proc}
% 
% 
% This means only the |export| and |import| operations remain to 
% implement. The natural export format is as a \OMSref{list1}{list} of 
% the exports of the components, which means |export| is yet another 
% method that falls into the general pattern.
% 
% \begin{proc}{export}
%   As a matter of practicality, one may however observe that this 
%   procedure can be reused as an |export| in other structures too, 
%   so nothing is claimed about the first three parameters.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::export\
  {param1 param2 param3 CGL API element attrD} {
   set L {}
   foreach e $element G $CGL {
      set D $attrD
      dict lappend D mtmtcl:path component [llength $L]
      lappend L [{*}$G export $e $D]
   }
   dict lappend attrD mtmtcl:path tuple
   ::mtmtcl::openmath::OM A [
      ::mtmtcl::openmath::OM mS list1 list $attrD tuple
   ] {*}$L
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{import}
%   Here is an |import| implementation that goes with that |export| 
%   procedure.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::import\
  {param1 param2 param3 CGL API path tree} {
   while {[lindex $tree 0] eq "OMATTR"} {set tree [lindex $tree 2 1]}
   ::mtmtcl::openmath::OMAS_switch $tree {} \
     http://www.openmath.org/cd/list1#list {
      if {[llength [lindex $tree 2]] != [llength $CGL]+1} then {
         return -code error -errorcode [list API import EDOM $path $tree]\
           "Got [expr {[llength [lindex $tree 2]]-1}] components,\
            expected [llength $CGL]"
      }
      set res {}
      foreach G $CGL subtree [lrange [lindex $tree 2] 1 end] {
         lappend res [{*}$G import\
           [linsert $path end component [llength $res]] $subtree]
      }
      return $res
   }
   return -code error -errorcode [list API import EDOM $path $tree]\
     "Expected a list1#list"
}
%   \end{tcl}
%   Since the unitary groups defined above do not support 
%   \APIref{import}{1.0}, it may well happen that this procedure 
%   errors out when one tries to use it, but that is fine since the 
%   API of the product group in those cases will not claim it 
%   supports importing. Anyone calling a method not covered by any 
%   interface does so at one's own risk.
% \end{proc}
% 
% \begin{proc}{group_API}
%   The job of computing the \word{API} for a product group is done 
%   by the |group_API| procedure, which has the syntax
%   \begin{displaysyntax}
%     |group_API| \word{component group list}
%   \end{displaysyntax}
%   where each element of the \word{component group list} is the 
%   command prefix for one of the component groups. This call returns 
%   an \word{API} dictionary.
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::product::group_API {CGL} {
   set res [dict create "direct product" 1.0]
%   \end{tcl}
%   Regardless of what the ``component groups'' are, the product will 
%   be a \APIref+{direct product}{1.0}. Will it satisfy v\,1.1 too, 
%   though? That depends on whether the components satisfy 
%   \APIref+{equality}{1.0}.
%   \begin{tcl}
   set ok 1
   foreach G $CGL {
      if {![{*}$G API equality 1.0]} then {set ok 0; break}
   }
   if {$ok} then {
      dict set res "direct product" 1.1
      dict set res "equality" 1.0
%   \end{tcl}
%   The product cannot support \APIref+{equality}{1.1} since |=| as 
%   implemented above is strictly binary, and making it variadic 
%   instead is of little use.
%   
%   For the rest of the checks it seems a good idea to optimise for 
%   the case that all components are Lie groups, since that implies 
%   that they are a lot of other things too.
%   \begin{tcl}
      set ver 1.1
      foreach G $CGL {
         if {[{*}$G API "Lie group" $ver]} then {continue}
         if {$ver eq "1.1" && [{*}$G API "Lie group" 1.0]} then {
            set ver 1.0
         } else {
            set ver ""
            break
         }
      }
      if {$ver ne ""} then {
         dict set res "Lie group" $ver
         dict set res group 1.0
         dict set res semigroup 1.0
         dict set res monoid 1.0
         if {$ver eq "1.1"} then {
            dict set res manifold 1.0
         }
      } else {
%   \end{tcl}
%   The value of catering for \texttt{group}s that are not 
%   \texttt{Lie group}s could be questioned, but it's no big deal.
%   \begin{tcl}
         set ok 1
         foreach G $CGL {
            if {![{*}$G API group 1.0]} then {set ok 0; break}
         }
         if {$ok} then {
            dict set res group 1.0
            dict set res semigroup 1.0
            dict set res monoid 1.0
         }
      }
   }
%   \end{tcl}
%   But there are a few more interfaces to check: 
%   \APIref+{subset}{2.1} and \APIref+{metric space}{1.2}.
%   \begin{tcl}
   set ver 2.1
   foreach G $CGL {
      if {[{*}$G API subset $ver]} then {continue}
      if {$ver eq "2.1" && [{*}$G API subset 2.0]} then {
         set ver 2.0
      } else {
         set ver ""
         break
      }
   }
   if {$ver ne ""} then {dict set res subset $ver}
   set ver 1.2
   foreach G $CGL {
      if {[{*}$G API "metric space" $ver]} then {continue}
      if {$ver eq "1.2"} then {
         set ver 1.1
         if {[{*}$G API "metric space" $ver]} then {continue}
      }
      if {[{*}$G API "metric space" 1.0]} then {
         set ver 1.0
      } else {
         set ver ""; break
      }
   }
   if {$ver ne ""} then {dict set res "metric space" $ver}
%   \end{tcl}
%   And also \APIref+{export}{2.0} and \APIref{import}{1.0}.
%   \begin{tcl}
   set ok 1
   foreach G $CGL {
      if {![{*}$G API export 2.0]} then {set ok 0; break}
   }
   if {$ok} then {dict set res export 2.0}
   set ok 1
   foreach G $CGL {
      if {![{*}$G API import 1.0]} then {set ok 0; break}
   }
   if {$ok} then {dict set res import 1.0}
%   \end{tcl}
%   But those appear to be it.
%   \begin{tcl}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% \subsection{The Lie algebra structure}
% 
% Next in line is the Lie algebra structure, which largely follows 
% the same principles. The |algebra| ensemble will have the syntax
% \begin{displaysyntax}
%   algebra \word{superset} \word{component algebras} \word{API-dict} 
%   \word{method} \word{arg}\regstar
% \end{displaysyntax}
% and this dictates how many arguments the procedures implementing 
% the methods will have.
% 
% \begin{proc}{+}
%   Apart from that, addition looks exactly the same as group 
%   multiplication.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::+ {Super CAL API left right} {
   set res {}
   foreach l $left r $right A $CAL {
      lappend res [{*}$A + $l $r]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{0}
%   And the zero operation looks like getting the group identity.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::0 {Super CAL API} {
   set res {}
   foreach A $CAL {lappend res [{*}$A 0]}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{proc}{neg}
%   Ditto for the negative and inverse.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::neg {Super CAL API arg} {
   set res {}
   foreach a $arg A $CAL {lappend res [{*}$A neg $a]}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% Should one bother with subtraction? Probably not, since it opens up 
% a can of worms regarding how that should be implemented: Always 
% rely on subtraction in the components? Or negate-and-add when 
% subtraction isn't available? Adapting probably requires choosing an 
% appropriate ensemble! Such a feature can always be added later, if 
% the need is felt.
% 
% \begin{proc}{.}
%   An operation that is needed is however multiplication by scalar.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::. {Super CAL API r arg} {
   set res {}
   foreach a $arg A $CAL {lappend res [{*}$A . $r $a]}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% The scalars are however an issue which is somewhat tricky. For the 
% cartesian product of a bunch of modules to be a module, they must 
% all be modules over the same ring, but \mtl\ offers no mechanism 
% for checking whether two structures are ``the same'',\footnote{
%   In general, it can be a highly nontrivial question to tell whether 
%   two structures are the same, so it is mostly a good thing that we 
%   do not claim to be able to answer it.
% } so what can one do? Only have trust in that the \emph{user} made 
% sure that all components are over the same ring, and in that case 
% each component gives equal access to the implementation of that 
% ring.
% 
% \begin{proc}{innerprod}
%   Access to the ring of scalars becomes an issue for the 
%   implementation of the inner product, as it needs to add the 
%   component inner products together. Since it should not matter 
%   which component's |scalar|s are used, it is always the first one.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::innerprod {Super CAL API left right} {
   set res [{*}[lindex $CAL 0] scalar 0]
   foreach A $CAL l $left r $right {
      set res [{*}[lindex $CAL 0] + $res [{*}$A innerprod $l $r]]
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{tclcommand}{ensemble}{algebra}
%   For the time being, that is all the method implementation 
%   procedures that the |algebra| ensemble needs.
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::product {
   namespace ensemble create -parameters {
      Superset ComponentAlgebraList API
   } -map {
      API {::API::nstatic 2}
%   \end{tcl}
%   The \APIref{direct product}{1.1} operations can all be 
%   implemented as in the |group|, if one pads the prefixes to account 
%   for two missing parameters.
%   \begin{tcl}
      component {::apply {{Super CAL API k args} {
         tailcall {*}[lindex $CAL $k] {*}$args
      } ::}}
      tuple         {tuple 1 2}
      index         {index 1 2}
      no.components {no.components 1 2}
%   \end{tcl}
%   The same is true for the \APIref+{subset}{2.1}, 
%   \APIref{export}{2.0}, \APIref{import}{1.0}, and \APIref{metric 
%   space}{1.0} methods.
%   \begin{tcl}
      superset {::apply {{Super CAL API args} {
         tailcall {*}$Super {*}$args
      } ::}}
      improve       {improve 1 2}
      export        {export 1 2}
      import        {import 1 2}
      distance      {distance 1 2}
%   \end{tcl}
%   \APIref{equality}{1.0} also makes do with the |group =|, but the 
%   \APIref{ring}{2.0}, \APIref{ring-module}{2.1}, and \APIref{inner 
%   product space}{1.1} additions make do without padding. For the 
%   \APIref{ring-algebra}{2.0} method |*| (i.e., the Lie bracket), it 
%   is again possible to reuse the |group *| if padding it; the 
%   component structures are different from those of a |group|, so 
%   they implement |*| differently.
%   \begin{tcl}
      =             {= 1 2}
      +             +
      0             0
      neg           neg 
      .             .
      scalar {::apply {{Super CAL API args} {
         tailcall {*}[lindex $CAL 0] scalar {*}$args
      } ::}}
      innerprod     innerprod
      *             {* 1 2}
%   \end{tcl}
%   Conspicuously missing from the above list is the \APIref{free 
%   ring-module}{2.1} methods. They have a canonical definition, but 
%   implementing them will have to wait until the details concerning 
%   the formalisation of a disjoint union has been sorted out. (The 
%   index set of the basis will be a formally disjoint union of the 
%   component index sets.)
%   \begin{tcl}
   } -command [namespace current]::algebra -prefix 0
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% \begin{proc}{algebra_API}
%   All that is needed to complete the work with the Lie algebra 
%   structure is thus the procedure computing its \word{API-dict}, 
%   which has the call syntax
%   \begin{displaysyntax}
%     |algebra_API| \word{component structure list}
%   \end{displaysyntax}
%   but that is to a large extent the same as for the |space| 
%   structure, so it makes sense to begin by calling that.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::algebra_API {CAL} {
   set res [space_API $CAL]
%   \end{tcl}
%   What is not covered by that procedure is on one hand those 
%   interfaces that concern the |*| method: \APIref{ring}{2.0} and 
%   \APIref{ring-algebra}{2.0}.
%   \begin{tcl}
   set interface ring-algebra
   foreach A $CAL {
      if {[{*}$A API $interface 2.0]} then {continue}
      if {[{*}$A API ring 2.0]} then {
         set interface ring
      } else {
         return $res
      }
   }
   dict lappend res $interface 2.0
   if {$interface eq "ring-algebra"} then {
      dict lappend res ring 2.0
   }
%   \end{tcl}
%   On the other hand, there is the \APIref+{subset}{2.1} interface.
%   \begin{tcl}
   set minor 1
   foreach S $CAL {
      if {[{*}$S API subset 2.$minor]} then {continue}
      if {[incr minor -1] >= 0} then {
         if {[{*}$S API subset 2.$minor]} then {continue}
      }
      break
   }
   if {$minor>=0} then {dict lappend res subset 2.$minor}
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% 
% 
% \subsection{The space structure}
% 
% \begin{proc}{space_API}
%   The syntax of the procedure for determining the \word{API-dict} 
%   of a product of spaces is similarly
%   \begin{displaysyntax}
%     |space_API| \word{component structure list}
%   \end{displaysyntax}
%   
%   Here, the check begins with those interfaces that are mostly 
%   independent from other interfaces. It is as an initial guess 
%   assumed that \APIref{equality}{1.0} is supported, since then 
%   \APIref+{direct product}{1.1} will be supported as well, but if 
%   it in the end turns out that |equality| is not supported then 
%   both of these will have to be unset.
%   \begin{tcl}
proc ::mtmtcl::Lie::product::space_API {CSL} {
   set res [dict create "direct product" 1.1 equality 1.0]
   set ok 1
   foreach S $CSL {
      if {![{*}$S API export 2.0]} then {set ok 0; break}
   }
   if {$ok} then {dict lappend res export 2.0}
   set ok 1
   foreach S $CSL {
      if {![{*}$S API import 1.0]} then {set ok 0; break}
   }
   if {$ok} then {dict lappend res import 1.0}
%   \end{tcl}
%   \APIref+{metric space}{1.1} and up implies support for 
%   \APIref{equality}{1.0} and thus for \APIref+{direct product}{1.1}.
%   \begin{tcl}
   set minor 2
   foreach S $CSL {
      if {[{*}$S API "metric space" 1.$minor]} then {continue}
      if {[incr minor -1] >= 0} then {
         if {[{*}$S API "metric space" 1.$minor]} then {continue}
         if {[incr minor -1] >= 0} then {
            if {[{*}$S API "metric space" 1.$minor]} then {continue}
         }
      }
      break
   }
   if {$minor >= 0} then {dict lappend res "metric space" 1.$minor}
%   \end{tcl}
%   Then begins the grunt work of checking for the algebraic 
%   interfaces. This is optimised for the case that the strongest 
%   interface under consideration is supported.
%   \begin{tcl}
   set ok 1
   foreach S $CSL {
      if {![{*}$S API "inner product space" 1.1]} then {
         set ok 0; break
      }
   }
   if {$ok} then {
      dict set res "inner product space" 1.1
      dict set res "ring-module" 2.1
      dict set res "additive group" 2.0
      return $res
   }
%   \end{tcl}
%   But otherwise the weaker interfaces are tried, in turn.
%   \begin{tcl}
   set ok 1
   foreach S $CSL {
      if {![{*}$S API "ring-module" 2.1]} then {set ok 0; break}
   }
   if {$ok} then {
      dict set res "ring-module" 2.1
      dict set res "additive group" 2.0
      return $res
   }
   set ok 1
   foreach S $CSL {
      if {![{*}$S API "additive group" 2.0]} then {set ok 0; break}
   }
   if {$ok} then {
      dict set res "additive group" 2.0
      return $res
   }
   foreach S $CSL {
      if {![{*}$S API "equality" 1.0]} then {
         dict unset res "equality"
         dict set res "direct product" 1.0
         break
      }
   }
   return $res
}
%   \end{tcl}
% \end{proc}
% 
% \begin{tclcommand}{ensemble}{space}
%   The |space| ensemble has the syntax
%   \begin{displaysyntax}
%     space \word{component spaces} \word{API-dict} \word{method} 
%     \word{arg}\regstar
%   \end{displaysyntax}
%   Since it does not have a superset parameter, it cannot support 
%   the \APIref{subset}{2.0} interface (not even in the case that the 
%   component spaces support it); this is a bit of a trade-off, 
%   but natural for a bottom level structure.
%   
%   \begin{tcl}
namespace eval ::mtmtcl::Lie::product {
   namespace ensemble create -parameters {ComponentSpaces API} -map {
      API {API::nstatic 1}
%   \end{tcl}
%   The |tuple|, |index|, and |no.components| methods can have the 
%   same implementations as for the |group|, if one pads the prefixes 
%   to account for the missing parameters.
%   \begin{tcl}
      component {::apply {{CSL API k args} {
         tailcall {*}[lindex $CSL $k] {*}$args
      } ::}}
      tuple         {tuple p1 p2 p3}
      index         {index p1 p2 p3}
      no.components {no.components p1 p2 p3}
%   \end{tcl}
%   The same is true for the |import|, |export|, and |distance| 
%   methods.
%   \begin{tcl}
      import        {import p1 p2 p3}
      export        {export p1 p2 p3}
      distance      {distance p1 p2 p3}
%   \end{tcl}
%   Ditto for the operations shared with |algebra|; in that case one 
%   padding parameter is sufficient.
%   \begin{tcl}
      =             {= p1 p2 p3}
      +             {+ p1}
      0             {0 p1}
      neg           {neg p1} 
      -             {- p1}
      .             {. p1}
      scalar {::apply {{CSL API args} {
         tailcall {*}[lindex $CSL 0] {*}$args
      } ::}}
      innerprod     {innerprod p1}
   } -command [namespace current]::space
}
%   \end{tcl}
% \end{tclcommand}
% 
% 
% \subsection{The constructor command}
% 
% \begin{proc}{make}
%   The product constructor command |make| has the syntax
%   \begin{displaysyntax}
%     ::mtmtcl::Lie::product::make \begin{regblock}
%       group \regalt algebra \regalt space
%     \end{regblock} \word{component-list} \begin{regblock}[\regstar]
%       \word{option} \word{value}
%     \end{regblock}
%   \end{displaysyntax}
%   and returns a command prefix implementing the product as a Lie 
%   group / Lie algebra / space of the structures in the 
%   \word{component-list}. At the moment all options are ignored, 
%   but that may change.
%   
%   \begin{tcl}
proc ::mtmtcl::Lie::product::make {what CSL args} {
   if {![llength $CSL]} then {
      return -code error "Empty products are not supported"
   }
   switch -- $what {
%   \end{tcl}
%   Constructing a product space prefix is straightforward, and 
%   mostly amounts to computing the API dictionary.
%   \begin{tcl}
      space {
         return [list [namespace which space] $CSL\
           [space_API $CSL]]
      }
%   \end{tcl}
%   The algebra is a bit more work, since that can have a |superset| 
%   and thus requires recursive construction of a prefix for the 
%   product (as a space) of the component |superset|s.
%   \begin{tcl}
      algebra {
         set prefix [list [namespace which algebra]]
         set API [algebra_API $CSL]
         if {[::API::static $API superset 2.0]} then {
            set L {}
            foreach S $CSL {
               lappend L [linsert $S end superset]
            }
            lappend prefix [make space $L]
         } else {
            lappend prefix ::error
         }
         lappend prefix $CSL $API
         return $prefix
      }
%   \end{tcl}
%   The group case is even trickier, since each \APIref{Lie 
%   group}{1.1} has three separate underlying structures, which all 
%   need to be constructed as products of their component 
%   counterparts. The main reason the coordinate space is produced by 
%   |make algebra| rather than |make space| is that the former can 
%   have a |superset|, which the latter does not. It is of less 
%   importance that the above implementations of Lie matrix groups 
%   both reuse the tangent space as coordinate space.
%   \begin{tcl}
      group {
         set prefix [list [namespace which group]]
         set L {}
         foreach S $CSL {
            lappend L [linsert $S end tangent]
         }
         lappend prefix [make algebra $L]
         set L {}
         foreach S $CSL {
            lappend L [linsert $S end coord]
         }
         lappend prefix [make algebra $L]
         set L {}
         foreach S $CSL {
            lappend L [linsert $S end superset]
         }
         lappend prefix [make space $L]
         lappend prefix $CSL [group_API $CSL]
         return $prefix
      }
%   \end{tcl}
%   But those are all the possibilities that exist (so far).
%   \begin{tcl}
   }
   return -code error "Unknown type (must be group, algebra, or\
     space) of product: $what"
}
%   \end{tcl}
% \end{proc}
% 
% 
% \begin{tcl}
%</product>
% \end{tcl}
% 
% \begin{thebibliography}{99}
% 
% \bibitem{Higham}
%   Nicholas J. Higham: 
%   \textit{Functions of Matrices --- Theory and Computation},
%   SIAM, 2008; 
%   ISBN 978-0-898716-46-7.
% \end{thebibliography}
% 
\endinput